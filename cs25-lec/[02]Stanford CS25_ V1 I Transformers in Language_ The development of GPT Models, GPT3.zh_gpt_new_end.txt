所以，这个模型的一个样本看起来像这样。
所以他们还指向 200 年的 9960 亿美元，占 0.63%。
这是一堆无意义的话。
所以这个句子不太连贯，但至少单词似乎有点相关，就像它们来自同一个空间。
现在，跳到 2011 年深度学习繁荣的开始，我们现在用神经网络进行语言建模，特别是用循环神经网络。
所以你可以摆脱 Ngram 模型中的这个巨大查找表。
相反，我们可以让我们的影响是这些标记，并让这种循环细胞记住一些状态和持久状态。
所以如果我们建立一个像这样的神经模型，我们得到一个示例如下。
所以生命的意义是古代人类繁衍的传统，对好孩子的有利条件较少，因此要移除活力。
所以再次，这并没有真正意义，但它开始有了一个真实句子的流畅感。
是的。
所以更进一步跳到 2016 年，我们有了 LSTM 模型。
当然，LSTMs 是在 RNNs 之上的一种架构创新，它们具有更好的梯度流。
所以它们甚至更好地模拟了长期的依赖关系。
因此，使用LSTM模型，我们得到了这样一个样本，即在过去的两年中，更多的新技术迅速进入市场，并且越来越多的公司必须应对不断变化的在线环境挑战。
所以这个句子开始有点意义了。
有明显的痕迹，比如短语"不断变化"的重复。
从2018年开始，我们有了第一个基于自回归transformer的模型，这些模型在建模这些非常长期的依赖关系方面表现得更好。
这里我展示的是一个完成的例子。
因此，在一个完成中，用户提供提示。
在这种情况下，这段文本横跨堪萨斯州，模型将从这个提示继续。
所以你可以看到，这个完成在多个句子之间是连贯的，尽管有明显的拼写错误。
所以你看到这样一个，不管是什么 Doc Nafee，所以它并不完全有意义。
现在我们来到了GPT-2，这是一个15亿参数的transformer模型。
我复制了我个人认为最引人注目的GPT-2完成。 
与上一页相比，这个设置了一个明显的虚假提示。
所以我们有关于在南美找到独角兽和科学家的内容。
这个模型可能之前没有见过这个确切的提示，必须编造一些一致的内容。
我觉得最令人印象深刻的是，它能够在多个段落中保持一致性。
它创造了这个虚构的佩雷斯博士，并且在多个段落中一直保持了佩雷斯。
我觉得它的名字取得非常贴切。
你可以看到他来自拉巴斯大学，是的，在这一点上我们有相当一致的完整内容。
所以值得披露的是，这是10个样本中最好的。
所以我们仍然需要多次采样才能得到这样的样本。
最后，结束这一节。
是的，是的，当然。
你是在争论仅仅是让我失败的那些例子吗，那10个中最糟糕的？
我可以找一些出来。
是的。
是的。
是的，是的，是的。
我们很抱歉。
最后一个问题。
当你有这10个时，你说我们取了最好的那个。
那是在什么意义上？
是的。
所以这是由人类判断的，我可能会稍微详细解释一下大部分的内容。
所以我想用GPT-3来结束这种飞快的概述。
由于GPT-2已经产生了如此连贯的标签，比如你如何描述GPT-3呢？
我想说最好的方法是，假设你从GPT-2中选择了五次或十次中最好的一次完成，那么这就是你从GPT-3中得到的第一次完成。
当然，"最好"在这里是一种个人衡量标准。
这里我展示了《三体问题》的完成。
你可以看到这次完成令人印象深刻的地方在于它真正忠于这部小说的风格。
我认为第二件让我印象深刻的事情是，它产生的比喻和象征如此之诗意。
所以你会看到这样的描述，血液渗透过她的夹克，一朵暗红色的花在她的胸口绽放。
就像他是一种非常富有诗意和文风的句子。
所以他绝对理解这是小说的一部分，并且试图产生与之相同风格的散文。
所以随着生成的文本变得越来越贴近人类水平，我认为一个真正...
GPT-3的每个参数有多大？
是的，所以它有1750亿个参数，而 GPT-2 大约有10亿个。
那么，你认为这种非常微小的准确性提高是造成了多大的差异吗？
是的，这是一个非常好的问题。
所以在这之后我们可以深入探讨一下，但是有关神经规模定律的研究也正在进行中。
这个想法是，你能否通过一系列较小模型的性能来预测较大模型的性能？
所以我宁愿将性能的提高描述为，并不是因为困惑度的小幅增加，而是它是否符合预期，并且在这方面，GPT-3 是符合预期的。
所以，这是一些关于...的直觉。
我个人认为，在 OpenAI，如果实验没有成功，我们可能已经停止了。
不，我只是认为这是一个有点普遍的事情，所以我们不需要深入探讨这种紧张关系。
在机器学习中，你会看到人们追求额外的1%或25%的准确性，但是模型的增长是在一个功能性的规模上增长的。
所以我有时候会想知道这是否值得，以及你应该在哪里停止。
是的，我想也许这方面我们会稍微涉及一下，但是也有一些意义是，当你达到模型建模的熵极限时，每一次拥有都会给你...
如果你考虑准确性，它并不是线性的。
就好像早期的1%并不等同于最后的1%。
因此，最后的那些部分确实可以帮助你稍微挤出一点点。
抱歉，我跳到我的话题了。
哦是的，是的。
抱歉，这是准确性。
我会解释这个。
所以随着生成文本变得越来越逼真，我认为一个非常自然的问题是人类是否仍然能够区分真假文本。
在这里我们有...
这当然是一个非常设定好的情景。
并非在所有情况下，模型都能够欺骗人类，但这是针对新闻文章的情况。
我们展示了GPT-3生成的样本与真实新闻文章进行对比。
你可以看到，随着参数数量的增加，人类区分真假文章的能力会降低到随机猜测的水平。
是的？
你是如何生成新闻文章的？
哦，我其实不太确定。
所以我并没有特别做这项工作，但我认为一种可能的方法是使用一个分隔符，然后从那里开始生成新闻文章。
还有其他问题吗？
很好。
所以即使有了所有这些令人印象深刻的结果，我认为现在值得退一步思考，问一下我们真正关心的语言建模是为了什么？
它实际上有什么用？
我认为人们可以这样说，这实际上是一个相当狭窄的能力。
为什么你只想要一个系统为你继续写作呢？
你可以争论说，有更重要的任务要解决，比如摘要或翻译。
我认为OpenAI的大多数研究人员都会同意这个观点。
事实上，GPT实际上并不是一个专注于语言建模作为最终目标的项目，而主要是作为一个解决称为无监督学习的问题的工具，我将在接下来的几张幻灯片中介绍。
所以我想做一个关于OpenAI语言建模历史的介绍，希望能解释为什么我们最终使用了GPT系列模型以及我们是如何到达那里的。
希望在这一部分之后，这一切会变得更加直观。
所以深度学习繁荣始于2012年的AlexNet，这是一个能够接受图像和标签并将图像分类为其标签的系统。
我们在AlexNet中发现的是，这些系统能够出奇地很好地泛化。
你可以采用那些不一定是训练分布的数据集，你仍然能在它们上得到相当好的特征。
从那以后，这种监督式方法真的非常、非常强大，对吗？
我们已经能够在许多不同的领域训练模型，以非常准确地进行分类。
你甚至可以有一些保证，监督学习会工作得很好。
所以这里有关键风险优化。
但监督学习的问题是，标签往往是稀缺的，对吧？
特别是在语言任务中，真的没有那么多的文本与它们的摘要配对，或者太多跨语言的配对。
所以收集大量数据可能不太难，但实际上可扩展地标记所有这些数据。
这可能非常耗时且昂贵。
所以无监督学习的主要问题是，我们能否也从未标记的数据中学习？
这更可怕了，因为突然之间我们开始优化一个目标，这不是我们关心的那个，这是真的，对吗？
所以我们过去有的很多保证，我们现在不再拥有。
我们只能有点希望我们学到的特性能够适应广泛的下游任务。
但尽管如此，在语言方面有理由保持非常乐观。
原因是有一个巨大的未标记数据宝库，那就是互联网。
所以真正的问题是，我们能否利用互联网上所有这些未标记的数据来解决我们确实没有那么多数据的语言任务？
希望是如果我们在互联网上预训练这个模型，它们会看到所有这些词在不同环境中的使用，某种理解关系，并且它们将能够利用这种理解来完成我们所做的任何类型的任务。
既然我们已经确定了为什么语言是尝试无监督学习的一个好领域，那么让我们讨论为什么使用生成模型以及为什么使用自回归生成模型。
我确实想强调，你在有监督学习中拥有的很多保障在无监督学习中已经不再存在。
所以这些论点会有一点直觉型的。
因此，我想要提出的第一个论点是这个由Richard Feynman所说的引用，这是一个相当宽广的空间。
所以我不能创造的，我不理解。
这个想法的逆是我们称之为合成分析。
我能创造的东西，我也能理解。
这个已经被Josh Tenenbaum研究过了。
这背后肯定也有某种生物学动机。
但这里的想法是，如果你能创建一个能够生成多样且连贯的样本的语言模型，那么它必定也会建立起能够帮助你解决语言理解问题的表示。
接下来的问题是为什么我们使用自回归模型？
你可能有一个局部目标，对吧？
你只是在预测下一个词。
你可以通过某种方式做得很好，比如某种端gram近似，对吧？
为什么它擅长解决那些允许你总结整段内容的事情？
所以这里的一个直观的论点可能是，假设你想在推理小说的语言建模上做得很好。
然后在结尾有这个重大揭示，比如，“哦，罪犯是某某人”，然后你想预测下一个标记。
要在这项任务中表现得很好，你真的需要对故事中发生的事情有很好的理解，包括所有的曲折转折，甚至可能还需要一些类似演绎推理的技巧。
所以生命的第一个迹象，哦，你有问题吗？
哦，是的。
我们在OpenAI遇到的生命的第一个迹象是预测亚马逊评论是积极的还是消极的任务。
这项工作是在2017年进行的。
所以我们没有像通常的监督式学习那样训练一个分类器，而是训练了一个LSTM模型，只是用来预测亚马逊评论中的下一个字符。
当我们在这个LSTM的特征上训练一个线性模型时，令人惊讶的是，我们发现其中一个细胞或神经元在预测情绪时是在激活的，并且这个神经元的正激活对应于积极的评论，负激活对应于消极的评论。
这是尽管在训练时没有看到任何标签。
所以你甚至可以跟踪这个神经元值在样本中的变化。
所以这有点难以理解，但这些评论是那种也许有人说，哦，我真的很喜欢这部电影，但我不喜欢这一部分。
你可以看到情绪在转换，当你从积极到消极时。
是的，只是预测下一个字符的结果，哦是的。
是否有任何单克隆的架构来鼓励？
哦是的，没有，没有。
这只是一个纯粹的LSTM。
所以你们默认一个神经元，看哪一个在隐藏状态中最活跃。
是的。
所以你在上面训练一个线性分类器。
一个神经元正在发挥作用，是的，只是一个超出预测能力的例外。
好的。
下一个是GPT-1，它是最早证明这种方法可以广泛运用的示范之一。
所以GPT-1是在互联网上训练的，不再是在亚马逊评论上了，而且在许多不同的下游任务上也表现不错。
是的。
而且，这里要强调的一点是，对你的观点来说，微调非常重要，你不会摧毁架构，重新调整一个新模型。
所以它只是一个新的头，为你的任务分类。
这表明您不仅可以使用这种方法进行发送分析，还可以用于蕴涵、语义相似性以及在许多这些基准下获取数据。
所以我已经从一个非常强大的语言模型的角度介绍了GPT-2。
现在我认为值得从无监督学习的角度来看待它。
就像GPT-1一样，GPT-2是在互联网的大量数据上训练的，它只是被训练来预测从前面的标记或单词中预测下一个标记或单词。
但是GPT-2的关键洞察力是许多下游任务可以自然地表达为语言建模任务。
是的，所以GPT-2探讨了我们可以在没有任何微调的情况下，只是使用这种方法来执行下游任务的效果有多好。
所以让我从几个例子开始。
所以假设您想解决一些阅读理解基准测试。
这通常设置为提示，即您必须阅读的一些段落，然后是一堆问题，您必须回答这些问题。
所以您实际上可以直接粘贴整个提示内容。
您提出一个问题，冒号，写出问题，回答冒号，然后让模型从那里完成。
这种方式可以为您提供零准备阅读理解。
我们也可以将其用于其他任务，比如摘要。
例如，这里是CNN文章开头的一部分，关于某种考古发现，你只需在看到这段话后输入TLDR，如果模型足够好的话，它应该会生成好的摘要。
我想展示的最后一个例子是，你也可以进行零次翻译。
所以，如果你想把一个法语句子转换成英语，你可以设置一个提示，如句子插入法语句子，翻译成英语意味着什么，然后模型会完成。
它有时也能做得很好。
这里需要注意的一个关键点是，这是随着参数数量增加的性能图表。
而且，在所有这些模型中，它们都是在同一个数据集上训练的。
所以唯一的变量是规模。
你可以看到，随着模型规模的扩大，这种零次射击能力出现了，或者说平滑地变得更好。
所以规模的作用在这里是重要的。
是的，我认为这些开始接近一些，我猜它们不是很好的基准，但至少是值得尊重的。
是的，确切地说。
在很多情况下，这并不是很好。
老实说，用于翻译的蓝色指标实际上经常会出现，非常感谢。
这不是一个很好的指标。
它的作用是拿一个参考解决方案，然后基本上进行一些像是端gram比较的操作。
在自然语言处理中拥有好的翻译度量标准是一个大问题。
当我谈论代码时，我会多谈一些。
好的。
那么，最后让我们谈谈 GPT-3 如何融入这一画面。
GPT-3 的主要见解是，训练过程本身可以解释为元学习的上下文，这有点像在分布上进行学习。
在训练过程中，模型正在发展某种能力。
它在建模某些段落方面获得了一些技能。
在推理时，当它在迅速了解任务是基于迄今为止提示是什么并适应于该任务以预测下一个标记时，它可以将时间带到推理时间。
所以你可以将训练过程中所有SGD步骤的外部循环视为一种方式，将任务识别和建模下一个标记的内部循环。
所以你可以想象很多任务都是以这种方式框定的。
例如，在左侧，你可以有很多附加的上下文示例，希望这些示例可以帮助你解决一个新的附加问题，比如你可以尝试解开31加41等式。
接下来我将在下一张幻灯片中探讨这两种基准测试的结果。
因此，我们将这种设置称为紫红色算术，简单解释一下，你正在将你的transformer的整个上下文作为尽可能多的示例输入。
最后，你输入你想解决的示例。
所以这里的示例可以是这些前三个加法问题。
然后你有31加41等式，然后你让模型来完成。
所以你会注意到，随着语言模型变得更大，它更能够识别这个任务。
你可以看到，在加法、减法甚至一些乘法任务上，性能会随着模型参数增加到2000亿而显著提高。
在这里似乎有某种阶梯函数的变化。
观察单词还原，这也是真的。
所以我们在X轴上再次有参数，我们有准确性，而每个都是不同种类的还原任务。
所以这条蓝线是你某种循环移动字母，你希望它能还原循环。
还有很多其他变换你可以做，比如随机插入某些单词，例如。
所以这里的最终观点是，这是一个相当普遍的现象。
我们不仅仅在这两个前述任务上测试它。
我们尝试了大约40多个任务的数组。
在这里你可以看到零次射击、一次射击和少数射击性能随着模型的扩大而增加。
所以当然它们都在平滑增加，但需要注意的一点是，零次射击和少数射击之间的差距随着规模的增大也在改善。
棒极了。
所以我们刚刚看到我们可以预训练转换器。
哦，继续。
我很好奇，看起来有三件事。
一个是它们本身被使用。
二是参数的数量。
然后第三个问题，我的理解也是被摄入的数据量。
我很好奇在这三者之间，你展示了很多参数数量肯定会有帮助。
不过我很好奇，你是否有一种感觉，那就是训练任务的难度和复杂性，以及调整的质量程度。
是的。
是的。
所以我想我可以深入一下，也许在这之后会有些话要说，但是是的，让我们在这之后深入讨论。
是的。
我猜想GPT二和三是不同的。
GPT一只是为某些任务增加了额外的分类头。
是的。
很棒。
是的。
好问题。
所以是的，我们刚刚看到我们可以在这种预先训练和发现设置中使用transformer，在这种设置中，我们在预先训练中有一些大量未标记的数据。
在发现设置中我们只有一点点数据，我们可以用这种方式解决许多语言任务。
我想说这已经成为过去几年语言领域中的主导范式。
因此有一些后续目标，像Bert和T5，它们在推动最先进水平方面做得非常好，但并没有什么真正说明这些transformer模型必须应用于语言。
transformer是一个序列模型，因此，它可以仅仅摄取任何字节序列并对它们进行建模。
当你思考这个问题时，像我们消费的所有数据，比如我们的视频或音频，它们在我们的计算机上以字节序列的形式表示。
对。
因此我们可能会想，哦，这种方法能否用来建模我们想要的任何模态？
我认为这种范式至少在我们真的没有好的归纳偏差时非常有趣，就像我们没有。
所以我们不这样做。
但一个问题是，当你确实有非常强的归纳偏差时，它是否还能工作？
所以我将介绍一些工作，这些工作表明答案是肯定的，在图像领域，卷积已经如此流行并且被证实是有效的情况下，它仍然工作得相当好。
我将在这里非常简短地展示第二个结果，即DALI，它展示了它足够强大，甚至能够摄取两种不同的模态并能够结合。
那么第一个问题是，你如何将GPT应用于图像？
有几件事你必须做。
你必须修改这个自回归的下一个词预测目标。
所以自然的类比是你可以把图像想象成一个非常奇怪的语言，其中的“词”是像素。
而你需要预测的是每个点的下一个像素。
因此，我们可以将目标从下一个词预测改为下一个像素预测。
当然，我们希望将其展开为一个序列。
这就是它在计算机上存储的方式。
你只有一个字节序列。
是的。
好问题。
所以在语言设置中，我们在这个大型未标记的互联网数据集上预训练，然后在问答或这些其他基准测试上进行微调。
然后在图像中，这种情况的一个好的类比是你可以在图像网上预训练，不需要标签。
你有一个，比方说，资源少，数据少，抱歉，就像到目前为止，你可以尝试攻击我们的分类。
当然，在这两种设置中，你都可以进行微调和GPT。
你可以做零次射击。
我会说在图像上的标准评估是你做线性探测。
所以你从你的模型中取特征。
模型被冻结了。
你通过模型传递，得到一些特征，然后你看这些特征的预测能力如何。
这是一种社交性的，基本上你让一个模型预测给定的下一个像素。
是的。
是的。
所以CNN是一个自回归图像预测模型的实例。
所以我们在这里问的是，我们能否真的采取相同的transformer架构，我们在语言中使用的，不做任何修改，只是把它投掷出去。
所以这里没有任何2D先验。
所以是的，我，我，我将这称为一个我们确信训练过的模型。
在这里你可以实际看到模型的一些完成作品是什么样的。
所以在左列，我输入的是图像前半部分的像素，而在接下来的四列中，你看到的是不同模型生成的完成作品。
而右列这里是原始参考图像。
你实际上可以看到模型在做一些有趣的事情，对吗？
如果你看最后两排，它没有每次都用网球和魔法地得到相同的完成作品。
这就像是将这些鸟放在不同的环境中，有时候添加反射是将这座灯塔放在草地和水域，例如。
所以如果你认同这种分析综合的理念，我们确实有一些综合部分的提示。
所以我没时间和你们一起讨论所有的结果，但我只想说，在这种设置下，它在某种程度上是相当成功的，你没有太多标记的数据。
如果你在特征的基础上训练一个线性模型，你会得到比在英语网上训练的简历和睡眠相同方法更好的结果。
所以这就像是这个领域的典型方法之间的区别，这个和在image net上的resident之间，你得到了这些特征。
哦，是的。
哦是的。
如果你将其与这种方法进行比较，生成一个在image net上没有标签的生成模型，获取这些特征。
实际上，它对其中一些特征更好地进行了预测。
是的。
一旦这个架构是相同的。
完全正确。
是的。
是的。
是的。
是的。
是的。
所以这个，嗯，是的，所以你可以修改GPT，使其具有可以对涡旋位置进行2D偏置的功能。
嗯，我们不这么做。
我们只是想看看，你能否使用完全相同的方法？
所以早些时候，一些数据只是序列的，但也有元数据显示了序列应该如何被重构。
比如，关于这个故事的数据，但当你想要把序列转换成图片时，你会有元数据会说一些像在NumPy数组中那样的话，它会说，这里是步长。
所以这里是我们的重排。
我好奇的是，在给DPT一个图像之前，至少给了这些元数据。
我明白了。
我明白了。
好的。
这是一个极好的问题。
是的。
在这种情况下，嗯，我们，所有的图片都有相同的形状。
好的。
好的。
好的。
好的。
是的。
所以，但我们不会在模型中像，呃，是的，告诉它行的概念。
是的。
所以它需要从数据中学习，但是，是的，如果数据看起来像是变量图像形状，那么他们可以测试在哪里做。
是的。
是的。
像素比尺寸中的多得多。
呃，是的。
所以这是一些关键的低分辨率图像。
嗯，是的，我们实际上可以将我们要比较的模型训练在高分辨率图像上。
所以我认为这使得它更加令人印象深刻。
但是我们只是在 32x32 上进行训练。
很酷。
所以如果我们对这些模型进行微调以进行 CIFAR 分类，我们可以获得 99% 的准确率，这与 G 管道相匹配。
例如，G 管道是一个系统，它是在带标签的图像网上进行预训练，然后再用标签进行微调。
所以是的，这只是向你展示，即使是这种方法，它并不真正了解卷积，也可以做得很好。
我认为你下周会听到更多关于这个的讲话。
到现在为止，对于用 transformers 来建模许多不同的模态并不奇怪。
所以在 Dolly 中，我们只是问，嗯，对于将两种不同的模态提供给模型并看看我们是否可以学习如何以文本为条件生成图像。
例如，你可能希望它做的一件事是，你提供其中一条这样的文本描述，然后希望它生成一些像下面这样的图像。
而这样做的简单方法就是在字幕图像的组合上训练一个Transformer。
当然，在很多情况下，想法是非常简单的，但实施和执行是困难的地方。
我不会对此进行太多讨论。
我认为今天的重点是语言，但你可以参考论文中的许多细节。
哦，是的。
所以，你可以设定一个最大的捕获长度，然后在那个长度上进行截断，你可以填充到那个长度。
对。
所以你可以看到，它可以生成相当不错的样本。
如果你想要一个带有“OpenAI”字样的店面，它并不完美。
但至少它被理解了，它有点像反向OCR问题，你拿一些文本然后渲染它。
通常是在办公室这样的地方渲染它。
所以，这是一个鼓舞人心的迹象，但我认为，在这里，我的最爱结果是一个零惊人的任务。
所以这里的情况是，例如，如果您的提示与底部的草图完全相同，则可以将其上半部分输入到这个图像中，这是一个帽子，然后请求它完成图像的其余部分，那么它将实际呈现顶部的猫咪就像是一个草图。
您也可以使用相同的方法翻转照片，例如，您可以对照片进行缩放。
当然它们并不完美。
但它对原始字幕中文本的意图有一些理解，比如训练集中是否有“极端特写视角”这样的措辞？
我认为可能有一些类似的例子。
这可能是它获取一些知识的地方。
我们不会主动寻找这些例子。
但是，是的，确实如此。
好的。
完美。
是的。
所以这只是，我们只是去，进行大规模的网络脚本。
我们不会试图找到这样的例子。
对。
因此，您还可以进行类似的着色等操作，对吧？
你可以将猫的颜色变成红色，这样可以更容易地识别图中的对象。
嗯，而且，你可以进行一些语义转换，比如给猫加上墨镜，然后你可以把它放在邮票上。
是的。
所以非常了不起的是，你可以做很多这样的零次转换。
嗯，它并没有被特别训练来做这些事情。
很酷。
那么，接下来，我今天演讲的最后一部分是关于 Codex 的，这是我们最近发布的代码编写模型。
你应该在这里问的第一个问题是，为什么要训练它们来写代码呢？
在这一点上，这难道不只是另一种情绪吗？目前有什么新奇之处？
对。
那么让我给你一些理由。
首先是，GPT-3 已经有了从文档字符串或描述性方法名称中编写 Python 代码的基本能力。
而且我们实际上并没有训练它太多的代码数据。
事实上，我认为可能有主动的过滤来摆脱代码数据。
所以我们对这个功能感到惊讶，因此，你知道，如果我们确实用这个模型并在我们可以找到的大量代码上进行交易，也许会发生一些有趣的事情。
接下来，代码与其他模式的不同之处在于，样本的正确性有一种地面真实性，函数可以通过单元测试和解释器进行测试。
这与语言非常不同，因为要获得一个地面真实的评估，你可能需要一个人来介入。
即使这样，有时候人们也不会同意，比如说，这个是更好的例子，或者这个不是更好的例子。
我曾经也喜欢竞技编程，我真的很想创建一个可以解决我遇到问题的模型。
所以这是同样的事情吗？
就像，你们在这方面与 GitHub 合作了吗？
我们也写了一篇论文。
所以，是的，我认为高级编程语言类似于我们的人类语言。
你们有没有尝试过更低级别的？
有的。
有的。
嗯，嘿，我觉得有一些，是的，有一些后续工作，我们只是在一堆不同的语言上交易，我脑海中没有度量标准，但我见过一些汇编写作模型。
嗯，所以我想我会继续之前的疗法，所以我们有这个研究，我们有单元测试和解释器。
那么我们到底如何评估这些模型，以一种对这两个概念有所了解的方式呢？
所以我们做的第一件事是有了一个数据集，一个新的数据集，其中包含 164 个手写编程问题。
而且，嗯，这些基本上是这里展示的格式。
就像有一个函数名，一个文档字符串，还有一个解决方案。
嗯，平均大约有八个单元。
那么为什么重要的是我们手写这些呢？
嗯，问题在于我们在如此庞大的 GitHub 部分上进行训练。
就像你说，好的，我要取一些 B 代码问题，然后把它们转化为一种评估。
那行不通，因为有太多的 GitHub 存储库，像是，哦，这个问题的解决方案在这里。
所以虽然这不能保证这个问题没有重复，但至少是有人写下来的，而不是从另一个来源复制过来的。
嗯，这里有一些单元测试的例子，你会用来评估前面的函数。
我认为应该很清楚，我们应该使用这个指标。
就像这是正确的基准指标要使用的。
我是说，人们确实使用单元测试来评估代码。
我想说，如果你熟悉竞赛编程，你就无法手动评判成千上万个提交的全部内容，你需要单元测试，这是相当好的。
所以这里有一个有趣的地方是，我们必须创建一个沙箱环境来运行这些生成的解决方案，因为当你在GitHub上训练时，有一堆恶意代码。
有一堆不安全的代码。
你知道的，你的模型应该对此进行采样，并在你的环境中运行它。
很酷。
所以现在我们有了一个评估数据集，让我们定义一个指标。
我们要使用的指标称为“K个通过”，定义为所有问题上的平均概率，其中至少有一个样本通过了测试。
所以，如果我们仅仅通过对每个问题进行精确生成案例样本来评估这个度量标准，那么实际上，它并不是，嗯，在这种方式的抽样中存在很高的方差。
但是你可以想象一下，一个特定样本的过去率大约是1/K，就像，嗯，这有点像是全有或全无的情况。
所以，嗯，我们所做的是生成一个更大的样本集，大于K的大多数时间都是大于五K的情况。
嗯，然后我们计算出正确的数量，我们计算出这个无偏估计量，看起来比实际情况更复杂。
这只是互补计数。
你，嗯，你从中取一些组合，其中所有组合都失败。
然后，我们训练我们的模型，就像我之前暗示的那样，有大约160GB的代码，这些代码是从5400万个存储库中收集而来的。
为了进行高效的训练，我们做的是从各种规模的QPT三模型中微调。
嗯，这实际上并不是绝对必要的。
我们发现，即使没有这样做，我们也可以达到大致相同的最终损失和性能，但是没有这样做会更慢。
所以我们已经有了这些模型。
为什么不直接找到它们？
而且，呃，在代码中有一个额外的技巧可以使训练更快，那就是有很多空格序列对吧？
而这些在语言中不能高效压缩，因为你很少看到它们。
所以它们通常被拆分成许多独立的标记。
因此，我们额外引入了一些标记来压缩这些空格序列。
这使得训练可能快了大约30或40%。
所以标记观察，是的，确切地说。
是的。
太好了。
所以一旦我们有了这些模型，我们可以回顾人类评估数据集，并且我可以分享一些问题给你们，让你们了解模型的情况以及数据集中问题的难度级别。
这是一个120亿参数的模型，通过率达到90%，这意味着90%的样本将通过单元测试。
这对任何人来说都是非常像第一天学Python能够做到的，所以你，呃，将列表中的所有元素增加一。
呃，这是一个通过率为17%的问题。
这是一个解决方案。
这是我早些时候给出的问题。
所以你被给定了一个非空的整数列表。
您要返回所有奇数元素之和，这些奇数元素位于偶数位置。
这听起来对您可能不那么困难，但模型经常会对此感到困惑，比如，哦，奇数是指位置还是元素。
嗯，所以在这里你实际上可以看到它正在做正确的事情。
最后，这是数据集中较难问题之一的例子。
所以通过率在这里不到1%。
所以这里发生的实际上是有一个编码函数，它接受一个字符串。
它将其分成每组三个字符的块，并且对每个字符进行循环位移，你必须编写一个解码器，一些可以逆转此操作的东西。
嗯，所以，你可以看到模型，这是一个真实的模型解决方案。
所以它以相同的方式切分字符。
你可以看到循环位移是相反的方式。
所以，嗯，在那里，它取每组的第一个元素移到末尾，现在它取每组的最后一个元素，那就是Jennifer。
好的。
所以我想知道，嗯，所以像你在评论中举了几个例子，它们的效果如何。
所以，我在想这个模型是否能够通过那些只有例子而没有依赖的例子来推断出它正在做什么。
是的。
所以我们的一些任务，有一些例子在教义中。
但是，我觉得其中一些例子只是为了匹配我们在现实世界中找到的真实任务的分布。
就像在这种情况下，它没有，但是肯定对于单元测试，这些任务中没有一个出现。
我只是好奇，如果你只给它例子而不给任务的描述。
哦，我明白了。
我明白了。
那么它是否可以像纯归纳一样，你完全不告诉任务是什么？
嗯，是的。
嗯，我还没有尝试过，老实说。
我觉得这值得一试。
是的。
谢谢。
没问题。
所以，在这一点上，我们已经更改了Codex模型。
我们对这个指标进行了评估，但问题是，这一切麻烦都值得吗？
对。
您已经有了这些度量标准，如蓝色，它们是基于匹配的，在语言中。
难道我们不能仅使用这个来近似吗？
我们不需要像解释器一样。
我们不需要生成这么多样本，如果能像这样分离出来就好了。
嗯，但我们发现，呃，这就是，呃，如果你从人类中随机抽取四个问题，并绘制正确与错误解决方案的蓝色评分分布图，你实际上会发现很多分布，总的来说，对吗？
就像，呃，很难区分绿色和蓝色的分布。
所以这表明蓝色评分实际上不是一个很好的衡量功能实践的指标，我们确实需要这种新的指标和这个新的数据集。
所以现在让我们探索通过率在K处，且K大于1的设置。
因此，我们在这里的第一个观察是，你在其上采样的温度会影响你的通过率K，仅仅为了一些直觉，呃，如果你进行温度为零的采样，你每次进行人工采样都会得到相同的样本。
所以，你生成多少样本并不重要。
嗯，你只会得到相同的通过率。
嗯，但是如果你想要生成一百个样本，你可以承受一些错误，但你只想要一个非常多样化的样本集。
所以你可以增加温度，你可以看到随着你增加温度，样本数量对路径的斜率，它变得，所以你可以看到整体的上限，并找到每个样本数量的最佳温度。
所以这就带我来到了个人最喜欢的这篇论文的结果，我称之为采样的不合理有效性。
所以让我解释一下这里发生了什么。
这是模型中的参数数量，这里你有通过率为一和通过率为一百。
我之所以使用这个术语不合理有效性，是因为我认为如果橙色线和蓝色线没有那么远，我可能不会那么惊讶。
就这些规模而言，该模型几乎不再产生语法错误。
如果你运行它，它会运行并产生某种输出。
所以你可以想象一个世界，在那里，基本上你所做的是，模型有一种方法在脑海中，只是不断地对这种方法进行采样。
这只是对错的问题，而我们发现模型实际上是在组合不同的部分并产生功能上不同的东西。
而且，通过从模型中抽取大量样本，您可以将准确率从不到 30% 提高到超过 70%。
不幸的是，如果您没有访问单元测试，知道您的样本中有一个是正确的并不那么有用。
现在，一个实际情境是，比如您正在创建一个自动完成工具，您生成了一百个样本，但您不想向用户展示一百个样本并让他们选择一个。
是的。
您希望尽量进行预过滤，但您没有单元测试。
那么我们能否用其他排名启发式方法来近似这个 Oracle 抽样呢？
这里我展示了几种不同的启发式方法。
比如您可以随机选择一个，但看起来最有希望的是，由我写的，而不是可能。
虽然这种启发式方法在理论上可能不太有根据，但在语言上，这种启发式方法也是相当强大的。
所以回想一下，我们正在做的是，我们有这个评估集，其中有一些独立的函数。
我们想要为它们提供解决方案，但是当我们进行训练时，有很多与这个任务无关的代码。
例如，有很多我们看到的类。
实际上，还有一些数据类，这些也是相关的。
实际上，在 GitHub 上也有很多错误的代码。
所以，我们可能会对不正确的解决方案建模，也可能会对正确的解决方案建模。
所以，我们想到的一件事是，让我们在几个数据集上找到两个 Codex，它们是独立的函数，并且您对此有更可靠的正确解决方案。
所以我们做的是，我们从几个来源找到了这些问题。
所以一个是竞技编程问题。
您可以在这些网站上找到。
通常，它们会给您单元测试，有时候他们不会给您单元测试，您可以提交不正确的解决方案，他们会告诉您第一个失败的解决方案，并将其保留。
所以您可以获得很多竞技编程问题。
另一个来源是启用了持续集成的项目。
那么这些为什么有用呢？
因为你实际上可以进行一种执行跟踪。
所以当你运行集成测试时，你可以获取到两个函数的所有输入及其输出。
因此，你实际上拥有了真正的函数体，你知道测试输出应该是什么。
所以，你知道，某种意义上的基本事实输入和输出。
并且，这些就像是两个正交的数据集。
一种帮助你处理算法类的任务。
另一种更多是像，我能不能操纵命令行工具和像那样的测试？
所以这就引出了codex论文的主要人物。
所以真正我们看到的是能力的进步。
所以在这个人类关于数据集上的GPT-3，通过率在一是零。
基本上，你可以生成一两行连贯的代码，但从来不是一个完整的程序。
现在当你在代码上进行微调，也就是codex，这个橙色线条，你开始在这个数据集上看到某种非凡的表现。
当你进行这种额外的监督式微调，那是这条绿线，你获得了更好的通过率。
然后，如果你从这个模型中生成一百个样本，用平均对数概率重新排序，可以得到更好的通过率。
最后，当然，如果你能访问 Oracle，它会给你最佳的通过率。
所以我这里有一个问题。
你实际上可以使用任何排名来像，像将其放入模型中吗？
你可以将其用作背景信号吗？
是的。
是的。
我们只是放进去了，我不知道我能不能多说这些结果。
是的。
最后，我不想暗示这些模型是完美的。
它们有很多人类程序员不会遇到的限制。
所以其中一个就是，实际上所有生成模型都是自回归生成模型。
有点像，我们在绑定方面有些问题。
所以当有很多变量涉及，有很多操作进行时，有时很难弄清楚哪个操作通过哪个变量进行绑定。
所以你可以在左边看到一些例子。
另外，还有一个有点反直觉的行为是组合。
所以我们可以用一堆非常简单的构建块，比如，拿一个字符串然后反转它，或者，或者像删除每第三个字符这样的操作。
而且我是人，就像你可以改变这两个操作一样，你可能也可以改变它们的结尾，但是我们的模型还不能做到这一点。
很棒。
所以接下来就是结论，嗯，我们在今天的演讲中有四个主要观点。
所以首先，神经语言建模取得了相当快的进展，GPT。
这不是语言建模的推动结果，更多是对推动无监督学习的工作的结果。
第三点是，自回归建模是通用的，即使存在强烈的归纳偏见，比如在图像中或者在文本中，它也能产生强大的结果。
最后，我们可以通过对代码上的 GPT-3 进行微调来产生强大的共同生成模型。
采样是一个非常有效的提高模型性能的方式。
很酷。
最后，我想感谢我的 Codex 主要合著者，一些 OpenAI 的导师，以及我与之合作非常密切的团队。
太棒了。
谢谢大家的注意。
