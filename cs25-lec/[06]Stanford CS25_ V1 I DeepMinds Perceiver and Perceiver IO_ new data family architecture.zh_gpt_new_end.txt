所以今天我要谈论的是我们在 DeepMind 近期所做的一些工作，我们正在开发一系列被我们称为“感知器”的架构。
而我将以我们的一个目标来激励这个，即开发一种通用的架构。
我想立刻激励我们为什么关心通用架构。
首先，这两个原因都相当实际，但基本想法是，如果我们考虑一下我们可能想象收集的所有数据。
其中很多基本上涉及我们所认为的传统感官模式，无论这些事物是触觉和本体感觉，还是回声定位，或者是您需要吸收文本的感知方式，无论您希望如何格式化，还是更奇特的事物，比如基于事件的摄像头，触须，以及触须感知，气味和深度之类的事物，一直到当我们考虑科学感知时所考虑的感官模式。
因此，基本上，如果我们考虑全部数据集以及实际上为模拟每种不同模态所需的时间，对于每一个这些都试图设计归纳偏见，似乎是难以实现的。
所以我们不想一个一个地设计它们。
这是一个行之有效的方法。
在某些方面，这也许是对我们如何思考为不同问题开发新架构的合理描述，但它不会扩展。
作为一个社区，我们无法承担为每一个问题手工设计的演绎偏见。
因此，与其这样做，我们希望构建至少在第一次尝试时能够处理所有问题的架构。
为什么我们应该致力于通用架构还有另一个实际的论据，那就是这样做将使我们能够构建更简单、更统一的系统。
因此，如果你看一下特别是复杂的多模态数据流在感知计算机视觉或模式识别文献中是如何处理的。
事实上，通常是通过使用我们知道适用于各个模态的归纳偏见，然后设计方法将这些不同的子系统结合起来，这可能意味着为每一种情况构建特定的输入模块，然后尝试各种不同的组合方式。
所以这样做可能有效，但原则上，它只能在一个或少数几个领域中工作。
而且，这样做会得到很难维护的系统，往往是脆弱的，往往依赖于对输入模态的特定处理假设。
因此，与其那样做，我们更希望朝着拥有统一的黑匣子架构的方向发展，这种架构只是运行起来。
这里的想法是，如果我们能够达到这一点，我们就可以抽象出架构构建过程，真正专注于其他更高层次的问题。
所以这是这项工作的动机。
我们要做的方式当然是通过致力于迄今为止我们拥有的最通用的架构，也就是基本上是一个transformer。
你们都对transformer的基本构建块非常熟悉。
但简单来说，我们可以思考一下它们的优点，即它们使用了通用的归纳偏差。
因此，它们是非局部的，这意味着它们不对哪些点应该彼此比较做出特定于领域的假设，而是在关注的焦点上往往是全局的。
他们将位置视为特征，而不是架构的硬性约束，这与基于MLP的架构或ConvNets的工作方式形成对比，后者将位置作为架构组件来约束计算的方式。
当然，最后，设计中存在广泛的权重共享。
因为它们专注于矩阵运算，所以它们往往对TPU和GPU友好。
所以这些都是关于transformers工作方式的非常好的特性。
当然，另一方面，它们的计算内存扩展非常差。
而且，这有两个方面的原因。
注意机制本身的计算规模是二次的。
所以，在transformers的核心，有一个O(M²L)的复杂度。
我喜欢用这种方式写它，因为它真的强调了这基本上是一个性质，随着模型变得更大，无论是在输入大小上还是在深度上，这个问题都会变得更糟。
而且因为深度也有这种扩展，这里还有另一种实际的问题发生。
因为我们所做的计算量与输入大小成正比，所以标准Transformer的工作方式中没有瓶颈，即使是线性扩展也会成为一个问题。
因此，在实践中，对于非常非常大的Transformer来说，这通常是真正重要的瓶颈，但它们都在起作用。
所以我们真的希望压制这两个方面。
因此，这里的观点是，要有真正通用的架构，我们不能只是在原则上通用的架构。
我们必须有能够在我们关心的规模和数据类型上实际使用的架构。
所以，仅仅是为了，这对你们所有人来说都是老生常谈的，但标准的QKV注意力的工作方式基本上是这样的。
所以这都是矩阵乘法。
所以我们有一些输入。
我们通过对输入进行一维卷积，即一维卷积来计算查询键和值。
然后我们计算注意力分数。
这是一个矩阵乘法，具有以下这些形状。
然后我们使用这里的输出来计算权重，计算注意力模块本身的实际输出。
然后最后，我们通过一个额外的MLP运行这个，它是应用卷积来获得输出的。
所以这是我们在这里工作的起点。
让我简单地重申一下为什么我们会希望拥有这些标准transformers的优势。
所以非局部性是我们这里的两个归纳偏差原则之一。
我认为将这与ConvNets中获得的有效局部性进行对比是有用的，以及这实际上意味着什么。
所以如果我们基本上按深度来看，输入可以看到哪些其他输入，这意味着如何轻松地表达两个输入点的函数。
假设我们看看这里输入的黄色和紫色点。
现在，我将它们尽可能地设置得远离彼此。
但我们可能会问，在你实际处理这两个点之前，有效的计算需要有多深。
如果你看看一个3x3的卷积，你会发现，你必须一直看到网络的最后，直到你将这些点一起处理。
这意味着你能够表达的函数实际上看着这两点的函数会变得非常浅，因为它们必须建立在这个非常非常深的堆栈之上，这个堆栈仅仅给你提供了局部性。
实际上，如果你看一下，例如，resnets的工作方式。
所以你有一个初始块，它有一个七乘七的卷积。
然后之后一直都是三乘三的卷积。
在所有224乘224像素的图像互相看到对方之前，你需要28个这样的标准处理堆栈中的三乘三的卷积。
这意味着在resnet 50中，像素边缘上的点实际上永远不会看到对方。
这有点让人感到困惑，但它表明我们确实在相当大程度上限制了可以用这些模型轻松表达的函数。
因此，有一些图像的函数是无法用ResNet-50捕捉到的。
另一方面，如果你看一个具有对完整输入的全局注意力的架构，比如transformer，如果你能够按照这种方式进行扩展，或者像我们将要讨论的perceiver，所有像素都可以相互交互。
所以模型基本上可以捕捉到这些事情，并且比它在首先考虑局部性的情况下能更容易地表达出这些函数。
我们还可以发现，这类架构的另一个有趣特性是位置被特征化了。
这基本上意味着我们不再编码某个东西的建筑位置来确定它与其他位置的位置关系。
这也允许网络基本上使用它想要的任何位置信息，但也可以按照自己的意愿丢弃它。
这是它在使用傅立叶或正弦样特性的架构上的标准方法。
但这里有很多灵活性。
好的，现在就从如何卷积神经网络与transformer相关这个角度来思考，它们可能看起来好像存在可扩展性与普适性的平衡。
如果我们看卷积神经网络，它们的应用方式，通常我们可以考虑将它们用在网格结构的数据上。
当然，卷积的泛化形式适用于具有更加有趣拓扑结构的数据集，但通常我们可以将其视为在某种空间中的网格上操作，而transformers适用于一般的集合。
所以从这个角度来看，transformers更加通用。
另一方面，它们的规模要差得多。
所以，卷积神经网络是线性的，在输入点、滤波器大小和架构的层数上都是线性的，而transformers的规模是二次的，它们在深度上仍然是线性的。
因此，从这个角度来看，我们在Perceiver工作线上感兴趣的是将transformers进行扩展，但保持其通用性质。
所以我们希望得到介于这两个极端之间的东西。
我们做到这一点的方式是通过研究自注意力，并在某种程度上修改它以使我们能够更好地扩展。
因此，要了解自注意力在标准transformers中实际执行的操作，我们将输入数组（这里写为指数）作为示例，其中包括标记的数量或像素的数量，基本上是输入单元的数量，具体取决于您所查看的内容，以及通道。
我们有一个1D卷积，所以这是相对于Q、K和V的大O。
然后我们使用此操作的输出计算注意力图。
这给我们一个矩阵相乘，这是二次缩放的源头。
然后最后，我们使用另一个矩阵相乘来计算输出特征。
我们已经在这里受到速率限制，因为即使对于标准分辨率的图像，M也相当大，大约是50,000。
对于标准的ImageNet图像，再次它们非常小。
所以这是一件事，如果我们想要深度架构，它就不会起作用。
所以我们所做的是在架构的输入处，用跨注意力层替换自注意力。
我们通过基本上一个学到的查询来做到这一点。
所以我们只是用一个学到的组件替换输入中的查询。
所以这些索引和通道，你可以把它们想象成RNN的学到的初始状态。
这个想法在文献中有各种各样的名称。
我们称之为潜在的，但它们有时被称为诱导点或其他东西。
所以基本思想是，我们学习查询的输入，保持其键值不变。
这样做的缺点，或者说优势在于，当我们在此之后计算注意力图时，现在我们基本上将其从方阵转换为矩形矩阵，并将矩阵乘法的复杂性降低到O(mn)。
所以现在它与输入大小成线性关系。
而第二个矩阵乘法具有完全相同的性质。
因此，从二次变为线性。
而这个很酷的事情是，交叉注意力的复杂性是线性的，但输出实际上更小。
所以我认为这实际上是更重要的一点，这使我们能够将一个相当大的东西映射成一个与输入无关大小的东西。
我们，所以我们对此拥有完全控制权，这是一个超参数。
这使我们能够在此架构的顶部构建深层网络，以及此潜在的顶部。
因为这个大小很小，我们可以控制，所以我们可以承受在此之上的二次复杂性。
所以我们采用了这个思想，是的？
请继续。
抱歉，我还有点困惑，你们是如何在第二步将这个查询转换成一个矩形的。
这是因为你们在第一步用一个学习到的东西来替换了查询，而这个东西相对于输入大小来说要小得多吗？
是的，完全正确。
所以，如果你看这里的底层矩阵乘法，它被写成QK转置，所以这基本上，这里的外部维度是，它的形状是由查询决定的，通过缩小该查询，我们只是改变了矩阵乘法的输出。
谢谢。
好的，我猜，继续吧。
好的，那么你只对查询这样做，所以键和值保持原始的大小矩阵，是吗？
是的，没错。
好的，但是基本上，我不知道我不理解的是什么。
所以对我来说问题在于，对于一个查询，现在在我的脑海中，我在寻找，假设我有第i个标记。
现在没有第i个查询了。
这不会导致问题吗？
比如当我试图使用它来计算分数时。
是的，这里发生的是你在比较，你会有一个更小的查询子集。
所以如果你考虑这个问题，不是从矩阵相乘的角度，而是从比较每个查询与每个键的角度来看。
所以在正常的自我注意力机制中，我们对每个键有一个查询。
所以每个点都与每个其他点进行比较，对吧？
所以这里我们所做的是，我们不是将每个点与每个其他点进行比较，而是有一组可以看作是一种聚类中心的点。
所以它是一个较小的数量，我们将每个这样的点与每个输入点进行比较。
但是我们不知道哪些标记技术上属于哪些聚类，对吧？
是的。
所以它必须被学习。
是的，完全正确。
完全正确。
所以思考这个问题的一种方式是，我们不是通过将所有东西与所有东西进行比较来说，在正常的自我注意力和transformer中我们是在说，好的，我知道这一点的特征是什么，我希望它能注意到相似的特征。
在这里，我们要表达的意思是，我们正在学习一些应该与输入的某些子集最大程度相似的补充点。
所以，如果我错了，请纠正我，但本质上这实际上是在执行某种硬注意力，你是在说，与其对所有点进行查询，不如选择我们认为非常相似的一些点，并且只对这些硬的、你选择的点进行一些注意力，对吗？
是的，它们是相关的。
那可能是一种思考方式。
对这个想法的一个微小修改是，它们基本上存在于抽象空间中。
所以它们并不被分配到输入查询或输入点的一个对应关系。
它们是被学习的，因此它们可以处于中间的某个位置。
但我认为这是一个很好的思考方式。
这是一个很好的直觉。
但我想我在这里有点困惑的一个地方是，你在这里有关于两个矩阵的索引，就是最左边的紫色和绿色矩阵的索引，但是这些索引不一定对应于输入。
就像在自然语言处理领域，它们不一定是标记，对吧？
这些只是某种程度上的向量索引。
但是在这种情况下，该矩阵是从输入标记到一个N乘D矩阵的某种映射的结果。
是这样吗？
不，事实上，它们，它们，基本上就像是一个学习到的权重集合的方式之一。
所以它们的功能和学习到的位置编码完全相同。
所以它 基本上只是一个学习到的嵌入，但它不受任何条件的限制。
它只是某种程度上，它就是，它只是一组权重。
哦，好的。
这样更有意义，谢谢。
好的，所以如果没有更多的问题，我将继续，但当然，随时可以打断我。
所以，鉴于这个想法，我们有了这个学习到的潜在数组，再次强调，它的功能有点像一个RNN的初始状态或者说是一组权重。
我们基本上是随机初始化它，然后我们使用它来关注输入的字节数组。
因此，这里的字节数组是像ImageNet的像素的平坦集。
而这个的输出将存在于与潜在数组相同的空间，因此具有相同的索引空间。
并且在这里也有残差连接，就像你通常在一个注意力层中所做的那样。
所以一旦我们进入空间，我们就可以通过使用标准的变换器来构建架构，但是用潜在空间而不是输入空间来表达。
这将使我们基本上能够结束，因为我们已经将输入精炼到了更小的空间，我们仍然可以灵活地允许所有这些点进行交互。
所以这应该仍然与transformer一样具有表达力，就像一个普通的transformer一样。
然后这里的每个模块现在都是潜在大小的二次方，而不是输入大小。
所以这是我们可以控制的东西。
所以在感知器的原始版本中，我们发现有额外的交叉关注非常有帮助。
所以这当然是你可以做的事情。
而这背后的直觉是，如果这个瓶颈非常严重，我们无法保留来自输入的所有信息。
所以我们希望这些查询，现在是在过去的条件下，能够回顾输入点。
所以这是我们发现在调整第一篇论文时非常有帮助的一点。
但我要说的一个警告是，我们不再推荐这作为最佳实践，因为这些交叉关注最终会变得非常繁重。
但这是你可以探索的事情，当然，如果你想要更多条件查询或者想要能够跨越关注正在输入的新数据。
我们在拥有有限数据量的数据集背景下发现的另一有帮助的事情是在深度上允许权重共享，对于这些架构来说，包括ImageNet。
所以，这基本上就是将不同的交叉注意力和不同的自注意力层的权重绑定在一起，就像是重复的。
因此，这看起来就像是一个在深度上展开的RNN。
所以，这只是在一个高层次上。
这给我们提供了一种可以应用于图像的架构，但不对图像结构做任何假设。
所以这是一个可以在其他地方使用的架构。
而且基本上，基本上，我们通过位置编码提供有关输入空间结构的信息。
在这里，我们使用2D傅立叶特征位置编码。
只是为了向您展示它看起来是什么样子，以便让您了解，因此每个输入点基本上被分配到某个位置。
所以你将在这里的某个位置。
而且我们在2D中具有正弦和余弦特征。
所以这基本上是对2D输入位置的傅里叶分解。
我们发现的几个事情是，如果我们对频率进行采样，那就是信号的奈奎斯特频率最大的频率，我们的效果比使用较低版本的要好。
基本上，这是因为这样会使每个点都能意识到图像中的每个不同的点，而如果您以较低的频率进行采样，就会出现混叠，因此并非所有点都能辨认。
我们还发现，相对密集地采样频谱倾向于有助于效果。
而我们在开发时对比的是 NERF。
所以 NERF，至少在早期的实现中，使用了相当少的频带。
我们发现，我们添加得越多，效果就越好。
总的来说，这是需要注意的一点。
最后，与语言不同，您通常需要将您的嵌入与您使用的正弦或位置编码相加，而在这里，我们发现将它们串联起来的效果始终更好。
所以这可能是因为内容嵌入不像语言中那样稀疏。
我们并不完全确定，但这是我一直观察到的事情。
在我开始讲结果之前，我只是想将这与在图像环境中使用transformer的其他某些方法进行对比。
因此，这里的明显先例是视觉transformer。
我认为这是一个非常好的方向，特别是在图像环境中，但是有一些关于它的警告，使它不太适用于更一般的、更通用的用途。
其中之一是，视觉transformer确实使用了输入的二维卷积。
这通常用补丁的术语来表达，输入补丁。
这是二维transformer的一个特例。
这确实限制了您可以将其用于的输入类别。
因为我们基本上将这种修补或卷积内置到其中，这意味着这种方法实际上不足以使其在非网格数据上工作。
您可以采用其他方式进行调整，但这是您需要为您正在研究的每个领域专门处理的事情。
最后，由于我们有这种输入，我们告诉架构它应该首先关注初始分组，这就等于取消了非局部性假设。
做这个只做一次会产生多大的差异并不是很清楚，但当你考虑这个架构时，这是需要注意的事情。
最后，交叉注意力在视觉文献中被广泛使用。
所以只是简单举几个例子，Dettr是Facebook的一种目标检测方法，基本上有一个卷积主干，然后用来生成输出特征图。
然后将其传递到transformer编码器解码器中。
当然，每当你听到编码器解码器，你会想到交叉注意力，因为从编码器到解码器，有一个交叉注意力步骤。
因此，他们基本上使用交叉注意力从某种特征图表示转换为更像对象边界框的东西。
还有关于学习自监督或无监督对象分割模型的很好的工作。
在这项工作中，他们正在做一些非常相似的事情，他们有一个卷积主干。
然后使用我们这里介绍的类似潜变量的东西来做，他们在这里称之为槽，但基本上是将一些输出像素分配给不同的槽，以便他们在这里对分割模型中的槽进行独立的互补解码。
还有很多其他事情。
好的，首先我会，现在我要带你们看一下这个模型的结果。
嗨，我可以继续了吗？
我会在你开始后继续。
好的，很酷。
对此感到抱歉。
你能回到我们之前链接的几张幻灯片吗？你知道的，就像输入是如何流入其中的那种。
是的，就是那个。
好的。
嗯，我有两个问题，潜transformer基本上就像是自注意力，对吗？
是的，潜transformer是一个完全自注意的transformer。
明白了。
那么为什么键和值直接流入交叉注意力，而查询也流入其中，但潜阵列与查询并行地流入交叉注意力呢？
你能解释一下吗？
是的，这只是，嗯，它旨在描述残差连接。
因此，交叉注意力，这种交叉注意力被描绘为一个交叉注意力模块。
因此，交叉注意力本身具有注意力，它具有一个残差连接，然后有一个MLP。
这就是它的意思。
好的。
但基本上QKV是标准的。
知道了。
谢谢。
嗨，我有一个与此略有关联的问题。
实际上我们可以直接盖章。
所以我觉得这件事情很有趣。
抱歉，我听不到你说什么了。
你断了。
主要是由注意力层组成，无论是自注意力还是图像转换器。
你能听到我说话吗？
可以听见吗？
声音断断续续的。
我觉得我们现在没问题了。
但我觉得一些最近的工作。
哦，好的。
我应该打字吗？
是这样吗？
我应该打字吗？
是的，我觉得这是个好主意。
是的。
我会打字的。
谢谢，抱歉。
好的。
请随意继续。
我会慢慢打字。
听起来不错。
对我来说挺好的。
是的。
实际上，在你讲上一张幻灯片时，我可以插一句吗，Drew？
好的。
所以这些残差连接，我其实不知道交叉注意力在使用它们。
这些连续交叉注意力层对残差连接有多重依赖呢？
是的，在初始阶段，有两件事我会说，在初始的交叉注意力中，这实际上并没有什么区别。
所以这是我们剔除的一部分。
当我们到达 Perceiver .io 版本时，我们在解码器的交叉注意力中也做了同样的事情，这在那里可能会有所不同，这取决于你在做什么。
我认为当你使用这种重复的交叉注意力时，实际上这是至关重要的，所以当你有这种迭代结构时。
原因是实际用于条件查询的东西基本上就是所有的，那就是到目前为止架构状态的完整表示。
所以跳过连接是从这里来的，基本上是在查询通道中，是在潜在空间中。
所以这基本上是使你最终拥有这种稠密和稳定架构的原因。
谢谢。
所以 ImageNet。
好的，在标准的 ImageNet 处理中，基本上我们与一些对照进行比较，到目前为止，这有点过时了，但我们与一些，只是一些基本的对照进行比较。
因此，与ResNet-50相比，那时候，最好的视觉转换模型纯粹是在ImageNet上。
我们绝对在同一个数量级。
这不是，这些并不是你的最先进的结果，但这是一种架构，再次强调，它不使用任何2D卷积。
因此，它能够做得这么好的事实让我们非常惊讶。
其中一个非常酷的事情是，由于这种架构不做任何假设，架构本身不做任何关于输入图像的空间结构的假设。
我们可以看看经过置换的ImageNet。
在第一个版本中，我们基本上是使用2D位置来计算特征。
因此，2D位置在某种程度上固定在一个位置，到像素，然后我们只是将它们全部混合在一起。
因此，这基本上将让您了解基线有多依赖输入图像的结构。
因此，如果我们看看Transformer和Perceiver的构造，它们不会改变。
因此，这不是经验性的发现。
这是模型的特性，但我们发现，ResNet -50的性能下降了一半左右，而VIT同样只有一层，它依赖于空间结构，也下降了大约15个点。
因此，这表明它在很大程度上依赖于第一层的空间结构信息。
我们可以通过学习完全习得的位置编码，而不是依赖二维傅立叶特征，来稍微推动这一点。
基本上，这就是现在的架构，这是一个完全没有输入结构信息的模型。
因此，将它们洗牌并重新学习绝对是等价的。
而且我们发现，这种架构也能被推至 70% 以上。
而且我们在这里得到了稍好的数字。
总的来说，这似乎效果较差，但 2D 信息还是很有用的，不过你能获得与五六年前的技术水平相当的数据，这一点很酷。
所以这很酷。
抱歉，我有点笨。<EOS
你是说最后两行的区别在于倒数第二行的位置嵌入是二维的，而最后一行的位置嵌入基本上是一维的，对吗？
所以，它是有学问的。
所以，基本上，我相信，这是一个 256 维的学习向量。
但这基本上意味着，模型本身并不了解输入的空间结构。
因此，我们使用的二维位置编码最终会有大约 200 个特征，这取决于你正在看什么。
但它们能为你提供输入的二维结构的详细信息，因为它们是基于输入空间的傅立叶分解。
好，有道理。
谢谢。
嗨，德鲁。
我能问一个关于你用来产生这些传感器波的频率的问题吗？
就像之前的几张幻灯片一样？
是的，这张幻灯片。
基本上，我确实听过一些信号处理方面的讲座。
我知道，如果要避免混叠，我需要至少以奈奎斯特频率采样。<EOS
所以我很好奇为什么要从1开始使用频率，直到奈奎斯特频率，而不是从奈奎斯特频率开始到一些非常高的频率。
哦，我明白了。
所以，基本上，始终使用的最大频率是奈奎斯特。
关于我的生态系统的任何事物都会被混叠，所以你实际上无法解决它。
因为它是在像素空间中，对吧？
所以我们采样 - 一是基本上只是给你一个涵盖整个图像的振荡。
所以这基本上只是非混叠频率全范围的一个样本。
哦，好的，很酷。
谢谢。
好的，所以在图像结果之后，我们想尝试在其他领域使用它。
特别是，我们对如何在多模态领域中使用这个感兴趣。
所以一旦结合了各种不同类型的输入特征，而在这些空间中遇到的一个挑战或问题是来自不同模态的数据最终具有不同的特征，并且它们总是具有不同的语义。
所以如果你将视频的位置编码加上RGB，最终你会得到一些通道的数量。
然后如果您有音频，那对应的数据可能是成对的，但它往往具有较少的特征，并且仅具有一维的位置编码。
所以我们处理这个的方式基本上是通过学习模态特定的位置编码。
所以这些基本上是为每种模态专门学习的嵌入。
这样做的基本上是标记，最终标记来自音频或视频的特征，其中包含一些网络可以学习的信息，使其能够区分哪个是哪个。
但是鉴于这些填充的、这种学习填充的特征向量，我们然后将它们全部连接起来，这就是我们处理多模态数据的方式。
所以基本上架构的输入看起来仍然只是一个大数组。
只是在构造这个的时候，我们知道这个数组中的一些特征，其中的一些行来自视频，而另一些来自音频。
但是模型本身除了学到的知识之外，没有其他信息。
哦，我们还有一些问题。
是的，您可以先开始。
哦，是的，抱歉。
我以为现在结束了。
但是，是的，没错。
如果您能听到我，这只是一个简单的原因。
我一直在正式学习很多transformer相关的内容，所以我不知道位置嵌入是什么。
哦，那么位置嵌入是什么呢？
是的，基本上位置嵌入是一个表明这个的特征。
所以最简单的想法是在文本中。
所以文本，输入是1D，东西存在于某个1D序列中。
对于那里的每个点，你都会对它在那个序列中的位置进行特征化。
所以最简单的事情就是，如果你有-1到1是完整的范围。
它只是实际上表示它在那个序列中的位置。
但是我们通常会添加一些，我们希望对其进行特征化，而不仅仅是单个的特征。
因此，傅里叶分解是这样做的一种方式，以某种方式为其提供高频结构的特权信息。
但是当我们学习东西时，我们也可以只是使用位置来索引一些嵌入数组，这就是我们学习时所做的。
所以基本上它只是一组权重，这些权重被添加到该点的特征中，使网络了解它在Groucher序列中的位置。
你想接下来做什么吗？
抱歉，我刚才得找到一个静音按钮。
好的，实际上我有两个关于傅立叶特征的问题。
我想知道，你们是如何对它们进行采样的，是均匀采样吗？
还是说，你们是如何学习这些特征的？
是的，基本上我们是线性采样它们的。
所以基本上我们会取整个空间，然后根据预算线性采样它们。
在各种设置中，我们实际上已经尝试过学习这些特征。
所以你实际上可以用它们初始化一个数组，然后学习它们。
这有时确实有帮助。
你也可以尝试在这方面使用更复杂的策略。
好的，很酷。
我接下来的问题基本上是，我觉得你们研究的卖点在于你们不做任何结构性的假设。
你可以采用任何类型的格式。
然而，对于编码来说，维度不是会有所不同吗？比如说，如果是文本，就是1D。
如果是图像，就是2D。
如果是视频，就是3D。
那么，你有更多的点，位置编码会更多，对吗？
这样不会从本质上泄露输入的性质吗？
是的，的确会。
所以我完全同意这一点，你完全是对的。
在这个版本中，我们学习了位置编码，从那个角度来看，这是最纯粹的。
所以它基本上不提供有关地面真实空间结构的信息。
它给模型提供的是，当你进行学习位置编码时，它会说，例如，图像1上的点k与图像2上的点k之间存在对应关系。
所以这基本上是你可以给它的最少信息，同时仍然允许它弄清楚输入点之间的结构关系。
所以这是我们一直在努力推进的方向。
一般来说，给予架构你可以访问的地面真实结构信息，比如这个点位于2D的这个点，是有帮助的。
所以这里有几件事情。
从实际的角度来看，如果你想要好的结果，你需要利用这些东西，或者利用这些东西是有帮助的。
但我们确实希望朝着减少依赖这些东西的方向发展。
所以这基本上是我们正在积极探讨的事情。
好的，说得通。
谢谢。
所以我觉得她已经在聊天中发布了她的问题。
我也看到你举手了。
所以如果你想的话，可以试一试。
如果不想的话，我就念出问题来。
好的，我试试。
如果有不流畅的地方，请告诉我。
嗯，现在还好吗？
到目前为止还不错，是的。
哦，好的。
好的，很酷。
所以我很好奇，看着你所展示的感知器图表，它是一堆注意力层，对吧？
比如交叉注意力和自注意力。
我认为最近在视觉transformer的研究中有一个小趋势，试图在最后几层替换注意力，而不是使用注意力，将它们变成卷积以解决这种注意力扩展的问题，对吧，用一种不同的方式。
所以在这里，感知器架构试图使自注意力变得更廉价。
他们试图替换它，并且他们有点规避了这个问题。
所以我很好奇。
我见过两种方式的论文，有些试图做你引用的那些事情，还有一些也在尝试这样做。
在我看来，每个人总是有好的结果之类的。
我很好奇你是否认为有理由选择其中一种方法，或者你是否认为这种替代方法也很有前途，或者有没有理由，你知道，研究应该朝着某个方向进行？
是的，我认为，我心目中的主要取舍是在视觉文献之间，我认为，在这方面，它在这种混合和人们方面的发展简直是爆炸性增长。
是的。
他们是对的，在速度和性能的权衡的帕累托曲线上的确切位置。
但他们基本上主要关注于视觉特定的问题。
因此，计算机视觉社区本身通常不会将自己规范化到不适用于非视觉的事物。
所以你最终得到的是在视觉问题上非常高效，非常高性能的东西。
所以从那个角度来看，我认为这是一条非常重要的工作线。
那可能是正确的做事方式。
我们所追求的是尽可能通用的东西，同时还要具有一定的性能。
这种事情至关重要。
哦，抱歉打断你了。
请继续。
不，不，请你先说。
我本来想说，这种事情就像是很重要。
简单总结一下。
所以你觉得关注注意力很重要，因为对于自然语言处理来说那是至关重要的。
就像你不能只是在最后加一个卷积然后解决问题。
但是在视觉领域，也许你可以，而且这没关系。
这样理解对吗？
这只是其中的一部分。
视觉和自然语言处理并不是唯一的两个领域。
我们正在寻找的基本上是...
所以我们希望用这个来解决的问题包括事件型摄像头、细胞生物学、蛋白质等等，这些问题可能我们甚至没有正确的卷积归纳偏见来知道如何构建这些东西。
它们最终成为整个研究项目，比如基于网格的卷积工作。
哦，好的，谢谢。
我还有一个关于架构的问题。
我看到你有交叉注意力，然后是 Lita transformer，然后是交叉注意力，抱歉如果你说过我没注意到，那么...
我很好奇，如果你将这些层中的自注意力替换为交叉注意力，会对你的准确性产生什么影响？
这样做可行吗？
这是一个有效的问题吗？
是的，你可以修改这个模型，使其具有一定的层级结构，这样就会有多个阶段的丢失关注。
我们还没有将这个工作做好，但这并不意味着这不是一个好主意。
所以也许有一种正确的方法可以做到这一点，我们还没有想出来，对吧？
但这是我们尝试过的一点东西。
哦，很棒。
好的，非常感谢你。
我很感激。
是的，没问题。
好的，让我...
我们时间有限，所以也许我会直接跳过。
在我们时间不多之前，我至少想谈谈我们对这个架构所做的修改，以使其更普遍地工作。
我们在这里看到的第一个架构，基本感知器的问题之一是，它基本上适用于任意输入，但它设计为仅在分类或回归任务上作为输出时才能发挥作用。
所以基本上我们想看看我们是否可以使用相同的交叉注意力策略进行解码，结果证明你可以。
这是一种非常有效的方法，基本上是开箱即用。
所以我们的想法是，如果我们有我们的交叉注意力输入和自我注意力来进行处理，我们可以引入一组额外的查询。
这些基本上是给出您尝试解码的每个点的语义的查询。
我们将这些作为输入传递给另一个交叉注意力层，该层的配置基本上与编码器交叉注意力的配置相反。
所以现在查询可能是一个潜在的大问题，而键和值来自这个潜在的。
所以基本上这允许我们保留原始感知器的所有优点。
所以我们有一个线性扩展的编码器，我们有一个处理器阶段，这种潜在的自我注意力与输入大小无关。
现在我们有一个解码器，它保持解耦，但在输出大小方面具有线性扩展。
所以通过这样做，我们现在基本上可以将相同的方法应用于基本上的密集输出任务。
为了让你对其工作原理有所了解，直观地说，如果我们对这张小狗图片进行自动编码，基本上我们要做的就是进行编码处理，然后进行解码，我们获取与每个点相对应的查询，然后将其传递给解码器。
因此，我们可以查询其中一个点。
我们得到一个像素，然后查询另一个像素。
我们得到另一个像素点，一直查询到全部 10 000 个像素点。
就这样，我们就可以用它进行重建了。
而它最酷的地方在于，它开启了一系列新的应用。
因此，我们只需改变查询的工作方式，就能获得不同类型的输出结果。
So if we want to do something like multimodal auto encoding, where we have some of the outputs are videos, We use the same construction trick to get positions, that to get queries that are, have the relevant semantics for each of the points that we're decoding.
我们可以做到这一点，即使这些不同数据的大小基本相同。
因此，他们拥有的点的数量是相当多样的。
因此，在本文的多模态音频编码实验中，我们同时对视频、音频和标签进行了编码。<EOS
所以所有这些都只是被传递到它们的统一网络中，然后逐个解码。
但我们现在也可以通过在序列中的位置上加以约束来进行大规模语言建模。
我们可以通过基本上给出查询网络的任务的索引来进行多任务分类。
而且我们也可以通过传递输入特征以及位置来执行光流等操作。
所以我只是会快速跳到一些不同的地方 - 之后我可以与大家分享幻灯片供查看。
其中一些东西相当酷。
简单地说，我想谈谈语言和光流。
那么对于语言，基本上我们想要做的是看看是否可以使用这个来替代标记化。
为什么我们会关心去除标记化呢？
首先，我们主要使用标记化是因为transformer在序列长度方面的扩展性较差，而标记化将序列长度减少了约四分之一。
但是这会带来各种问题。
那么我们为什么要关心去除标记器呢？
首先，标记器在罕见词上的表现不佳。
所以，如果你比较基于字节的分解，像这样的输入序列的UTF-8编码，你会发现基本上是将内存中的点均匀分配给每个输入字符。
异常的是变音符，它们最终会将其分成两部分。
但是，如果你看一下句子片段的标记化，你会发现学到了pepper是一个标记，但jalapeno在这种情况下被分成了五个。
这基本上表示分配的容量取决于单词的稀有程度，这可能导致次优的编码。
它们还对微小的扰动很脆弱。
其中一个著名的例子是，如果你输入了，所以如果你玩过GPT-3，你会注意到输出对添加空格或在末尾省略空格的位置非常敏感，这基本上是因为空格最终可能会被分解成标记化的不同部分。
还有其他事情也可能发生在那里，但这是其中之一的原因。
最后，标记不会跨语言转移。
所以，如果你想要一个模型，即使没有任何调整，也可以同时用于许多不同的语言，分词器会成为这一点的障碍。
如果我们能够摆脱它们，这将简化流程。
这也会使事情变得不那么脆弱，然后希望能够导致更通用的模型。
所以我们进行大规模语言建模的方式与我在那个示意性自动编码实验中展示的方式相同。
所以我们屏蔽了大约15%的输入。
这是一种标准的魔术数字。
然后我们在每个被屏蔽的位置解码，我们要求模型解码这些位置被屏蔽的任何字符。
一旦我们有了这个模型，这就是我们进行预训练的方式。
然后我们可以通过用一个多任务解码器替换解码器来对其进行微调，该解码器接收我们在下游评估设置中使用的任务，并训练模型以基于每个任务重新构建逻辑。
好的，为了查看这个模型的性能，我们基本上首先将其与BERT-BASE进行比较。
这只是一个我们非常了解的可靠基准。
首先，通过比较两种具有匹配FLOP的模型，我们可以看到Perceiver IO和BERT BASE的性能相当。
你会看到这里有一个不同的权衡。
为了获得相同数量的FLOPS，基本上我们使感知者IO更深，这最终导致它具有更多的参数，但基于每个FLOPS来看，它的性能大致相同。
另一方面，如果我们从BERT中移除分词器并保持FLOPS不变，我们会看到深度中的参数数量急剧减少。
这是因为BERT随着序列长度的增加而扩展性相当差，因为它使用普通的Transformer。
但如果我们使用没有分词的感知者，我们可以看到在FLOPS计数时参数数量只是轻微减少，但性能几乎完全相同。
这意味着在这种设置下，感知者的性能基本相同，无论是否分词。
它学习了不同的策略。
它使用不同的参数，但基本上可以达到相同的性能。
然后，我们可以更多地借鉴在无分词器设置中发生的情况，我们看到我们也可以获得适度的性能提升。
我认为在语言设置中，查看所学到的注意力图也是有用的。
这里所可视化的基本上是对于每个潜变量，对于一些潜变量的子集，我们看它们在输入序列中关注的位置。
而其中一些最终是局部的，因此关注句子中的特定点。
其中一些是周期性的，因此它们看起来像是在序列上循环出现的点。
而其中一些看起来也像是挑选出句法特征，这非常好。
因此，它们基本上挑选出感叹号、大写字母或其他在序列开头非常有用且可解码的标点。
我们也可以基本上使用相同的架构来处理光流。
光流基本上是计算机视觉中一个重要的经典问题，给定视频中的一对帧，我们希望基本上追踪所有点。
因此，找出从一帧到另一帧的每个点的运动。
光流通常使用这些在底部显示的着色图像进行可视化。
而这基本上给你的是每个像素在每一点的速度的指示。
因此，你可以看到。
所以这里角色手里拿着的刀片向右移动，而她身后的这个生物则在向下移动。
所以光流存在一些问题，这使得它有趣可追溯。
一是它是一个密集的任务，基本上涉及到长距离的对应关系，但是标准的训练协议中，基本上没有大规模真实的训练数据，只是因为在真实场景中标记所有像素并弄清它们去向是非常困难的。
所以通常的做法是在一些合成数据上进行训练，然后在更真实的场景中进行评估。
光流也很有趣，因为它基本上是文献中一些最复杂的视觉架构的轨迹。
所以先前的最先进结果是这种方法称为 RAFT，它在去年的 DCCV 上获得了最佳论文奖。
我只是强调这一点，让你了解人们在手工设计这些架构方面投入了多少工作。
所以这是一个非常巧妙设计的架构。
基本上它包含了诸如全局相关体积之类的东西，这些体积是明确地在不同偏移处计算的，从而使模型能够推理不同尺度的东西是如何相互移动的。
它还具有本地邻域聚集操作以及更新块，以跟踪每个特定相关块中发生的情况。
最后，还开发了一些针对流的特定上采样运算符。
所以与此相反，基本上，我们想看看 Perceiver IO 在这里能做多好。
只是为了让你对我们进入这个领域的期望有所了解，我们认为，也许 Perceiver IO 会放弃很多结构。
所以我们希望我们能得到一些好的结果，但可能会出现过拟合的情况。
在这里正在发生的是领域转移的问题。
但另一方面，自注意力似乎是一种合理的方法来匹配这种对应关系。
我们实际上发现，仅通过在这里进行非常非常简单的预处理，即基本上提取每个像素周围的一个补丁，然后使用标准的 Perceiver IO 架构，我们就能够获得最先进的结果。
所以这基本上是对这种通用方法的验证，试图拥有通用的架构，可以进行迁移。
所以基本上，只需进行最小的调整，我们就能够获得比两种引人注目的基准测试都更好的结果，无论是在Cintel评估方法的两种情况下，还是在KITTI上获得可比较的结果。
所以这些是标准的。
我们还可以在实际世界数据上应用这一方法时，看到发生了什么。
这里没有地面真实情况，所以我们无法真正进行比较，但仍然有用，可以看到它如何移动。
我们可以看到，从定性上讲，它能够捕捉到很多细微的结构，并能够正确地捕捉那些明显朝特定方向移动的物体的运动。
我们还可以，我认为，看一下它是如何设法表示小结构的。
这个视频正在播放吗？
是的，我们能看到。
好的。
所以要注意的是这里的细小水滴，它们在鸟飞过时在空中飞扬。
由于我们在每个输出点都进行解码，所以这种架构能够表示这些。
因此，它能够捕获非常非常细微的细分，如果在这里使用卷积上采样器，将很难捕获。
好吧，所以我只是要...
这个房间的灯灭了。
我也很好奇，您是否还尝试过其他任务，比如深度估计？
因为Persevere看起来在那种模态上也可以工作得很好。
是的，所以我们还没有发表任何东西，但一些内部结果表明它工作得很好。
基本上，似乎没有，有一件令人惊讶的事情，我们有点不确定的是这个潜变量中会包含多少信息，因为基本上您在抽象化很多东西，它本质上没有任何2D结构。
但它似乎能够很好地表示事物。
这些解码机制似乎也能够做到这一点。
明白了。
所以我只是，出于时间的考虑，我要跳到结论。
德鲁，关于您分享的光流指标，我有一个问题，数字。
所以在表格中，它是像中心，最终，干净和kitty。
这些是不同的数据集还是不同的度量标准？
是相同的度量标准应用在不同的数据集上，还是说这是三种不同的度量标准？
是的，这些是三个不同的数据集。
所以Sintel clean和Sintel final基本上是两种，它们是对Sintel进行最终渲染的两种方式。
在所有情况下，这些方法都是只在autoflow数据集上进行训练的。
所以它们是在这种通用类型的古怪合成动作数据集上进行训练的。
然后我们在这些不同的要求上进行评估，而没有进行微调。
好的。
是的，流量的数据集非常小。
因此，微调通常是有问题的。
谢谢。
好的，所以简单总结一下。
找到端点误差的基本真相是什么？
是的，这是怎么回事，Cintel是一台计算机。
它基本上是一部相对高质量的CGI电影，基本上是开源的。
因此，他们实际上有基本真相。
所以如果你知道基本真相的3D状态，你可以计算从帧到帧的像素对应关系。
这就是在Sintel上使用的方法。
然后KITTI，它们基本上有，他们有一个用于确定所有点深度的激光雷达传感器。
然后他们计算对应关系。
所以实际上地面真实情况是地面真实的光流，但总的来说，获得密集的光流是很困难的。
收集它非常昂贵。
好的，谢谢。
好的，所以基本上，简而言之，感知器是基于注意力的架构，其规模线性扩展，并且可以在各种设置上作为transformer的替代品。
它们似乎还能够在性能上至少与依赖于2D卷积的模型相媲美。
但当然，在这里存在一个权衡，因此在一般性与特定领域的速度之间需要非常注意。
所以，正如在可以使用2D卷积的环境中所指出的，在这些情况下，将其纳入考虑当然是明智的。
它基本上是一种统一的架构，允许联合建模不同尺寸和不同模态的数据。
总的来说，它似乎是一种非常灵活的架构，能够在各种不同领域产生最先进或接近最先进的结果。 
在这两篇论文中，我们研究了许多我没有谈到的其他领域，包括3D点云建模，替换星际争霸中用于行为克隆代理的transformer以及其他一些领域。
所以，我们有很多证据表明这种通用方法似乎在广泛范围内奏效。
还有很多事情我们仍然没有尝试过。
所以我们非常愿意推动这个方向，并时刻为建议敞开大门等。
所以我们依赖于大量的相关工作，因为我们在这里汲取了许多不同领域的知识。
这里是一些亮点。
然后我想要感谢我在这项工作中的合著者们。
当然，我很乐意更深入地交流。
谢谢。
是的，非常感谢。
谢谢您，先生。
我有一个问题，您认为感知器模型的未来会如何？
您认为这会在转换社区中更多地被用来替代像ConnNet等模型吗？
是的，所以我认为，广义而言，我现在将感知器视为一种，在我们对如何构建架构、归纳偏差的正确方式没有很好的想法的领域，我们知道如何将它们相当好地调整的东西。
所以我认为这是其中一个非常强有力的案例。
所以在你真的不知道如何正确构造问题的情况下。
我还认为这些方法可以与配置网络结合使用，用于那些尽可能领域无关的事物。
但我认为多模态和新领域确实是，那是真正的，那是这些明显的选择的地方。
明白了。
另外，你觉得目前存在的瓶颈是什么？
如果你不介意，你能透露一下，你接下来在这方面的工作是什么吗？
所以我不能太多地谈论那方面的细节。
但是，有几个领域。
所以其中一个，我们真的不知道如何在一些小规模数据上使用它们。
所以在数据上，你没有数据来恢复归纳偏差。
所以我认为这是一个非常重要的领域。
我们还没有讨论过的另一件事是，你可能可以想象，我们会考虑如何同时训练多种模式或多种东西。
所以现在，所有这些架构都是孤立训练的，但是有很多机会去想出如何一起提出问题，并在所有这些问题上使用单一架构。
明白了。
另外，我不确定你是否尝试过，但你也可以用这个来处理表格数据之类的东西吗？
是的。
所以，实际上，这个架构把任何输入数据都视为表格数据。
所以我认为这确实是正确的思考方式。
很酷。
听起来不错。
谢谢你的讲话。
我将向学生们开放一般性问题。
那么，让我们开始录制吧。
