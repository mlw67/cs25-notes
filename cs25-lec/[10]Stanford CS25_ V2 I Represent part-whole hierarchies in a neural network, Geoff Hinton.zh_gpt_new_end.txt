在我们开始之前，我最近在斯坦福做了同样的演讲。
我建议邀请我的人，我可以只做一个演讲，两个观众群都可以来，但他们更喜欢两个单独的演讲。
所以如果你最近去过这个演讲，我建议你现在离开。
你不会学到任何新东西。
好的。
我要做的是将神经网络中的一些最新想法结合起来，试图解释神经网络如何表示部分-整体层次结构，而不违反神经元工作的基本原理。
我将用一个想象的系统来解释这些想法。
我开始为一个系统撰写设计文档，最后我决定设计文档本身已经相当有趣。
所以这只是虚拟的，不存在的东西。
现在有一点点已经存在了，但是我发现在想象系统的背景下很容易解释这些想法。
所以现在大多数研究神经网络的人都在做工程，他们并不真的在乎它是否完全符合大脑的工作原理。
他们并不试图理解大脑是如何工作的。
他们只是想要制造酷炫的技术。
所以在 ResNet 中有 100 层是可以接受的。
在卷积神经网络中，权重共享是可以的。
一些研究人员，尤其是计算神经科学家，调查神经网络，人工神经网络，试图理解大脑实际上是如何工作的。
我认为我们还有很多东西可以从大脑中学到。
而且我认为值得记住的是，大约半个世纪以来，使神经网络研究持续进行的唯一信念是，一定可以让这些东西学会复杂的事情，因为大脑可以。
因此，每个图像都有一个不同的解析树。
这就是图像中部分的孔的结构。
在真实的神经网络中，你不能动态地分配，你不能只是抓一堆神经元然后说，好的，现在你代表这个，因为你没有随机访问内存。
你不能随意设置神经元的权重。
一个神经元的功能由其连接确定，它们只会慢慢地改变，至少很可能是这样。
它们大部分时间是缓慢变化的。
所以问题是，如果你不能快速改变神经元的功能，你怎么表示动态解析树呢？
在符号 AI 中，这不是问题。
你只需获取一块内存，通常就是这样，然后说这将代表解析树中的一个节点，我将给它指针指向其他节点，指向表示其他节点的内存块，这样就没有问题。
大约五年的时间，我研究了一个叫做胶囊的理论，你会说，因为你不能动态分配神经元，所以你要提前分配它们。
所以我们将取一组神经元，并将它们分配给解析树中不同的可能节点。
对于大多数图像，这些神经元组中的大多数将保持沉默。
只有少数会处于活跃状态。
然后，那些活跃的神经元，我们必须动态地将它们连接到解析树中，因此我们必须有一种在这些神经元组之间进行路由的方式。
所以那就是胶囊理论，我有一些非常称职的人与我共同合作，他们实际上使它奏效了，但这是一场艰苦的战斗。
我认为有些想法是想要奏效的，有些想法是不想要奏效的，而胶囊理论介于其中。
像反向传播这样的东西只是想要奏效，你尝试一下，它们就奏效了。
还有其他一些想法我曾经提出过，它们就是不想要奏效。
胶囊理论介于其中，而我们成功了。
但是我现在有一个新理论，可以被看作是一种有趣的胶囊模型，其中每个胶囊都是普适的。
也就是说，每个胶囊不再专门用于特定类型的事物，而是每个胶囊可以代表任何类型的事物，但硬件仍然以胶囊的形式出现，有时也被称为嵌入。
因此，我将要讲述的想象系统被称为GLOM，在GLOM中，硬件被分配到列中，每个列包含图像小区域中正在发生的多个表示级别。
因此，在列内，您可能会有一个更低级别的表示，表示它是一个鼻孔，然后上一级可能会说它是一个鼻子，再上一级可能会说它是一张脸，再上一级可能会说它是一个人，最高级别可能会说它是一个派对。
这就是整个场景的情况。
表示部分整体层次结构的想法是使用这些不同级别的嵌入之间的一致性岛屿。
因此，在场景级别，即顶级别，您希望图像的每个小区域具有相同的嵌入，因为该区域是任何地方相同场景的一部分。
在对象级别，您希望属于对象的所有不同区域的嵌入都是相同的。
所以当你沿着这个层次结构向上走时，你正在努力使事物变得越来越相同，这就是你在消除冗余。
嵌入向量就像指针一样，嵌入向量是动态的。
它们是神经激活而不是神经权重，所以每个图像都可以有不同的嵌入向量是可以的。
这里有一张小图片。
如果你有一个一维的补丁行，这些是补丁的列，你会有类似于卷积神经网络的前端。
然后在前端之后，你会产生你最低层次的嵌入，告诉每个特定补丁中发生了什么。
所以那些底层的黑色箭头，它们都是不同的。
当然，这些嵌入是数千维的，也许在你的大脑中是数十万维。
所以一个二维向量是不够的，但至少我可以用方向来表示两个向量是否相同。
所以在最低层，所有的补丁都会有不同的表示。
但是在上一层，前两个补丁，它们可能是鼻孔的一部分，例如。
所以，是的，它们会有相同的嵌入。
但是再往上一级，前三个补丁可能是鼻子的一部分，所以它们都会有相同的嵌入。
请注意，即使图像中的内容非常不同，但在部分层面上，这三个红色向量都意味着相同的东西。
所以我们所做的是为表面上非常不同的东西获得相同的表示。
通过为不同的事物提供相同的表示，我们在图像中找到了空间的一致性。
而在对象级别上，你可能会有一个鼻子，然后是一个嘴巴，它们是同一张脸的一部分。
因此，所有这些向量都是相同的，而这个网络还没有安定下来产生一些看不见的层次。
所以，共识的岛屿是捕捉解析树的要点。
现在它们比解析树要强大一些。
它们可以捕捉诸如闭嘴之类的东西。
在某个层次上，关闭和嘴巴可以是不同的向量，但在更高的层次上，关闭和嘴巴可以有完全相同的向量，即闭嘴的向量，并且它们可以是分离的。
所以在这里你可以做比上下文无关文法更强大的事情，但基本上它是一个解析树。
如果你是一名物理学家，你可以将这些级别中的每一个看作是一个具有实值向量而不是二进制自旋的糖衣模型。
你可以将它们看作是级别之间的坐标变换，这使得问题变得更加复杂。
然后，这是一种多级糖衣模型，但是级别之间的相互作用非常复杂。
因为，例如，在上面的红色箭头和黑色箭头之间，你需要一个鼻子和脸之间的坐标变换。
但我们稍后会讲到这一点。
如果你不是物理学家，那就把这些都忽略掉，因为这并没有什么帮助。
所以我想开始，并且我想说，我猜，这对于自然语言课程尤其相关，因为你们中的一些人不是视觉人员，我要试图向你证明，坐标系不仅仅是笛卡尔发明的东西。
坐标系很早以前就是大脑发明的，并且我们使用坐标系来理解图像中发生的事情。
我还想证明图像的句法树在心理上是现实存在的。
所以我打算用一个任务来做这个，这个任务是我很久以前在1970年代发明的，事实上那时我还是一名研究生。
你们必须完成这个任务才能充分获益。
所以，我要你们想象一下，在你们面前的桌面上，有一个线框立方体。
它的方向是立方体的标准方向。
它就放在桌面上。
从你的角度看，它有一个前右下角和一个后左上角。
开始。
好的。
前面的右下角和其他四个角都放在桌面上。
而后左上角则位于穿过立方体中心的对角线的另一端。
好的，到目前为止一切顺利。
现在，我们要做的是旋转立方体，使这根手指停留在桌面上，而另一根手指垂直于桌面，就像这样。
这根手指不应该移动。
好的。
现在，我们把立方体放在了一个方向上，原来的对角线现在变成了垂直线。
而你所要做的就是用底部的手指，因为它还在桌面上，然后用底部的手指指向立方体的其他角。
所以，我希望你能真正做到这一点。
开始。<EOS
拿起你的底部手指，将你的顶部手指放在那条刚刚变成垂直的对角线的另一端，然后只是指向其他角落的位置。
而且幸运的是它是可以缩放的，所以大多数其他人不会看到你做了什么。
我可以看到有些人没有指向，这是很糟糕的。
所以大多数人会指出另外四个角落，最常见的回答是它们在这里、这里、这里和这里。
他们指出在那个轴的一半高度形成的正方形的四个角。
这是错误的，你可以想象。
而且很容易看出这是错误的，因为如果你想象一下正常方向的立方体并数一数角，那就有八个。
而这两个是其中的两个角。
那么其他两个角去哪了呢？
有一种理论是，当你旋转立方体时，离心力使它们飞到你的无意识中。
那不是一个很好的理论。
所以这里发生的是你不知道其他角在哪里，除非你是类似于晶体学家这样的人。
你可以想象立方体的一部分，但你只是无法想象其他角的结构，它们形成了什么结构。
而这个常见的回答，人们提出的四个角落形成一个正方形，实际上是在做一些非常奇怪的事情。
它试图，它在说，好吧，我不知道，我不知道一个立方体的位，但我对立方体的一些特性有了解。
我知道角落是四个一组的。
我知道一个立方体具有四重旋转对称性，两个面是镜像对称的，但是直角摆动。
所以人们做的是保持他们回答中立方体的对称性。
他们给出一个正方形中的四个角。
现在，如果他们这样做，实际上他们指出的是两个金字塔，每个金字塔都有一个正方形的底座，一个颠倒过来，它们底部相连。
所以你可以很容易地将其可视化。
这是一个以正方形为底的金字塔，下面黏着另一个。
所以现在你的两个手指成为了这两个金字塔的顶点。
有趣的是，通过这样做，你保留了立方体的对称性，却付出了相当激进的代价，那就是将面变成了顶点，将顶点变成了面。
如果你这样做，你指出的东西是一个八面体。
它有八个面和六个顶点。
而一个立方体有六个面和八个顶点。
所以为了保留你所了解的立方体的对称性，如果你这样做了，你已经做了一些非常激进的事情，这将面变成了顶点，顶点变成了面。
我应该向你展示答案的样子。
所以我要退后一步，试着找到足够的光线，也许你可以看到这个立方体。
这是一个立方体，你可以看到其他边围绕着中间形成一种锯齿状的环。
我有一个它的图片。
这些彩色的棒子是立方体的其他边，不接触你的指尖的那些边。
你的顶部手指连接到这些翻边的三个顶点，而你的底部手指连接到那里的最低三个顶点。
这就是一个立方体的样子。
这是你完全不了解的东西。
这只是一个完全不同的立方体模型。
它是如此不同，我会给它一个不同的名字。
我会叫它一个六面体。
要注意的是，六面体和立方体在概念上完全不同。
如果你把一个看作六面体，另一个看作立方体，你甚至不会知道它们中的一个是另一个。
这就像是一个倾斜的正方形和一个竖直的菱形之间的模糊性，但更强大，因为你对它不熟悉。
这证明了人们确实使用坐标系。
如果你用不同的坐标系来描述事物，我强迫你使用一个不同的坐标系，让对角线垂直，并要求你相对于该垂直轴来描述它，那么熟悉的事物就变得完全陌生。
当你相对于这个新的参照系看到它们时，它们就是完全不同的东西。
注意，像卷积神经网络这样的东西没有这种能力。
它们不能看着一个东西，然后对同一件事情有两种完全不同的内部表示。
我还向你展示了你进行解析。
在这里，我已经将其着色，所以你将其解析成我称之为“皇冠”的形状，这是三个朝上和向外倾斜的三角形瓣。
这是一个不同的解析。
同样的绿色瓣朝上倾斜并向外倾斜。
现在我们有一个向下倾斜并向外倾斜的红色瓣。
我们有一个中央矩形，你只是矩形的两端。
如果你意识到了这一点，那么我闭上你的眼睛问你，那里有任何平行的边吗？
你非常清楚那两条蓝边是平行的，而你通常意识不到其他任何平行的边，尽管你知道根据对称性，必须存在其他成对的边。
同样对于这个王冠。
如果你看到了这个王冠，然后我让你闭上眼睛，问你是否有平行的边，你看不到任何平行的边。
那是因为你用于这些翻边的坐标系与边不对齐。
只有当它们与你使用的坐标系对齐时，你才会注意到平行的边。
对于矩形来说，平行的边与坐标系对齐。
对于这些翻边，它们不对齐。
所以你知道那两条蓝边是平行的，但你并没有意识到其中一条绿边和一条红边是平行的。
所以这不像是尼克立立方体的歧义，当它翻转时，你会认为现实中的东西是不同的，事物在不同的深度。
这就像，下个周末我们将去拜访亲戚。
所以，如果你把下周末我们将要去看亲戚这句话，它可以意味着下周末，我们将要做的是去看亲戚。
或者它可以意味着下周末，我们将要做的就是去看亲戚。
现在这些是完全不同的意思。
它们恰巧具有相同的真实条件。
从真实条件的角度来看，它们的意思是一样的，因为如果你正在去看亲戚，那么你就是在去看亲戚。
这是一种歧义。
对世界上正在发生的事情没有异议，但是对句子的理解却完全不同。
所以这是上世纪70年代提出的。
这就是上世纪70年代的人工智能的样子。
这是对皇冠解释的一种结构描述。
所以你有各个部分在层次结构中的节点。
我还在弧上放了一些东西。
那个rwx是皇冠和瓣之间的关系，可以用矩阵表示。
它实际上是皇冠的固有参考系和瓣的固有参考系之间的关系。
请注意，如果我改变了我的观点，这一点都不会改变。
这种关系将成为神经网络权重的一个好选择。
因为您希望神经网络能够独立于视点地识别形状。
而且，rwv是关于形状的与视点无关的知识。
这里是锯齿状的解释。
这里还有另一种情况，我已经添加了重要的蓝色框中的内容。
它们是节点与观察者之间的关系。
这是更明确地说明。
冠的固有参考系与观察者（您的眼睛）的固有参考系之间的坐标变换就是rwv。
而那是一种完全不同的东西。
因为随着视点的改变，那也会改变。
事实上，随着视点的改变，所有这些蓝色框中的内容都以一种一致的方式一起改变。
而且有一个简单的关系，即如果你取rwv，然后将其乘以rwx，你就得到rxv。
所以您可以轻松地在结构描述中传播视点信息。
这就是我认为心理形象是什么。
而不是一堆像素，而是带有相关视点信息的结构描述。
这解释了很多关于心理图像的特性。
就像如果你想要用 rwx 这样的东西做推理，你会形成一个心理图像。
也就是说，你填补，你选择一个视角。
我想再做一个演示来说服你，解决心理想象问题时你总是选择一个视角。
所以我要给你另一个非常简单的心理想象问题，冒着超时的风险。
想象一下，你在一个特定的点上，然后你向东走了一英里，然后向北走了一英里，然后再向东走了一英里。
回到起点的方向是什么？
这不是一个很难的问题。
它有点向南，而且很大程度上是向西，对吧？
它不完全是西南方向，但它有点像西南方向。
现在，当你做这个任务时，你想象的是，从你的角度来看，你向东走了一英里，然后向北走了一英里，然后再向东走了一英里。
我告诉你你没有想象到的。
你没有想象你向东走了一英里，然后向北走了一英里，然后再向东走了一英里。
你本可以完美地解决这个问题，而不是把北方当作上方，但你选择了北方作为上方。
你也没有想象到这一点。
你向东走了一英里，然后向北走了一英里，然后再向东走了一英里。
而这你也没有想象到。
你向东走了一英里，然后向北走了一英里，以此类推。
你在特定比例、特定方向和特定位置上想象到了它。
你可以回答大致有多大以及其他相关问题。
这就是解决涉及事物之间关系的任务时，你形成心理图像的证据。
好了，关于心理想象就说这么多。
现在我将给你一个非常简要的对比学习介绍。
这是演讲中的一个完全脱节的部分，但我很快会再次回到主题。
在对比自我监督学习中，我们试图让图像的两个不同裁剪具有相同的表示。
很久以前，Becker 和 Hinton 的一篇论文中我们就是这样做的，用来发现图像中的低级连贯性，比如表面的连续性或表面的深度。
这一方法已经有了很大的改进，并且已被用于进行诸如分类之类的任务。
也就是说，您拿到一张图像，其中有一个明显的物体，然后您说，如果我截取包含该物体任意部分的图像，它应该与图像的另一部分包含该物体的截图具有相同的表示。
而这在过去几年里得到了很大的发展。
我要讲一下几年前由我在多伦多的团队开发的一个模型，名为Simclear，但还有很多其他模型，而且事情已经有所改进。
所以在Simclear中，您拿到一张图像X，然后取两个不同的截图，并对每个截图进行颜色失真处理。
这是为了防止它使用颜色直方图来表示它们是相同的。
所以你要搞乱颜色，这样它就不能简单地使用颜色了。
这样就得到了Xi tilde和XJ tilde。
然后，您将它们送入同一个神经网络F，然后得到一个表示H。
然后，您将表示H送入另一个神经网络，对其进行轻微的压缩。
它降到了低维度。
这是一个我不打算解释的额外复杂性，但它使它的性能更好一些。
您可以在不进行这项操作的情况下进行。
你得到了两个嵌入向量，Xi 和 ZJ，你的目标是最大化这些向量之间的一致性。
于是你开始尝试，你说，好的，让我们从随机神经网络开始，神经网络中的随机权重。
让我们取两个补丁，并让它们通过这些变换。
让我们尝试让 Xi 和 ZJ 相同。
所以让我们反向传播 I 的组件和 J 的组件之间的平方差异。嘿，突然之间，你发现一切都崩溃了。
对于每个图像，它总是会产生相同的 Xi 和 ZJ。
然后你意识到，嗯，这不是我所理解的一致性。
我的意思是，当你得到同一图像的两个裁剪时，它们应该是相同的，当你得到两个不同图像的裁剪时，它们应该是不同的。
否则，就没有真正的一致性，对吧？
所以你必须有负例。
你必须展示来自不同图像的裁剪，并说这些应该是不同的。
如果它们已经不同，你就不会试图让它们更加不同。
很容易让事物变得截然不同，但这不是你想要的。
你只是想确保它们足够不同，这样来自不同图像的作物不会被认为来自同一图像。
所以如果它们碰巧非常相似，你就将它们分开，这样就阻止了你的表示崩溃。
这就是对比学习，而且它运作得非常好。
所以你可以通过尝试最大化来自同一图像的两个图像补丁的表示之间的一致性来进行无监督学习。
在你这样做之后，你只需取图像补丁的表示并将其馈送到线性分类器中。
一堆权重，所以你将表示乘以一个权重矩阵，经过softmax处理并得到类标签。
然后通过梯度下降来训练它。
你会发现，这几乎和在标记的数据上训练一样好。
所以现在你唯一在标记的数据上训练的是最后的线性分类器。
之前的层是在未标记的数据上训练的，你成功地训练了表示而不需要标签。
现在这有一个问题。
它运行得非常好，但它确实混淆了对象和整个场景。
所以说，从同一场景中获取的两个不同的补丁应该在场景级别上获得相同的向量标签，因为它们来自同一场景。
但是，如果其中一个补丁包含物体A和B的部分，另一个补丁包含物体A和C的部分，该怎么办呢？
你真的不希望这两个补丁在物体级别上具有相同的表示。
所以我们必须区分这些不同级别的表示。
对于对比学习，如果你不使用任何形式的门控或注意力，那么实际上你在场景级别上进行学习。
我们希望在物体级别获得的表示，如果两个补丁都是来自物体A，则应该是相同的，但如果一个补丁来自物体A，另一个补丁来自物体B，则应该是不同的。
为了做到这一点，我们需要某种形式的注意力来决定它们是否真的来自同一物体。
因此，GLOM被设计用来做到这一点。
它旨在利用对比学习，并引入Transformer中的注意力，以便在事物不相同时不尝试说它们是相同的。
我在这一点上应该提到，你们大多数人应该对BERT很熟悉，你可以把输入BERT的单词片段想象成我在这里使用的图像块。
在BERT中，你有一个完整的列来表示相同的单词片段。
在BERT中，随着你上升，你得到的表示语义更丰富。
但是在BERT中，并没有尝试去获得像整个短语这样更大的表示。
我要谈论的是一种修改BERT的方法。
所以随着你上升，你会得到越来越大的一致性区域。
例如，经过几个层次之后，像 new 和 York 这样的东西将会有不同的 York 片段，假设它有两个不同的片段，如果是以类似 GLOM 的方式完成的，它们将会有完全相同的表示。
然后随着你再上升一层，New 的片段，好吧，New 可能是一个独立的事物，但是York 的片段将会有完全相同的表示。
它们将会有这种一致性区域，并且那将是一个复合事物的表示。
随着你的上升，你会得到这些表示越来越大的一致性区域。
而那将是一种更有用的BERT，因为它不是采用代表单词片段的向量，然后通过取每个组件的最大值将它们混合在一起，例如这样做就很疯狂，而是明确地在学习过程中形成部分-整体层次结构中较大部分的表示。
所以，在GLOM中我们追求的是一种比由于表面往往在图像的相邻区域具有相同深度和相同方向而引起的空间一致性更复杂的空间一致性。
我们追求的是这种空间一致性，即如果你在图像中找到一个嘴巴，找到一个鼻子，然后找到使脸的空间关系，那就是一种特定的一致性。
而我们想要通过无监督的方式去追求这种一致性，并且我们想要在图像中发现这种一致性。
在我更详细地介绍GLOM之前，我想先声明一下。
多年来，计算机视觉将视觉视为你得到的是均匀分辨率的静态图像，然后想要知道其中有什么。
但这并不是现实世界中视觉的工作方式。
在现实世界中，有这样一个外部循环，你要决定看哪里。
如果你是一个人或一个机器人，最好要聪明地做到这一点。
这给你提供了光学阵列的一个样本。
它将光学阵列，即传入的光，转化为视网膜图像。
在你的视网膜上，中间有高分辨率，边缘有低分辨率。
所以你专注于特定的细节，你永远不会以均匀分辨率处理整个图像。
你总是在专注于某些东西，并且处理你在高分辨率处注视的地方，而其他所有东西在更低的分辨率下处理，特别是在边缘处。
所以我将忽略所有关于如何决定看哪里以及如何组合来自不同注视的信息的复杂性，我只是说，让我们只谈论一下第一个注视或者是一个新的图像。
所以你看向某个地方，那么在第一个注视上会发生什么？
我们知道，大脑中相同的硬件将被重用于下一个注视，但让我们只考虑第一个注视。
所以最后，这是架构的一个图片。
这是单个位置的架构，就像 BERT 中的单个词片段一样。
它向你展示了多个帧发生了什么。 
所以GLOM实际上是为视频设计的，但我只谈论将其应用于静态图像。
那么你应该把静态图像看作是一个非常无聊的视频，其中帧彼此相同。
所以我向您展示了层次结构中的三个相邻层次，并向您展示了随时间发生的情况。
因此，如果您看中间层次，也许那是主要部分级别，看一下那个标有级别L的框，那就是第四帧，右手边的级别L框。
让我们问一下，该框的状态，该嵌入的状态是如何确定的。
所以在框内，我们将获得一个嵌入。
而嵌入将是对图像小区域的主要部分级别发生情况的表示。
在这个图中，级别L中的所有这些嵌入将始终专用于视网膜图像的相同区域。
好的，在右侧的级别L嵌入中，您可以看到有三个因素在那里确定它。
有绿色箭头，对于静态图像，绿色箭头相当无聊。
它只是在告诉您应该与级别L先前的状态相似，因此它只是进行时间积分。
蓝色箭头实际上是一个具有几个隐藏层的神经网络。
我只是在这里展示嵌入，而不是所有神经网络的层。
我们需要几个隐藏层来进行所需的坐标转换。
蓝色箭头基本上是在下一个时间步骤的下一级获取信息。
所以，在第三帧中，第L级减一可能表示我认为我可能是一个鼻孔。
嗯，如果你认为你可能是一个鼻孔，那么你在上一级预测的是一个鼻子。
而且，如果你有一个鼻孔的坐标框架，你可以预测鼻子的坐标框架。
也许不是完美的，但你对鼻子的方向、位置和比例有一个很好的主意。
所以，这个自下而上的神经网络是一个可以获取第L级减一的任何类型的部分的网络。
它可以获取一个鼻孔，但它也可以获取一个方向盘，并从方向盘预测汽车，并预测出你在上一级得到的东西。
红色箭头是一个自上而下的神经网络。
所以红色箭头是从整个脸预测鼻子。
而且，它也有几个隐藏层来进行坐标转换。
因为如果你知道脸部的坐标框架，你知道一个脸和一个鼻子之间的关系，而这将在那个自顶向下的神经网络的权重中，那么你就可以预测它是一个鼻子，以及鼻子的姿态是什么。
而所有这些都将在嵌入向量的活动中进行。
好的，现在所有这些都是发生在硬件的一个列中，所有这一切都关于图像的一个特定区域。
所以这与BERT中的一个单词片段非常相似。
你拥有所有这些层次的表示。
这有点令人困惑，这与BERT的关系是什么。
我会在最后给你一个长篇论文的引用，其中有一个关于这如何与BERT相关的整个部分。
但这很令人困惑，因为这有时间步长。
而这使得一切变得更加复杂。
好的，所以这些是决定级别和嵌入的三个因素。
但还有第四个因素，就在底部的黑色部分。
那就是不同位置交互的唯一方式。
而那是transformer的一个非常简化的形式。
如果你拿一个transformer，比如BERT，然后说，让我们使嵌入、键、查询和值都与彼此相同。
我们只有这一个向量。
所以现在，你所要做的就是让一列中的第L级嵌入与附近列中的第L级嵌入相同。
但是它将会被门控。
只有在它们已经相当相似的情况下，你才会尝试让它们相同。
所以注意力是如何工作的。
你取位置X的第L级嵌入，即L X。然后取附近位置Y的第L级嵌入，即L Y。
取标量积，进行指数运算，然后进行归一化。
换句话说，进行softmax操作。
这就给你一个权重，用于使L X与L Y相同的愿望。
因此，由邻居产生的输入是附近列的第L级嵌入的注意力加权平均值。
这是你得到的额外输入。
它试图让你与附近的事物达成一致。
这就是导致你得到这些一致性区域的原因。
回到这张图片。
我认为这是我们想要看到的。
我们得到对象级别的大一致性的原因是因为我们试图在那里达成一致。
我们试图学习从红色箭头到上一级的坐标变换，以及从绿色箭头到上一级的坐标变换，从而使我们达成一致。
现在，我们需要担心的一件事是，感知中的困难事物，在语言中并不那么糟糕，在视觉感知中可能更糟糕，因为存在很多歧义。
例如，如果我看着一张线描图，我看到一个圆圈。
嗯，一个圆圈可以是一个脸的右眼，或者可以是一个脸的左眼，或者可以是汽车的前轮或后轮。
一个圆圈可能是各种各样的东西。
我们希望消除圆圈的歧义。
并且有一长串使用诸如马尔可夫随机场之类的东西的工作。
在这里，我们需要马尔可夫随机场的一个变体，我称之为转换随机场，因为例如，可能是眼睛的东西和可能是嘴巴的东西之间的交互需要通过坐标变换来控制。
你知道，对于，让我们拿鼻子和嘴巴，因为那是我的标准东西。
如果你拿着可能是鼻子的东西，并且你想问，有没有人支持鼻子这个想法？
那么，你想做的是向附近的所有事物发送一条消息，询问它们是否具有支持我是鼻子这一想法所需的正确姿势和正确身份？
因此，例如，你想要从鼻子发送一条消息，你会向所有附近的位置发送一条消息，询问是否有一个嘴巴具有我通过鼻子的姿势预测得出的姿势，乘以鼻子和嘴之间的坐标变换，现在我可以预测嘴的姿势。
有没有人具有那个姿势认为它可能是一个嘴巴？
我想你可以看到，你将不得不发送很多不同的消息。
对于可能支持你的每种其他事物，你都需要发送不同的消息。
因此，你将需要一个多头transformer，并且它将执行这些坐标变换。
并且你必须在回程途中协调地进行逆变换，因为如果嘴巴支持你，它需要支持的是一个鼻子，并不是具有嘴巴姿势的鼻子，而是具有适当姿势的鼻子。
所以这将变得非常复杂。
你将会有 n 平方次交互，全部都会有坐标转换。
有另一种更简单的方法，称为哈夫变换，至少在你有一种表示模糊性的方式时，它会简单得多。
所以，与其直接部分之间的交互，比如鼻子和嘴巴，你要做的是让每个部分都去预测整体。
所以鼻子可以预测脸，它可以预测脸部的姿势，嘴巴也可以预测脸。
现在这些将会在 glom 的不同列中，但在 glom 的一列中，你会有一个鼻子预测脸。
在附近的一列中，你会有一个嘴巴预测脸，如果这确实是一个脸，那么这两个脸应该是一样的。
所以，当你对附近的事物进行注意力加权平均时，你所做的是得到对你的假设的支持的确认，我的意思是，假设在一列中你认为它是一个带有这个姿势的脸，那么它得到了附近列的支持，这些列从完全不同的数据中导出了完全相同的嵌入。
一个是从鼻子推导出来的，一个是从嘴巴推导出来的。
而这不需要任何动态路由。
因为嵌入始终指的是图像同一小块中正在发生的事情，在列内部没有路由，列之间有一点像路由，但它只是标准的transformer式注意力。
你只是试图同意类似的事物。
好的，所以这就是glom的工作方式。
而且一个大问题是，如果我看到一个圆，它可能是左眼，也可能是右眼，可能是汽车的前轮，也可能是汽车的后轮。
因为我对特定级别的特定补丁的嵌入必须能够代表任何东西，当我遇到模糊的东西时，我必须处理所有可能是其一部分的可能性。
所以，与其试图在零件级别解决歧义，我可以跳到上一个级别并在那里解决歧义，只需看看事物是否相同，这是一种更容易解决歧义的方式。
但这样做的代价是，我必须能够在上一个级别保留所有我得到的歧义。
现在事实证明你是可以做到的。
我们做过一个小小的玩具例子，你实际上可以保留这种歧义。
但这很困难。
这是神经网络擅长的事情。
所以如果你考虑上一级的嵌入，你有一堆神经元，它们的活动就是那个嵌入。
而你想要表示一个高度多模态的分布，比如可能是带有这种姿势的汽车，或者是带有那种姿势的汽车，或者是带有这种姿势的脸，或者是带有那种姿势的脸。
所有这些都是通过找到一个圈来进行的可能预测。
所以你必须表示所有这些。
问题是，神经网络能做到吗？
我认为它们必须是这样做的方式是，嵌入中的每个神经元代表着一个未归一化的对可能的身份和可能的姿势的对数概率分布，在可能的身份和可能的姿势的巨大空间的交叉乘积。
所以神经元是对该空间的一个相当模糊的对数概率分布。
当你激活神经元时，它所说的是，把这个对数概率分布加到你已经得到的东西中。
所以现在如果你有一堆对数概率分布，把它们全部加在一起，你就可以得到一个更加尖锐的对数概率分布。
当你求指数时，你会得到一个概率分布。
它变得非常尖锐。
所以在姿势和身份的这个联合空间中的非常模糊的基础函数，以及在该空间中的对数概率的基础函数可以结合起来产生明确的结论。
我认为这就是神经元表示事物的方式。
大多数人认为神经元是他们所代表的东西。
显然，在感知中，你必须处理不确定性。
因此，神经元必须擅长表示多模态分布。
这是我能想到的唯一方法。
这是一个相当弱的论点。
正是这个论点让乔姆斯基相信语言不是学习来的，因为他想不出语言是如何学习的。
我的观点是神经元必须使用这种表示，因为我想不出其他方法来做到这一点。
好的。
我之所以说了这么多是因为我有些激动，我有些超前了。
现在，你之所以可以这样做的原因，是因为在未归一化的对数概率空间中有这些非常模糊的分布，因为这些神经元都专门用于图像的一个小区域。
他们都试图表示图像区域中发生的事情。
所以你只是试图表示一件事情。
你并不是在尝试表示一些可能的对象集。
如果你试图表示一些可能的对象集，你会有一个可怕的绑定问题，而且你不能使用这些非常模糊的分布。
但是只要你知道，所有这些神经元，所有活跃的神经元，都指的是同一件事情，那么你就可以做交集。
你可以把对数概率分布加在一起，并交集它们表示的事物集合。
好的，我快接近结尾了。
像这样的系统该如何训练呢？
嗯，显然你可以像训练Bert那样训练它。
你可以进行端到端的深度训练。
对于GloM，我们训练玩具示例的方法是，你拿一张图像，然后将图像的一些区域剔除，然后让GloM在大约10次迭代中稳定下来，它试图填补图像中的最低级别表示，即图像中的最低级别嵌入。
然后它填补错误。
所以现在你通过时间反向传播那个错误，你在这个网络中通过时间反向传播。
所以它也会上下反向传播。
所以基本上你只是通过时间反向传播错误，因为填写了不正确的东西。
这基本上就是Bert训练的方式。
而你可以以相同的方式训练GloM。
但我还想在训练中加入一个额外的部分，以鼓励形成孤立的区块。
我们希望在更高层次鼓励形成相同向量的大区块。
你可以通过使用学习的信任来实现这一点。
所以如果你想象一下下一个时间步，如果你考虑嵌入是如何确定的，它是通过结合许多不同的因素来确定的。
在这个表示层面的上一个时间步中发生了什么？
在上一个时间步中的这个位置上发生了什么，但在下一个级别、在上一个级别下面，或在上一个级别上面呢？
还有，在相同层次的相邻位置上，在上一个时间步中发生了什么？
所有这些事情的加权平均被称为共识嵌入，这就是你用于下一个嵌入的东西。
我认为你可以看出，如果我们尝试构建自下而上的神经网络和自上而下的神经网络，如果我们试图使预测与共识一致，那么共识已经包含了来自附近位置的信息，因为注意力加权已经大致一致。
所以，通过试图使自上而下和自下而上的神经网络与共识一致，你试图使它们与附近的相似位置发生的情况一致。
这样你就会训练它形成岛屿。
这对神经科学家来说比自然语言处理的人更有趣，所以我将忽略掉这一点。
你可能会认为在对象级别复制所有这些嵌入是一种浪费。
所以，这个想法是在对象级别，会有大量的补丁，它们都有完全相同的向量表示。
这看起来像是一种浪费。
但实际上，生物学中充满了这样的事情。
你的所有细胞都有完全相同的DNA，所有器官的部分几乎都有相同的向量表达。
所以有很多复制发生在这里，以保持局部性。
这里的情况也是一样的。
实际上，当你就某种解释达成一致时，这种复制非常有用。
因为在你确定之前，你不知道哪些事情应该与其他事情相同。
所以，在每个位置上具有单独的向量来表示该对象级别上正在发生的事情，可以让你在逐渐定位时以明智的方式逐渐分割事物，这是非常灵活的。
这样做可以让你保留多种可能性。
而你所做的不太像是聚类。
你正在创建相同向量的聚类，而不是在固定数据中发现聚类。
因此，聚类时，你得到的是固定的数据，然后你发现这些聚类。
而在这里，每个层次的嵌入是可变的。
它们随时间变化。
它们由自顶向下和自底向上的输入以及来自附近位置的输入决定。
所以你所做的是形成聚类，而不是在固定数据中发现它们。
这具有略微不同的特点，并且可以更快地定位。
这种复制的另一个优点是你不希望在转换器的高层级中增加更多工作量。
但是你确实需要在更高层级进行更长的范围相互作用。
想必在最底层，你希望transformer中的互动是相当短距离的，并且它们可能是密集的。
当你到达更高层次时，你希望有更长距离的互动。
所以你可以让它们稀疏。
人们已经为鸟类系统做过类似的事情。
在这里，让它们稀疏很容易，因为你期望有大型岛屿。
所以你只需要看到一个大岛的一小块就知道那个岛的向量表示是什么样子的。
因此，随着你的层级提升，稀疏表示将会更有效地工作，如果你有这些大型的一致性岛屿。
所以这个想法是，随着你的层级提升，你会有更长距离和更稀疏的连接。
所以每个层级中的计算量是相同的。
简单总结一下，我展示了如何将神经网络的三个重要进展结合到GloM中。
我实际上没有谈论神经场。
而这对于自顶向下的网络是很重要的。
也许因为我有两分钟的空闲时间，我要回去简要提一下神经场。
当我训练那个自顶向下的神经网络时，我遇到了一个问题。
问题是，如果你看那些红色箭头和绿色箭头，它们是完全不同的。
但是如果你看到更高层次，即对象层次，所有这些向量都是相同的。
当然，在一个工程系统中，我想要在每个位置复制神经网络。
所以我在每个地方都使用完全相同的自上而下和自下而上的神经网络。
那么问题是，如何让相同的神经网络得到一个黑色箭头，有时产生一个红色箭头，有时产生一个绿色箭头，而它们有相当不同的方向呢？
即使面部向量在每个地方都是相同的，它怎么能在有鼻子的地方产生鼻子，在有嘴巴的地方产生嘴巴呢？
答案是，自上而下的神经网络不仅仅得到面部向量，它还得到产生部分向量的补丁的位置。
因此，应该得到红色向量的三个补丁与应该得到绿色向量的三个补丁的位置是不同的。
因此，如果我使用一个神经网络，它除了得到面部向量外，还得到位置作为输入，它可以做到这一点。
它可以获取编码在那个黑色向量中的面部姿势，可以获取图像中它正在预测下一层次的向量的位置，而且姿势是相对于图像的。
所以知道图像中的位置，知道整个脸部的姿势，它可以确定在那个位置需要预测脸的哪一部分。
所以在一个位置上，它可以预测，好的，那里应该有鼻子，然后它给你红色的向量。
在另一个位置，它可以预测从那个图像块的位置。
那里应该有嘴巴，所以它可以给你绿色的箭头。
因此，你可以在上一层获得相同的向量，以在下一层的不同位置预测不同的向量，只需给它正在预测的位置。
这就是神经场中发生的事情。
好。
现在，这是一个相当复杂的演讲。
关于这个演讲有一篇很长的论文存档，详细介绍了更多内容。
你可以把这个演讲看作是鼓励去阅读那篇论文。
我结束了。
恰好按时。
谢谢。
非常感谢。
