大家好。
欢迎来到CS25transformer联合V2。
这是2023年冬季在斯坦福举办的一门课程。
这门课程不是关于可以变成汽车的机器人，正如这张图片可能暗示的那样。
相反，它关于那些风靡全球、彻底改变了人工智能等领域的深度学习模型。
从自然语言处理开始，transformer已经被应用于计算机视觉、强化学习、生物学、机器人学等各个领域。
我们为您准备了一系列令人兴奋的视频，由一些非常引人入胜的演讲者带来，介绍他们如何将transformer应用于不同领域和领域的研究。
我们希望您会喜欢并从这些视频中学到东西。
所以，不多说了，让我们开始吧。
这是一场纯粹的导论讲座，我们将深入研究transformer的基本组成部分。
首先，让我们开始介绍讲师们。
所以对我来说，我目前在博士课程中有一个暂时的分歧。
我在一家机器人初创公司负责人工智能，并且我在一个机器人技术公司工作，因此我们正在研发一些通用用途的机器人，有点像机器人。
是的，我对机器人技术和构建高效学习算法非常热衷。
我的研究兴趣在于个人学习与改建，我在机器人领域有大量出版物。
我是康奈尔大学的本科生，这是一个美妙的地方，很高兴见到保罗。
所以我是史蒂文，目前是一年级的CSB演讲者。
克里斯在卡内基梅隆大学读的硕士，水印大学的本科。
主要从事自然语言处理研究，涉及语言和技术的任何内容。
但最近，我也开始对计算机视觉以及量子代数产生了更多兴趣，还有一些我为了好玩而做的事情。
很多音乐方面的东西，主要是钢琴。
一些自我推广，但我在我的Instagram、YouTube和TikTok上发布了很多内容，所以如果你们想看的话可以去看看。
我和我的朋友们也正在组建一个斯坦福钢琴俱乐部，所以如果有人感兴趣，可以给DM发送电子邮件获取详情。
除此之外，武术、健美和未来的戏剧、动漫，偶尔打游戏。
好的，很酷，是的。
所以我叫赖兰，不想谈论自己，我只想非常简要地说一下我非常兴奋能上这门课。
上次课程开设时我可能会在场，对不起教这门课，打扰了，上次我可能在场。
我玩得很开心。
我觉得上次我们请来了一群非常棒的讲师，对这次的开设我非常激动。
对了，感谢大家都来了，我期待我们一起度过一个非常愉快的季度。
谢谢。
对了，有趣的事实，Brandon是去年最直言不讳的学生，所以如果有人想要成为明年的助教，你知道我的意思。
是的，是的，是的。
好的，让我们看看，好的。
所以我们希望你们在这门课上学到的第一件事是，任务是如何如此多的工作的？
它们是如何被应用的，不只是会成为。
而如今，我们在 AI 机器学习中几乎无处不在。
这些主题中有一些新的交互或研究是什么？
很酷，所以这门课只是一个入门，我们将只谈论transformer的基础知识，介绍它们，谈论它们建立在自注意机制上，我们将更深入地研究像 BERT、GPT 等模型。
所以很棒，很高兴开始了。
好的，让我从介绍注意力时间线开始。
注意力始于2017年Vaswani等人发表的一篇论文，标题为《注意力就是你所需要的》。
那是transformer的开始。
在那之前，我们处于史前时代，我们拥有诸如RNN、LSTM之类的模型，还有一些简单的注意力机制，但效果不佳，也无法扩展。
从2017年开始，我们看到了transformer在自然语言处理领域的迅猛发展，人们开始将其用于各种用途。
我甚至听说过谷歌的一句话，我们的表现每次解雇语言学家时都会提高。
在过去的2018年，从2018年到2020年，我们看到了transformer向其他领域的扩展，如视觉、大量其他领域，以及生物学、酒精等等。在去年，2021年，是生成时代的开始，我们看到了大量的生成建模。
出现了像Codex、GPT、DALI、表扩散等模型，生成建模方面发生了很多事情，我们开始在人工智能领域扩展规模。
现在是现在，2022年初，现在我们有了像Chai GPT、Whisper等模型，还有很多其他的模型，我们在不断扩展而不是分裂。
所以这很棒。
所以这就是未来。
所以更深入地讲，一旦有了RNNs，我们就有了序列到序列模型，LSTM，GLU。
这里有效的是它们擅长编码历史，但不好的是它们不编码长序列，而且在编码上下文方面非常糟糕。
所以考虑这个例子，考虑尝试预测文本中的最后一个词，我在法国长大，点点点，我说一口流利的破折号。
在这里，你需要理解上下文才能预测出法语，就像注意机制非常擅长的那样，但是像你刚才用LSTMs一样，它根本不起作用。
transformer擅长的另一件事是更基于内容，就像上下文预测一样，就像找到注意力图。
如果我有像它这样的一个词，它与什么名词相关联？
我们可以给出可能激活的概率注意力，这比现有的机制更好。
好的，那么我们在2021年的位置上，我们正处于起飞的边缘。
我们开始意识到transformer在不同领域的潜力。
我们解决了许多长序列问题，比如蛋白质折叠，阿尔法折叠，离线RL。
我们开始看到了一些镜头，零射一般化，我们看到了多模态任务和应用，比如从语言生成图像。
所以那就是 Dali。
是的，感觉像亚洲，但那只是两年前的事情。
这也是一个关于transformer的讲座，你可以在 YouTube 上观看。
这就是我们从 2021 年到 2022 年的发展方向，从起飞的边缘到真正的起飞，现在我们看到了音频生成、艺术、音乐、故事等领域的独特应用。
我们开始看到推理能力，如常识、逻辑推理、数学推理，我们现在也能够获得人类的启示和互动。
他们能够使用强化学习和人类反馈。
这就是 Chai GPT 被训练成表现非常出色的方式。
我们现在有很多机制来控制毒性、偏见和伦理问题。
在其他领域也有很多发展，比如不同的模型。
所以未来就像一艘太空船，我们都对此感到兴奋。
我们还可以实现更多的应用。
如果你能看到transformer在那里也能发挥作用就太棒了。
一个大的例子是视频理解和捐赠。
那是每个人都感兴趣的事情。
而且我希望今年在这个领域能看到很多模型。
还有金融，商业。
我会非常兴奋地看到GPT作者创作小说，但我们需要解决非常长的序列建模问题，而大多数transformer模型仍然受限于大约4,000个令牌之类的限制。
所以我们需要让它们在长序列上更好地进行泛化。
我们还希望拥有可以进行多任务、多输入预测的通用化代理，就像Gato一样。
所以我认为我们也会看到更多这方面的内容。
最后，我们还想要领域特定的模型。
所以你可能想要一个擅长于像你的帮助这样的GPT模型。
那可能是像医生GPT模型。
你可能有一个大型的GPT模型，只涉及大量数据。
所以目前我们有像GPT模型这样的模型，它们可以应对一切，但我们可能会开始看到更多专注于一项任务的特定模型。
而且我们可以有像专家混合体这样的东西。
这就像你通常如何向专家咨询一样。
我们将拥有专业的人工智能模型，您可以针对不同的需求使用不同的人工智能模型。
目前仍然缺少许多要素，以使所有这些都取得成功。
首先是外部记忆。
我们已经开始看到这一点，但像GPT这样的模型感染是短暂的，没有长期记忆，并且它们没有记住对话以供长期存储的能力。
这是我们想要解决的问题。
其次是降低计算复杂性。
因此，注意力机制对于序列长度的复杂度是二次的，仅仅是学习。
我们希望在进行更快的计算时减少它。
我们想要做的另一件事是增强这些模型的可控性。
像很多这些模型可以是随机的，我们希望能够控制从它们得到什么样的输出。
您可能已经体验过GPT，如果您刷新，每次都会得到不同的输出，但您可能希望有机制来控制您得到的输出。
最后，我们希望将我们的最先进语言模型与人类大脑的工作方式相一致。
我们正在看到这方面的研究，但我们仍需要更多关于它们如何变得更重要的研究。
好的，谢谢。
嗨，是的，我很高兴能来这里。
我住得很近。
所以我收到邀请来上课，我就想，好吧，我就步行过去吧。
但后来我在那些幻灯片上花了大约10个小时。
所以事情没有那么简单。
所以是的，我想谈谈transformer。
我要跳过前面那两个。
我们不会讨论那些。
我们会讨论那个。
只是为了简化讲座，因为我们没有时间。
好，我想提供一点背景，为什么会有这种transformer成本存在？
所以有点历史背景。
我感觉像是边伯顿，我就像是告诉你们这个。
我不知道你们有没有看到饮料，基本上我是在2012年左右全力投入AI的。
也许是十年前。
当时你甚至不会说你加入了AI，顺便说一句，那时候是个不好的词。
现在可以谈论了，但当时甚至不是深度学习。
那时候是机器学习。
如果你是认真的，那就是你会用的术语。
但现在AI可以用了，我想。
基本上，你是否意识到你有多幸运可能进入这个领域并且大致上要去。
那时候大约在2011年左右，当我专门从事计算机视觉时，你的流程看起来是这样的。
所以你想要对一些图像进行分类。
你会去一篇论文，我认为这是代表性的。
在论文中，会有三页描述各种各样的厨房汇总不同类型特征描述符的动物园。
你会去计算机视觉会议上的海报展，每个人都会提出他们喜欢的特征描述符，这是完全荒谬的。
然后你会记录下你应该将哪个特征描述符纳入你的流程，因为你会提取所有的特征，然后在顶部放一个SVM。
这就是你会做的事情。
所以有两页。
确保你获取稀疏的SIP直方图，你的SSIMs，颜色直方图，纹理，小图像，别忘了几何特定的直方图。
所有这些基本上都有复杂的代码。
所以你从各处收集代码并运行它，这是一场彻底的噩梦。
除此之外，它还不起作用。
所以我认为，这代表了当时的预测。
你偶尔会得到这样的预测，然后你会像这样耸耸肩，就像偶尔会发生这样的事情一样。
今天，你会在寻找一个错误。
比那更糟糕的是，每一个AI领域都有它们自己完全独立的词汇表。
所以，如果你去看自然语言处理的论文，那些论文会完全不同。
所以你读着自然语言处理的论文，然后你就会想，什么是词性标注，形态分析，句法分析，共指解析，什么是NP，BT，JJA，还有你的计算？
所以词汇和一切都完全不同，你无法跨不同领域阅读论文。
所以从2012年开始，这一点有所改变，当时Alex Kuchevsky和他的同事们基本上证明了，如果你在大型数据集上扩展大型神经网络，你可以得到非常强大的性能。
到那时为止，人们非常关注算法，但这表明神经网络实际上扩展得非常好。
所以现在你需要担心的是计算和数据，如果你将其扩展起来，它的效果相当不错。
然后，这个配方实际上在许多 AI 领域都被复制粘贴了。
所以，自 2012 年以来，我们开始看到神经网络在各个领域不断涌现。
因此，我们在计算机视觉、自然语言处理、语音识别、翻译、强化学习等领域都看到了它们的身影。
所以，每个人开始使用相同类型的建模工具、建模框架。
现在当你进入自然语言处理领域开始阅读论文时，例如机器翻译，这是一篇序列到序列的论文，我们稍后会回到这个话题。
你开始阅读这些论文，你会发现，好的，我能认出这些词。
就像有一个神经网络，有一个参数，有一个优化器，它开始读起来像你所熟悉的东西。
因此，这极大地降低了进入不同领域的门槛。
然后我认为重要的是，当 transformer 在 2017 年出现时，重要的不仅仅是工具包和神经网络相似，而且是网络架构实际上收敛到了一种架构，你可以在各个领域随意复制粘贴。
因此，在当时，这其实是一篇关于 transformer 架构的并不起眼的机器翻译论文。
但我们自那时以来发现，你基本上可以复制粘贴这个架构，然后在任何地方使用它。
而且变化的是数据的细节和数据的分块以及如何输入它们。
虽然这是个夸张的说法，但它基本上是正确的第一顺序陈述。
所以现在论文看起来更加相似，因为每个人都在使用transformer。
这种趋同是令人瞩目的，是在过去十年里逐渐展开的。
对我来说，这相当疯狂。
我觉得有点有趣的是，我认为这是一种暗示，可能我们正在朝着大脑的某种功能收敛，因为大脑在整个皮层上非常均匀。
好吧，也许一些细节在改变，但这些感觉像是超参数，就像一个transformer一样，但你的听觉皮层和视觉皮层以及其他一切看起来非常相似。
所以也许我们正在朝着某种统一的、强大的学习算法收敛，之类的东西。
我觉得这很有趣。
好的，所以我想简要地谈谈transformer的历史来源。
所以我想从2003年开始。
我相当喜欢这篇论文。
这是神经网络首次在语言建模问题上得到广泛应用。
因此，在这种情况下，是在预测序列中的下一个单词，这使得您可以构建文本上的生成模型。
而在这种情况下，他们使用的是多层感知器。
所以非常简单的神经网络。
神经网络接收三个词并预测序列中第四个词的概率分布。
所以到这一点上一切都很好。
现在，随着时间的推移，人们开始将这个应用于机器翻译。
这就引出了2014年的序列到序列论文。
那是相当有影响力的。
这里的一个大问题是，好吧，我们不只是想拿三个词来预测第四个。
我们想要预测如何从一个英文句子翻译成一个法文句子。
关键问题是，好吧，您可以有任意数量的英文单词和任意数量的法文单词。
那么，如何设计一个能够处理这种可变大小输入的架构呢？
所以在这里他们使用了一个LSTM，基本上有两个部分被这个戳覆盖了，但基本上左边有一个编码器LSTM。
而它只是逐字逐字地消耗，逐渐建立起它所读内容的上下文。
然后，这充当解码器RNN或LSTM的调节向量，基本上为序列中的下一个词进行分块翻译，将英语翻译成法语或类似的语言。
现在，人们发现了这个方法的一个大问题，我认为很快就试图解决，那就是有一个叫做编码器瓶颈的东西。
因此，我们试图在这个整个英语句子上进行条件处理，将其压缩成一个从编码器传到解码器的单一向量。
这就是单一向量可能维护的信息量太大的问题。
这似乎并不正确。
于是，人们四处寻找方法来缓解这个注意力，抱歉，那时被称为编码器瓶颈的问题。
于是，这就引出了这篇论文，通过共同学习对齐和翻译进行神经机器翻译。
在这里，仅仅引用摘要中的内容，在本文中，我们猜想使用固定长度的向量会成为改进基本编码器解码器架构性能的瓶颈，并建议通过允许模型自动软搜索源句子中与预测目标词相关的部分来扩展这一点，而无需显式地形成这些部分或硬分割。
所以这是一种回顾来自编码器的单词的方法。
通过使用这种软搜索实现了这一点。
所以当你在这里解码单词时，在解码它们的同时，你可以通过本文提出的软注意机制回顾编码器中的单词。
所以这篇论文，我认为是我第一次基本上看到了注意力。
所以来自编码器的上下文向量是编码时单词的隐藏状态的加权和。
然后，这个和的权重来自一个基于当前解码状态和编码器生成的隐藏状态之间的兼容性的 softmax。
所以这是第一次你真的开始看它，并且这是注意力的当前现代方程。
我认为这是我第一次看到这篇论文。
据我所知，这是第一次使用注意力机制这个词。
所以我实际上试图深入了解注意力机制的历史细节。
这里的第一作者，迪米特里，我和他进行了邮件往来，基本上我给他发了封邮件。
我说，迪米特里，这真的很有趣。
transformer已经取得了成功。
你是怎么想出软注意力机制的，它最终成为transformer的核心呢？
令我惊讶的是，他给我回了一封非常有趣的长邮件。
这是那封邮件的一部分摘录。
所以基本上他谈到了他是如何寻找一种避免编码器和解码器之间瓶颈的方法的。
他有一些关于遍历序列的光标的想法，但并没有完全奏效。
然后在这里，有一天我突然想到，让解码器 RNN 学会如何搜索，把光标放在源序列中的哪里会很好。
这在某种程度上是受到了我中学时学习英语的翻译练习的启发。
你的目光在翻译时不断在源序列和目标序列之间移动。
所以从字面上看，我觉得这很有趣，他不是以英语为母语，但在这里，这给了他在这个机器翻译中的优势，引起了注意，然后引导到了Transformer。
所以这真的很迷人。
我将软查找表达为softmax和二进制状态的加权平均。
基本上令我非常激动的是，这在第一次尝试时就成功了。
所以我真的认为这是有趣的历史片段。
后来事实证明，循环神经网络搜索的名称有些平淡无奇。
所以更好的名称“注意力”是在一次最终的修订中由Yoshua提出的。
也许“注意力就是你所需要的”本来会被称为循环神经网络搜索，但我们要感谢Yoshua Bengio提出了稍微好一点的名字。
所以显然这就是这样的历史。
好的，这将我们带到了2017年，“注意力就是你所需要的”。
在Dimitri的论文中，这个注意力组件只是一个小部分，还有所有这些双向RNN和解码器，而这个只有注意力的论文则表示，好吧，你实际上可以删除所有的东西。
就是注意力本身使这项工作非常出色。
所以删除一切，保留注意力。
而且这篇论文的显著之处实际上是通常你会看到非常渐进的论文。
它们添加一样东西，然后证明这样做更好，但我觉得注意力是你需要的全部，它是多个因素的混合物。
它们以一种非常独特的方式结合在一起，同时在架构空间中也达到了一个非常好的局部最小值。
所以对我来说，这是一篇非常值得注意的里程碑论文。
我认为在幕后有相当多的工作。
所以删除所有的循环神经网络，只保留注意力，因为注意力是针对集合操作的。
我马上就会深入讨论这一点。
现在你需要对输入进行位置编码，因为注意力没有空间的概念。
所以他们应该非常小心。
他们采用了ResNets的残差网络结构。
他们将注意力与多层感知器交错使用。
他们使用了来自另一篇论文的层归一化的概念。
他们引入了多头注意力的概念，这些注意力是并行应用的。
他们给了我们，我认为是一个相当不错的一组超参数，直到今天仍在使用。
所以多层感知器中的扩张因子增加了4倍，我们将会更详细地讨论。
而这个4倍一直保持不变。
我相信有很多论文尝试过玩各种细节，尝试改进Transformer的各种小细节，但没有什么像这个一样好。
据我所知，唯一没有保持下来的是将层归一化的重新排列，进入预归一化版本，在这里你可以看到层归一化是在多头注意力重复前进行的，但他们只是在前面放置了它们。
所以只是层归一化的重新排列，但除此之外，GPT和今天看到的其他一切基本上都是五年前的2017年架构。
即使每个人都在研究它，它仍然证明是非常有韧性的，我认为这很有趣。
我认为有一些创新在位置编码中也得到了采纳。
更常见的是使用不同的旋转和相对位置编码等。
所以我认为有一些变化，但在大多数情况下，它仍然非常有韧性。
所以确实是一篇非常有趣的论文。
现在我想要深入讲解注意力机制。
而且我觉得我解释的方式与之前我见过的不太相似。
所以让我尝试以不同的方式来表达我对它的理解。
基本上对我来说，注意力就像是transformer的通信阶段，而transformer交织着两个阶段，通信阶段，即多头注意力，和计算阶段，即这个多层感知器或P-twim。
因此，在通信阶段，它实际上只是在有向图上进行数据相关的消息传递。
你可以将它看作是，好吧，忘记一切与机器翻译有关的东西。
让我们假设，我们在每个节点上都有有向图，你在其中存储一个向量。
然后现在让我谈谈关于这些向量在有向图中如何相互交流的通信阶段。
然后稍后的计算阶段只是多层感知器，它现在基本上是在每个节点上独立操作的。
但是在这个有向图中，这些节点如何相互交流呢？
所以我写了一些简单的Python代码，基本上我用Python写了这个，以创建使用注意力作为直接传递方案的一轮通信。
所以这里，一个节点有这个私有数据向量，你可以把它想象成是这个节点的私有信息。
然后它还可以发出一个键、一个查询和一个值。
简单地说，这是通过对这个节点进行线性变换来完成的。
所以关键是，我正在寻找的东西之一，抱歉，查询就是我正在寻找的东西之一。
关键是我拥有的东西之一，而值是我将要传达的东西之一。
当你的图由一些随机边组成的节点组成时，当你实际上让这些节点通信时，发生的情况是你以一些随机顺序单独地循环遍历所有节点，并且你在某个节点上，你得到查询向量Q，这是我在某个图中的一个节点，这是我正在寻找的东西。
所以这只是通过这里的线性变换来实现的。
然后我们看一下指向这个节点的所有输入，然后它们广播，我有什么东西，就是它们的键。
所以它们广播密钥，我有查询，然后它们通过点积相互作用以获得范围。
所以基本上通过做点积，你得到了指向我的所有信息以及我寻找的事物的趣味性的未归一化权重。
然后当你用 softmax 对其进行归一化，使其总和为一，你基本上就是使用那些分数，这些分数现在在我们的概率分布中总和为一，然后你对值进行加权求和以获得更新。
所以我有一个查询，它们有一些关键词，点积得到趣味性或者说亲和力，用 softmax 进行归一化，然后对这些值进行加权求和，流向我并更新我。
而且这是针对每个节点单独进行的，然后我们在最后进行更新。
这种消息传递方案在transformer的核心发生，以一种更矢量化、批处理的方式进行，这种方式更加令人困惑，同时还与层归一化等内容交替进行，以使训练表现更好。
但从高层次来看，这大致就是注意力机制中发生的事情。
所以，在transformer的通信阶段，这种消息传递方案在每个头部并行进行，然后在每个层中串行进行，并且每次都有不同的权重。
至于多头注意力，就是这样。
所以，如果你看这些编码器解码器模型，你可以把它看作是图中这些节点的连接方式，你可以想象，所有这些在编码器中的我们想要条件的标记，它们彼此之间是完全相连的。
所以当它们交流时，它们在计算其特征时是完全交流的。
但是在解码器中，因为我们试图构建一个语言模型，我们不希望未来的标记传递信息，因为它们在这一步暴露了答案。
所以解码器中的标记是从所有编码器状态完全连接过来的，然后它们也是从它们之前的所有内容完全连接过来的。
所以你最终得到的是这样一个有向图中的三角结构。
但这就是这个基本上实现的消息传递方案。
然后你也必须小心一点，因为在这里解码器的交叉注意力中，你消耗了来自编码器顶部的特征。
所以在编码器中，所有节点都在彼此观察，所有标记都在很多次观察彼此，他们真的弄清楚了里面有什么。
然后在解码器中，它只看顶部节点。
所以这大致是消息传递的方案。
我本来要深入讲一下transformer的实现。
我不知道有没有关于这个的任何问题。
这里涉及到了一点自注意力和多头注意力，但是它们有什么优势呢？
是的，自注意力和多头注意力。
多头注意力就是这个注意力方案，只是并行应用了多次。
多头表示相同注意力的独立应用。
所以这个消息传递方案基本上是并行多次进行的，对查询键和值使用不同的权重。
你可以差不多把它看作是在并行中，我正在寻找、从不同的节点中获取不同类型的信息，然后我把这些信息都收集到同一个节点中。
一切都是并行进行的。
所以头部实际上就像是在并行中复制粘贴，而层级则是复制粘贴，但是是串行的。
也许这样说有道理。
而自注意力，当它是自注意力时，它指的是这个节点在这里产生每个节点。
所以正如我在这里描述的那样，这实际上是自注意力，因为这些节点中的每一个都产生了一个来自这个单独节点的关键查询和一个值。
当你有交叉注意力时，你在这里有一个来自编码器的交叉注意力。
这只是意味着查询仍然是从这个节点产生的，但是键和值是作为来自编码器的节点的函数产生的。
所以我有我的查询，因为我正在尝试解码一些东西，序列中的第五个单词。
因为我是第五个单词，所以我在寻找某些东西。
然后，以能够回答我的查询的信息来源的形式，键和值可以来自当前解码序列中的前面节点或来自编码器的顶部。
所以所有已经多次看到所有编码标记的节点现在都可以广播它们包含的信息。
所以我猜总结一下自我注意力有点像，抱歉，交叉注意力和自我注意力只在键和值来自哪里方面有所不同。
无论是键和值是从这个节点产生的，还是它们是从一些外部来源产生的，比如编码器和那边的节点。
但从算法上讲是一样的，Michael。
所以第一个问题有两个方面，嵌套容量图范式中的层次结构是什么？- 是的，是的 - 什么样的要点？
所以想想，所以这些节点中的每一个都是一个标记。
我猜，他们对transformer的情况没有很清楚的认识，但是像这个节点可以代表解码器中的第三个输出词。
一开始，它只是单词的嵌入。
然后，好吧，我得再仔细想想这个知识。
我今天早上想出来的。
实际上，我昨天想出来的。
我们对此有另一个问题。
图的一个实例将会提供一个良好的直觉，因为节点已经丢失在单词嵌入中了吗？
这些节点基本上就是向量。
我会去实现一下。
我会去执行，然后也许我会将它们连接到图中。
所以让我首先尝试去，至少现在让我去，根据这个直觉，去nano GPT，这是一个基于图的图。
这是一个非常简单的transformer的完整实现。
所以我在过去几天里一直在研究这个，这里它正在复现GPT-2在开放网络文本上的表现。
因此，我可以说，这是一个相当严肃的实现，它重现了 GPT -2，并提供了足够的计算能力。
如果我没记错的话，这是一个由八个 GPU 组成的节点，持续了 38 个小时左右。
而且可读性很强，有 300 行。
大家可以看一看。
是的，让我简要地介绍一下。
所以，让我们尝试使用一个仅有解码器的transformer。
所以，这意味着它是一个语言模型。
它试图模拟序列中的下一个单词或序列中的下一个字符。
因此，我们训练的数据总是某种文本。
因此，这里有一些假莎士比亚。
对不起，这是真的莎士比亚。
我们要制作一个假莎士比亚。
这就是所谓的小莎士比亚数据集，这是我最喜欢的玩具数据集之一。
你可以把所有莎士比亚的作品串联起来，形成一个一兆字节的文件，然后你就可以在上面训练语言模型，得到无限的莎士比亚，如果你喜欢的话，我觉得这很酷。
所以我们有一个文本。
我们需要做的第一件事是将其转换为整数序列，因为转换器是原生处理的，你无法将文本插入转换器。<EOS
你需要以某种方式对其进行编码。
因此，编码的方式是我们将，例如，在最简单的情况下，每个字符都转换为一个整数。
然后，我们不再是“hi there”，而是会得到这个整数序列。
然后，你可以将每个单独的字符编码为一个整数，并得到一个庞大的整数序列。
你只需将其全部连接成一个大的、长的、一维的序列，然后就可以对其进行训练。
现在，在这里，我们只有一个单一的文档。
在某些情况下，如果你有多个独立的文档，人们喜欢创建特殊的标记，并将这些文档与这些特殊的文本结束标记交错，这样它们就在中间创建了边界。
但是这些边界实际上并没有任何建模的影响。
只是transformer应该通过反向传播学习，文档结束序列意味着你应该清除记忆。
好的，然后我们生成批次。
这些数据批次意味着我们回到了一维序列，并从这个序列中取出一些块。
比如说，如果块的大小是八，那么块的大小就表示你的transformer将处理的上下文的最大长度。
所以，如果我们的块大小是八，那意味着我们将有多达八个字符的上下文来预测序列中的第九个字符。
批大小表示我们将并行处理多少个序列。
我们希望这个值尽可能大，这样我们就能充分利用 GPU 和板上的并行性能。
所以在这个例子中，我们正在进行四乘八批处理。
所以这里的每一行都是独立的例子，每一行都是我们要训练的序列的一个小片段。
然后我们在这里的每个点都有输入和目标。
所以要完整地解释一下传递给 Transformer 的单个四乘八批处理中包含的内容，我在这里做了一些压缩。
所以当输入是 47 时，目标就是 58。
当输入是序列 47、58 时，目标是 1。
当输入是 47、58、1 时，目标是 51，依此类推。
所以实际上，这个四乘八的单个批处理示例包含了大量我们期望 Transformer 并行学习的个别示例。
所以你会看到，批次是完全独立地学习的，但是时间维度在水平方向上也是并行训练的。
因此，你的真正批次大小更像是 B 乘以 T。
只是模型在 T 方向上进行预测时，上下文是线性增长的。
这是模型将从中学习的所有示例，即单个批次。
现在这是 GPT 类。
因为这是一个仅解码器模型，所以我们不会有编码器，因为我们不是从英语翻译过来，也不会尝试条件化其他外部信息。
我们只是尝试产生一系列跟随彼此或可能跟随彼此的单词。
所以这都是 PyTorch，我稍微快一点，因为我假设人们已经学过 231M 或类似的内容。
但是在前向传递中，我们获取这些索引，然后通过嵌入查找表对索引的标识进行编码。
因此，每个整数都通过 nn.embedding 中的查找表索引到一组向量，并提取出该令牌的单词向量。
然后因为消息，因为被自身转换并不实际上，它本身可以原生地处理集合。
所以我们还需要对这些向量进行位置编码，这样我们基本上既有关于令牌标识的信息，又有关于其在序列中位置的信息，从一到块大小。
现在，关于什么和在哪里的信息是加法地结合在一起的。
因此，令牌嵌入和位置嵌入就像这里一样被简单地相加。
这里的X，然后有可选的丢弃。
这里的X基本上只包含单词及其位置的集合。
然后将其馈送到transformer的块中。
我们将要看看这里的块是什么。
但是在这里，目前，这只是transformer中的一系列块。
然后最后，有一个层归一化，然后您正在使用这个transformer的对象的线性投影来解码下一个词或序列中的下一个整数的对数。
因此，这里的LM头，简称语言模型头，只是一个线性函数。
因此，基本上对所有单词进行位置编码，将它们馈送到一系列块中，然后应用线性层以获得下一个字符的概率分布。
然后如果我们有目标，在数据加载器中生成的，你会注意到这些目标只是按时间偏移了一次的输入，然后这些目标输入到一个交叉熵损失中。
所以这只是一个负一似然，典型的分类损失。
现在让我们深入研究这些区块中的内容。
所以这些区块是按顺序应用的，再次提到，有通信阶段和计算阶段。
在通信阶段，所有节点都可以相互通信。
所以这些节点基本上，如果我们的块大小为八，那么在这个图中我们会有八个节点。
这个图中有八个节点。
第一个节点只指向自己。
第二个节点由第一个节点和自己指向。
第三个节点由前两个节点和自己指向，依此类推。
所以这里有八个节点。
所以你应用，X 中有一个残差路径。
你拿出它，应用一个层规范化然后自我注意力以便这些节点通信，但你必须记住批次是四。
因为批次是四，所以这也被应用了。
所以我们有八个节点进行通信，但其中有一批四个节点，它们都在与这八个节点进行单独通信。
当然，在批量维度上没有交叉。
幸运的是，它们之间没有批量归一化。
一旦它们交换了信息，它们就会使用多层感知器进行处理，这就是计算阶段。
所以，这里我们也缺少了交叉注意力，因为这是一个仅有解码器的模型。
所以我们只有这一步，多头注意力，那就是这一行，通信阶段。
然后我们有前馈，也就是 MLP，那就是计算阶段。
稍后我会回答问题。
然后这里的 MLP 相当简单。
MLP 只是对每个节点进行单独处理，只是在该节点上转换特征表示。
所以应用一个具有 Gelu 非线性的两层神经网络，你可以把它想象成是 ReLU 或类似的东西。
它只是一个非线性。
然后 MLP 很简单。
我认为那里没有太疯狂的东西。
然后这是因果自注意部分，通信阶段。
所以这就像是事情的核心和最复杂的部分。
只有因为批处理和如何屏蔽图中的连接性的实现细节，才会变得复杂，这样你就无法从未来获取任何信息，当你在预测你的标记时。
否则它会泄露信息。
所以如果我是第五个标记，如果我是第五个位置，那么我得到的是第四个标记进入输入，我参与到第三、第二和第一。
我试图弄清楚接下来的标记是什么。
好吧，在这个批次中，在时间维度上的下一个元素中，答案在输入中。
所以我无法从那里获取任何信息。
所以这就是为什么这一切都很棘手，但基本上在前向传递中，我们根据X计算查询、键和值。
所以这些都是键、查询和值。
在这里，当我计算注意力时，我有查询矩阵乘以键。
所以这是对所有查询和所有头部的所有键的并行点积。
所以我觉得要提一下这里也有头部的方面，在这里也都是并行完成的。
所以我们有批次维度，时间维度和头维度，最终得到五维张量，这一切都非常令人困惑。
所以我邀请你稍后仔细研究并确信这实际上是在做正确的事情。
但基本上你有批次维度，头维度和时间维度，然后你在它们上面有特征。
因此，这在所有批次元素、所有头元素和所有时间元素上进行评估，使用我之前给你的简单Python，即查询点乘P。
然后这里我们进行一个填充的掩码。
这是在基本上将那些不应该通信的节点之间的注意力夹紧为负无穷。
我们使用负无穷，因为我们将进行softmax。
所以负无穷将基本上使得这些元素的注意力为零。
因此，在这里我们最终会得到权重，即这些节点之间的关系，还有可选的丢失。
然后这里的注意力矩阵乘以V基本上是根据我们计算的关系来收集信息。
这只是所有这些节点上值的加权和。
所以这个矩阵乘法器正在进行加权求和。
然后转置连续视图，因为它都是在五维张量中复杂而混乱的，但实际上并没有做什么。
可选的辍学，然后是线性投影回到残差路径。
所以这里实现了通信情况。
然后您可以训练这个transformer，然后可以生成无限的莎士比亚。
我们将简单地通过这样做，因为我们的块大小是八，我们从一些令牌开始，就像在这种情况下我使用的那样，您可以使用类似换行符的东西作为起始令牌。
然后您只与自己通信，因为有一个单一节点，您会得到序列中第一个单词的概率分布。
然后您对其进行解码或序列中的第一个字符，您解码该字符，然后将字符带回并将其重新编码为整数。
现在您有了第二个东西。
所以您得到了，好的，我们处于第一个位置，这是任何整数，将位置编码加起来，进入序列，进入transformer。
然后，这个令牌现在与第一个令牌及其标识进行通信。
所以您只需不断地将其插回即可。
一旦您用尽了块大小，即为八，您就开始裁剪，因为您在训练此Transformer时，块大小永远不能超过八。
因此，我们会拥有越来越多的上下文，直到八个为止。
然后，如果您想要生成超过八个的内容，您必须开始裁剪，因为Transformer在时间维度上仅适用于八个元素。
因此，在主要设置中，所有这些Transformer都有一个有限的块大小或上下文长度。
在典型的模型中，这将是1,024个标记或2,048个标记，类似于那样。
但这些标记通常是像VPE标记或句子片段标记或工作片段标记之类的。
有许多不同的编码方式。
所以并不会那么长。
这就是为什么我认为他们提到，我们真的想要扩展上下文大小，但由于注意力在主要情况下是二次的，所以情况变得复杂。
现在，如果您想要实现一个编码器而不是一个解码器的注意力，那么您所需要做的就是这个掩码节点，然后删除那一行。
因此，如果您不对注意力进行掩码处理，那么所有节点都将相互通信，一切都是允许的，并且信息会在所有节点之间流动。
所以如果你想在这里加入编码器，只需删除所有编码器块，我们将在删除这行的地方使用注意力。
这样你就允许编码器存储任何内容，比如说10个标记或10个节点，它们都可以互相通信，进入transformer。
然后如果你想实现跨注意力，所以你有一个完整的编码器-解码器transformer，不只是一个仅有解码器的transformer或GPT，那么我们还需要在中间加入跨注意力。
所以这里有一个自注意力部分，其中所有的，有一个自注意力部分，一个跨注意力部分和这个MLP。
在跨注意力中，我们需要获取编码器顶部的特征。
我们需要在这里再添加一行，这将是跨注意力，而不是，我应该在实现时就应该把它实现了，而不只是指出，我想，但这里会有一个跨注意力的行。
所以我们会有三行，因为我们需要再添加一个块，查询将来自X，但键和值将来自编码器的顶部。
基本上会有信息从编码器严格地流向X中的所有节点，然后就是这样。
所以这对于解码器注意力来说是非常简单的修改。
所以你会听到人们说你有一种类似 GPT 的仅解码器模型。
你可以有一个类似 BERT 的仅编码器模型，或者你可以有一个编码器解码器模型，比如 T5 做一些机器翻译。
所以，在 BERT 中，你不能使用类似自回归的语言建模设置来训练它，你只是试图预测下一个元素序列。
你是用稍微不同的目标来训练它。
你输入整个句子，整个句子被允许完全通信，然后你试图对情感或类似的东西进行分类。
所以你不是在尝试模拟序列中的下一个标记。
所以这些都是用掩码进行不同的翻译，使用掩码和其他去噪技术。
所以这有点像transformer。
我会继续。
是的，也许有更多问题。
所以我们正在将图连接到模型，并做一些标记的事情。
我们仍然试图执行像是一个动态图，我们实际上可以在每个实例中改变它，而且我们也有一个功能来实现它。
我们通过屏蔽来对它施加这些约束，但尽管我们正在处理相同类型的东西。
所以我不确定我是否完全理解。
所以有不同的方式来看待这个类比，但其中一种类比是你可以将这个图解释为真正固定的。
只是每次我们进行通信时，我们使用不同的权重。
你可以往下看。
所以如果我们的块大小是八，在我的例子中，我们会有八个节点。
这里我们有两个，四个，六个，好吧。
所以我们会有八个节点。
它们将以这种方式连接，你将它们布置出来，只能从左到右连接。
我的意思是，但对于不同的问题，可能不会有一个用于连接功能的图。
为什么要连接？
通常连接不会因为数据或类似的原因而改变。
我认为模型会像一个实际的图一样，就像是一个有点不同的函数，但我在想是否需要。
我还没有看到一个例子，其中连接的动态变化是根据数据的函数。
通常连接是固定的。
如果你有一个编码器，而你正在训练一个BERT，你有多少标记你想要的，它们是完全连接的。
如果你有一个解码器在其中一个上，你有这个三角形的东西。
如果你有编码器解码器，那么你有尴尬地有两个节点池。
是的，好吧。
我想如果有一个不同的方法，你有像一个负面。
我的问题是，我想知道你对此了解多少。
我知道，就像，在我脑海中，是的，真的很难说。
这就是为什么我认为这篇论文很有趣的原因，就像，通常你会看到像一条路径，也许他们在内部有路径，但我想他们只是没有公开发表。
你所能看到的只是一些看起来不像transformer的东西。
我的意思是，你有ResNets，它们有很多这个，但是ResNet可能有点像这个，但是没有自注意组件，但是MLP在ResNet中也是存在的。
所以ResNet看起来很像这个，除了没有，你也可以在ResNets中使用层归一化，我相信。
通常有时它们可以是批次归一化。
所以它有点像ResNet。
这有点像是他们拿了一个ResNet，然后加入了自注意力，除了已有的MLP块之外，它有点像卷积。
而MLP严格来说是逐一卷积，但我认为这个想法类似，因为MLP就像典型的权重、非线性权重或操作。
但我会说，是的，这很有趣，因为很多工作都没有在那里。
然后他们给你这个transformer，然后事实证明，五年后，它甚至没有改变，尽管每个人都在努力改变它。
所以对我来说很有趣，它有点像一个包，在历史上我认为这很有趣。
我还和论文作者交流过，他们当时并不知道transformer会产生什么影响。
所以当你阅读这篇论文时，实际上有点不幸，因为这就像改变一切的论文。
但当人们阅读它时，就像是问号，因为它读起来像是一篇相当随机的机器翻译论文。
比如，哦，我们正在进行机器翻译。
哦，这是一个很酷的架构。
好的，很棒，结果不错。
它不太知道会发生什么。
所以当人们今天阅读它时，我认为他们可能会感到困惑。
拥有，就像拥有一样，最后我会发一些推文，但我想我会考虑重新命名它，有了事后的视角，嗯，我会解决这个问题的。
是的，我认为这也是一个很好的问题。
目前，我是说，我当然不喜欢自回归建模方法。
我觉得这样做有点奇怪，就像是抽样一个标记然后承诺它。
所以，你知道，也许有一些方法，也许有一些方法，例如扩散，我认为那会很酷。
或者我们会找到其他一些方法来稍后编辑序列，但仍然在自回归框架中。
但我觉得扩散有点像一个崭露头角的建模方法，我个人觉得更吸引人。
当我抽样文本时，我不是一下子就抽取一大段然后承诺下去。
我先草拟一份，然后再做一份更好的草拟。
这感觉像一个扩散过程。
所以这将是我的希望。
好的，还有一个问题。
所以是的，你认为园艺逻辑，它提供了一种可视化图形的方式。
但是你说自我注意力有点像完成边缘的论文，使用这个想法中的笔记上的点积。
然后一旦我们有了这张边缘的论文，我们就像乘以它的值，然后我们就适当地使用它。
是的。
是的，对。
你认为这里有一种，类似于用咖啡和网络进行区分的类比。
我觉得图神经网络有点令人困惑，因为我是说，以前有这种概念，我有点觉得也许今天，一切都是一个图网络，因为transformer是一个图神经网络处理器。
transformer操作的本地表示是通过直接连接的集合。
所以这是本地表示。
然后，好的，我应该继续，因为我还有大约30张幻灯片。
抱歉，抱歉，抱歉。
这个问题被划分了，是softmax吗？
为什么你不想要你的一个除以二？
哦，是的。
是的，根 DE，我觉得基本上就像你的，如果你用高斯分布从随机权重初始化，随着你的维度大小增长，你的值也增长，方差增大，然后你的 softmax 就会变成一个一半的向量。
所以这只是一种控制方差并使其始终保持在良好范围内以便 softmax 和良好分布的方法。
好的，所以这几乎就像是一种初始化的方法。
好的，所以transformer已经被应用到所有其他领域。
而这样做的方式在我看来有点荒谬，老实说，因为我是一个计算机视觉的人，你有 comnets，它们有点讲得通。
所以我们现在所做的，以位为例，你拿一张图像，然后把它切成小方块。
然后这些方块直接喂入transformer，就是这样，有点荒谬。
所以，我是说，是的。
所以，即使在最简单的情况下，transformer甚至都不真的知道这些补丁可能来自哪里。
它们通常是位置编码的，但它必须以某种方式重新发现它们的很多结构。
以这种方式接近它有点奇怪。
但这就像是将大图像简单地切成小方块，然后将它们馈送进去，就好像这些个体节点实际上效果相当不错。
而这是在一个transformer编码器中。
所以所有的补丁都在整个transformer中相互交流。
而这里的节点数就像是九个。
在语音识别中，你只需取你的MEL频谱图，将其切成片段，然后馈送到一个transformer中。
所以有这样一篇论文，也有whisper。
Whisper是一个复制-粘贴transformer。
如果你见过OpenAI的whisper，你只需将MEL频谱图切割并馈送到一个transformer中，然后假装你在处理文本，它效果非常好。
在RL中的决策transformer中，你取得在环境中经历的状态、动作和奖励，然后假装它是一种语言，开始对这些序列建模。
然后你可以在后来用它进行规划。
这效果相当不错。
甚至像alpha-fold这样的东西。
所以我们经常谈论分子以及你如何将它们嵌入其中。
所以在alpha-fold的计算核心也是一个transformer。
关于transformers，我想说的一件事是，我发现它们非常灵活，我真的很喜欢这一点。
我会给你一个来自特斯拉的例子。
你有一个comnet，它接收一张图像并对图像进行预测。
然后一个重要的问题是，你如何输入额外的信息？
这并不总是简单的。
假设我有额外的信息，我想通知，我希望输出受到这些信息的影响。
也许我有其他传感器，比如雷达。
也许我有一些地图信息或车辆类型或一些音频。
问题是，你如何将信息输入到comnet中？
你在哪里输入它？
你是把它连接起来吗？
你如何添加它？
在哪个阶段？
所以用transformer就容易得多，因为你只需拿取你想要的任何东西，将其切成片段，然后与之前的内容一起输入。
然后让自注意力机制弄清楚所有事物应该如何交流。
而这实际上是有效的。
所以只需将所有东西切碎并投入混合中，有点像这样的方式。
它使神经网络摆脱了欧几里得空间的负担，在以前，你必须安排计算以符合你正在布置计算的三维欧几里得空间。
就像计算实际上几乎发生在三维空间中一样。
如果你考虑一下，但在注意力中，一切都只是集合。
所以它是一个非常灵活的框架，你可以随意将东西添加到你的条件集合中，一切都会自我关注。
所以从那个角度来看，它是相当美丽的。
好的。
那么现在，究竟是什么让transformer如此有效呢？
我认为一个很好的例子来自于GPT-3论文，我鼓励人们阅读。
语言模型是二次学习者。
我可能会稍微改一下这个名字。
我可能会说transformer能够进行上下文学习或者元学习之类的东西。
这就是使它们真正特别的地方。
所以基本上它们正在处理的第二件事是，好的，我有一些上下文，我正在尝试提取一段内容。
这只是许多例子中的一个。
我有一段内容，我正在对它提问。
然后我会在提示中给出一段上下文，我会给出问题和答案。
所以我会给出一个问题答案的例子，另一个问题答案的例子，还有一个问题答案的例子，以此类推。
这样一来，哦，是的，人们很快就要离开了。
好的，这真的很重要，让我想想。
好的，所以真正有趣的是，基本上随着在上下文中给出更多的例子，准确性会提高。
所以这暗示着transformer能够在没有像典型的微调方式下的任何梯度下降的情况下，以某种方式学习激活。
所以如果你进行微调，你必须给出一个例子和答案，并使用梯度下降进行微调。
但是看起来transformer在其权重内部正在做一些类似于梯度下降的事情，作为它阅读提示时的某种元学习。
因此，在这篇论文中，他们探讨了，区分了这个外循环与随机梯度下降和这个内循环的上下文学习。
因此，内循环是transformer在某种程度上读取序列，而外循环则是通过梯度下降进行训练。 
基本上，transformer 的激活中会发生一些训练，就好像它在消耗一个非常类似于梯度下降的序列一样。
所以最近有一些论文暗示了这一点并进行了研究。
举个例子，在这篇论文中，他们提出了一个叫做原始运算符的东西。
他们认为原始运算符是由 transformer 实现的。
然后他们展示了你可以在原始运算符的基础上实现诸如岭回归之类的东西。
所以这有点像在暗示，也许在 transformer 的激活中有一些类似于基于梯度的学习的东西。
我认为这不是不可能想到的，因为什么是基于梯度的学习呢？
前向传播，反向传播然后更新。
嗯，这看起来像是一个共鸣，对吧？
因为你只是在改变，你在添加到权重上。
所以你开始具有初始随机权重的集合，前向传播，反向传播然后更新你的权重。
然后前向传播，反向传播，更新权重。
看起来像是一个共鸣，transformer 就是一个共鸣。
这些论文更加含糊，但基本上是在暗示为什么这可能是有潜力的。
然后我有一堆推特。
我只是把它们贴在这里。
我当时，这是为了一般性的消费。
因此，它们更加高层次，而且有点高 P，但我在谈论为什么这种架构如此有趣，以及为什么潜在地变得如此流行。
我认为它同时优化了三个我认为非常理想的属性。
第一，transformer 在前向传播中非常具有表现力。
它有点像能够实现非常有趣的函数，潜在地可以执行甚至像是元学习的函数。
第二，由于残差连接、层归一化等因素，它非常可优化。
第三，它非常高效。
这并不总是被认可的，但是如果你看一下计算图，transformer 是一个浅而宽的网络，非常适合利用 GPU 的并行性。
因此，我认为 transformer 被设计得非常有意识，以便在 GPU 上高效运行。
有一些先前的工作，比如神经GPU，我也非常喜欢，这实际上就像，我们怎么样，我们怎么设计在GPU上高效运行的神经网络，从硬件的限制出发，我认为这是一种非常有趣的思考方式。
哦，是的。
所以在这里我说我可能会称之为，我可能会称之为transformer为通用高效的，可优化的计算机，而不是仅仅是关注你所需要的。
就像我可能事后会称那篇论文提出的是一个非常通用的模型。
所以前向传播表达它。
在GPU使用方面非常高效，通过梯度下降很容易优化，并且训练得非常好。
然后我这里有一些其他的炒作推文，无论如何。
所以，你知道，你以后可以读它们，但我认为这个可能有趣。
所以以前的神经网络是专门为特定任务设计的特殊用途计算机。
GPT是一台通用计算机，可以在运行时重新配置以运行自然语言程序。
所以程序，程序是以提示的形式给出的，然后GPT通过完成文档来运行程序。
所以我个人非常喜欢这些类比，对于计算机来说，它就像是一台强大的计算机，并且可以通过梯度下降进行优化。
我不知道。
好的。
是的，就是这样。
你以后可以阅读这些内容，但这就是我要说的，谢谢你。
我就让它保持在这里。
抱歉，我刚刚发现了这个线索。
原来，如果你扩大训练集并使用强大的神经网络，比如transformer，那么网络就会变成一种通用的文本计算机。
我觉得这是一种很好的看待它的方式。
而不是执行单个文本序列，你可以设计提示中的序列。
由于transformer既强大又训练了足够大的、非常困难的数据集，它就成了这种通用的文本计算机。
所以我觉得这挺有趣的。
我们有三个要点。
我想，对我来说，我了解了电话号码。
然后你就得到了所有不同的东西。
我们有一种RNA。
然后我听说了transformer。
我正在寻找一个，你认为它有多相似，实际上很大程度上是这样，你知道，我认为真的是这样，因为它大多数时候更有效率。
或者你认为安全性有点像是你可以拥有的东西，为你提供的具体的东西吗？
所以我觉得有点像那样。
是的。
所以我会说，RNNs在原则上是可以实现任意程序的。
我觉得这有点像一个无用的陈述，在某种程度上，因为它们并不是，它们可能，我不确定它们是否，它们可能是富有表现力的，因为在某种程度上，它们可以实现这些任意的功能，但它们是不可优化的。
而且它们肯定不高效，因为它们是串行计算设备。
所以我认为，如果你将其看作是一个计算图，RNNs就是一个非常长而薄的计算图。
就像你拉伸神经元并查看所有单个神经元及其连接性，尝试将它们可视化。
RNNs就像一个非常长的图，而且对于可优化性也很差，因为我不确定为什么，但直观上来说，当你反向传播时，你不想走太多步骤。
因此，transformer是一个浅白的图形。
因此，从监督到输入，跳数很少。
而且沿着残差路径，梯度可以很容易地流动。
而且有所有这些层归一化来控制，颗粒状，所有这些激活的尺度。
因此，跳数不多，你很快就从监督到输入，只是在图形中流动。
所以，这一切都可以并行完成。
因此，你不需要在当前的解码器RNN中这样做。
你必须从第一个词，然后第二个词，再到第三个词，但在transformer中，每个单词都是完全并行处理的，这在某种程度上是一种，所以我认为所有这些都非常重要，因为所有这些都非常重要。
而且我认为第三点不太被讨论，但非常重要，因为在深度学习中规模很重要。
因此，你可以训练的网络大小是非常重要的。
所以如果在当前硬件上效率很高，那么我们可以使它更大。
当你提到你正在处理多模态数据时，它是如何工作的？
你喜欢不同的数据，不同的标记吗？
或者，不是。
所以，你拿你的图像，显然把它们切成块。
所以第一千个令牌或者其他东西。
现在我有一个特殊的，雷达也可能是，但我实际上不知道雷达的原始表示。
但是，你可以，你只需要把它切开并输入。
然后你必须以某种方式对其进行编码，就像transformer需要知道它们来自雷达一样。
所以你创建一个特殊的，你有一种特殊的令牌，你，这些雷达令牌在表示上略有不同，并且通过评分来学习。
并且车辆信息也将通过一个可以学习的特殊嵌入令牌而进来。
你不，这一切都只是一个集合。
但是，是的，这一切都只是一个集合，但是如果你想的话，你无法对这些集合进行位置编码。
所以，但是位置编码意味着你可以硬编码，例如，坐标，像使用正弦节点和余弦，你可以将其连接起来，但是最好不要连接位置，你只需要，这只是一个向量，总是停留在这个位置，无论有什么内容，都会加上它，并且这个向量是可以通过背景训练的。
这就是你做的方式。
我真的不喜欢这个。
我觉得它们有点微妙，就像它们似乎在工作，但听起来有时候有一些结构不太对，或者它们会变成其他的东西。
我有一个想法，但我更喜欢这个。
嗯，我不确定我是否理解这个问题。
所以我的意思是，位置编码器就像，它们实际上不是，它们有，好吧。
所以它们几乎没有归纳偏差之类的东西。
它们只是一直悬挂在某个位置的向量。
而你正在尝试，你正在以某种方式帮助它们。
嗯，我觉得直觉是好的，但是，如果你有足够的数据，通常尝试干预它通常是一件坏事。
尝试在数据集本身已经有足够知识的情况下输入知识通常不太生产力。
所以这真的取决于你处于什么规模。
如果你有无限的数据，那么你实际上希望编码越来越少。
结果证明这样效果更好。
而如果你有很少的数据，那么实际上你确实想要编码一些偏见。
也许如果你的数据集要小得多，那么卷积可能是个好主意，因为你实际上有更多滤波器带来的这种偏见。
所以，但我认为，嗯，transformer是非常通用的，但有方法可以干扰编码以添加更多结构。
例如，您可以编码正弦和余弦并退出，或者您实际上可以转到注意机制并说，好的，如果我的图像被分成补丁，这个补丁只能与这个邻域通信。
您可以在注意矩阵中执行此操作，只需屏蔽掉您不想要通信的内容。
因此，人们真的会尝试这样做，因为完全的注意力是低效的。
所以他们会穿插，例如，仅在所有补丁中进行通信的层，然后进行全局通信的层。
他们会做各种技巧。
因此，您可以逐渐引入更多的归纳偏差。
您会这样做，但归纳偏差有点像，它们从核心transformer中分解出来，它们在节点的连接中分解出来。
它们在位置编码中分解出来，可以干扰此竞争。
所以现在大概有200篇论文了，如果不是更多的话，它们有点难追踪，老实说，就像我的Safari浏览器一样，它在我的电脑上，有200个打开的标签，但是，是的，老实说，我甚至不确定我是否想要挑选我的最爱。
是的，我觉得你的东西非常有趣。
你可以把transformer想象成一个CP，我认为它是能够执行4,000个指令的东西，现在CP的主体就像存储变量一样，你有内存，就像用CP做程序一样，我只是多次做而已。
所以也许我可以像那样使用transformer。
我实际上更喜欢的另一个可能是固定上下文长度，但是允许网络以某种方式使用草稿本。
这样做的方式是，你会通过提示的示例来教transformer，嘿，你实际上有一个草稿本。
嘿，基本上，你记不住太多，你的上下文行是有限的，但是你可以使用一个草稿本，你可以通过发出开始草稿本然后写下你想记住的任何内容然后结束草稿本来做到这一点。
然后你继续做你想做的事。
然后在解码时，实际上你会有一些特殊的逻辑，当检测到起始scratch pad时，你会像保存在外部设备中一样保存其中的内容，并允许其进行关注。
所以基本上你可以动态地教会transformer，因为它是如此元学习。
你可以动态地教它使用其他小工具和设备，并允许它扩展其内存。
如果这有意义的话。
这就像人类学习使用记事本一样，对吧？
你不必把它记在脑子里。
所以把东西存在脑子里有点像transformer的上下文长度，但也许我们可以给它一个笔记本，然后它可以查询笔记本并从中读取和写入。
也许你可以使用transformer来玩另一个transformer。
我用的是他们要看到这个的方式。
我不知道我是否检测到了那个。
我有点觉得，你觉得这不仅仅是一个不断展开的长提示吗？
我没有进行详尽尝试，但我确实看到了一个遗忘事件。
我有点觉得块大小只是被移动了。
也许我错了。
我实际上不了解Chai GPT的内部。
是的。
两个在线问题。
所以一个问题是，你对架构有什么看法？
S4？
S4。
我发誓我没有一个S4。
哪一个是S4？
啊，第二个问题，这是一个个人问题。
你接下来打算做什么？
你没有第二个问题。
我的意思是，现在我正在研究像nano GPT这样的东西，nano GPT在哪里？
我的意思是，我基本上正在从计算机视觉转向，有点像基于视觉的产品，再深入一点进入语言领域。
Chai GPT在哪里？
好的，nano GPT。
所以最初我有min GPT，我把它改写成nano GPT，我正在研究这个。
我正在尝试复制GPTs。
我认为像Chai GPT这样的产品，逐步以产品方式改进，会非常有趣。
我认为很多人都有这种感觉，这就是为什么它变得如此广泛的原因。
所以我认为有类似谷歌加加加的东西要构建，我觉得非常有趣。
我们能让她在舱内快速转一圈吗？
