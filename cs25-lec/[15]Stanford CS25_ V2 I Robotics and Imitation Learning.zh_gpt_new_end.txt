嘿，各位。
很酷，是的。
感谢等待。
我很高兴能在这里。
我想简要介绍一下自己，我叫肖德明。
我是Google Brain团队的高级研究工程师。
我已经在机器人领域工作了五年。
我涉足了一些主题，包括多任务学习、强化学习，最近主要在广泛思考如何扩大机器人的规模，确保它们能够在真实世界中正常工作。
我想今天我会谈论一些不同的话题，但首先，我想说的是我们的团队现在非常庞大。
所有这些项目都是与一些团队合作的巨大项目，有些项目有40多人参与了多年。
所以这些都是大型的努力，我很幸运能够称自己是一组非常聪明的人的团队成员。
其次，我的一些看法可能比其他人更有争议。
所以所有这些观点绝对只代表我个人的看法，不代表Google或团队中其他任何人的看法。
那么，说了这些，欢迎来到我的TEDx演讲。
所以我想也许你们中的一些人已经看过了很多很酷的机器人视频、学习视频，这些视频如今在外面很流行，但我比以往任何时候都更加兴奋。
这不仅仅是炒作，我认为。
我认为在过去两年里，研究人员和机器人学家对学习的看法发生了根本性的转变。
而我认为这种转变与基础模型、大规模互联网模型在更广泛的基金会建模领域以及语言、音频等不同领域发生的所有趋势有很大关系。
但我想今天我的目标是向你们传达为什么我对今天这个时刻格外兴奋，以及为什么在机器人学习领域已经发生了非常根本的180度转变，我认为。
如果你们从这次演讲中带走的唯一一件事情就是你们对机器人学比之前稍微更加兴奋了一点，或者相信现在是这些机器人真正开始呈指数级增长并做一些真正酷的事情的时候。
我想那么我的演讲就算成功了。
嗯，让我们看看。
这次演讲将分为几个部分。
我们将从一个非常高的层面开始，只是讨论为什么基础模型对于机器人的基础模型而言如此重要，以及它可能是什么样子以及我们如何可能达到这个目标的成分和配方。
然后，我们将深入研究我的团队在过去一两年中为之感到非常自豪的一些不同的工作。
最后，我们将回到高层次，然后放大思考机器人学习的下一步是什么。
那么，为什么要为机器人建立基础模型呢？
等一下，让我试着把这个东西藏起来。
哦，那没关系。
我现在会保留那个条。
但是顶部的条上写着，为什么要为机器人建立基础模型呢？
这个词汇是在斯坦福这里创造的，我会在整个讲座中相当随意地使用短语“互联网规模模型”、“基础模型”和“大语言模型”。
我希望这是相当清楚的。
但一般来说，当我谈论那些在大量数据上进行训练的庞大的整体模型时，它们具有两个非常重要的属性，我认为这相当不错。
一个是出现。
当在小规模上运作的非常简单的事情，当你把事情放大时，它们会变得更好。
更多的数据，更多的计算，更大的模型。
我们在这里看到的情况是，当这些模型变得足够好时，它们擅长和能够做的领域空间开始以组合方式变得更大。
在这里，针对这两点，我想推荐两篇我强烈推荐的博客文章。
其中一篇是Jacob Steinhardt写的《对于人工智能，更多就意味着不同》。
这种链接了我们在其他领域（如物理学或生物学）中看到的现象。
例如，单个水分子的行为会非常不同，并且具有非常不同的，比如说，静电力，然后它们开始聚集在一起，开始作为一个液体整体行动。
我们在动物群和飞鸟群的模式中看到这一点。
我们在人类和经济中看到这一点。
我们在不同领域中看到这一点，并且现在甚至在人工智能中也看到这一点。
我们看到的模型正在做一些在更小的尺度下根本不可能的事情。
但是当它们达到某种关键的规模和大小时，它们开始表现得非常非常好。
在他的博客文章《涌现和LLM》中，您可以看到这个情节在左下方成功地跨越了一系列不同的任务，无论是模块化算术还是推理问答，成功率基本上在这些模型足够大足够好之前都是平稳的。
然后成功率就像火箭一样飙升。
这就是为什么我认为这些特别令人兴奋。
所以，有一个问题。
我很好奇，在你们办公室里，机器人基础模型展示了规模吗？
很好的问题，我很高兴你问。
我很兴奋地介绍一些我们在这方面的方向。
我希望我们将在大约10分钟左右回答您的问题。
但我认为这是我们所有人，包括我自己在内，心中都在想的一个问题。
所以我认为，在我们讨论任何机器人基础模型的可行性或存在性之前，这是否有必要？
我认为，一个并不明显的论点是，我认为新兴的能力并依赖于这些能力可能实际上对于机器人的正常工作是不可或缺的。
在过去几十年里，机器人学的许多研究都集中在一个箱子、一个房间、一张桌子、一个机器人，甚至是一栋楼里。
但是这些与人类每天在现实世界中操作的情况相比，复杂性相差几个数量级。
我认为要实现这一巨大的飞跃，我们将不得不依赖于这种新兴的能力扩展曲线，其中事情似乎有效，你有非常标准的演示，也许你有，你知道，一个类人机器人程序经过数百次试验后翻转，但从那里到像混沌的现实世界，我认为我们将不得不依赖于这种出现现象。
我认为甚至在智力上或学术上，思考为什么或为什么不为机器人制定一个基础模型也很有趣。
在许多其他领域已经取得了成功。
在音频、音乐、编码、语言和其他领域，似乎每天都有存在证明，包括3D模型及更高级别的领域。
但是，如果机器人有什么特别之处，无论是体现还是因果关系或物理基础，如果这是导致这个在所有这些其他领域中都有效的简单配方失败的原因，我认为研究为什么会这样很有意义。
我个人是乐观主义者。
我认为没有什么神奇的秘密酱料会阻止机器人采用在其他领域奏效的相同公式和配方来解决问题。
但是你知道，我认为这是一个我想找出答案的问题。
所以也许我们不仅仅是在哲学上激励这个问题，好的，我们需要基础模型，基础模型非常棒。
让我们试着为机器人构建一个。
我们怎么做到这一点呢？
嗯，我认为我们可以利用几个要素，站在巨人的肩膀上，看看其他领域。
第一个是从其他领域扩展机器学习设计原则。
首先让我们看看高容量架构，这是今天课程的主题。
像自我注意力这样的想法，就像transformer所包含的所有不同想法，正如Andrej Karpathy所说，这就像一个神奇的通用可微分计算机，非常通用，非常稳健，而且在许多不同维度上都非常可扩展。
让我们利用这些。
嗯，我们还应该利用今年看到的规模定律、趋势的更多指导原则。
一些chilla。
你知道的，我们不仅要扩大模型规模。
我们还必须扩大计算量，还必须扩大我们在庞大数据集语料库中训练的唯一标记数量。
但如果我们把这三者结合起来，已经被证明能够可靠地有相当大的成功机会。
嗯，无论你看的是什么人。
所以最后，这意味着什么，我认为这实际上以后可能会提到的是，数据集的大小似乎比质量更重要，即使你在维基百科上有一些拼写错误的句子或一些不太理想的东西。
如果从总体上看，你的数据集足够多样化和有趣。
嗯，这些事情希望会在混合中得到解决。
第二个要素是互联网规模模型的普及，不仅仅是原则。
令人兴奋的是，我相信这对专家和 lay 人都是非常震惊的，很多这些生成模型在许多不同的模态上都经历了新兴的能力，并一次又一次地超越了我们所有人最疯狂的期望。
但即使当我们认为我们已经筋疲力尽，所有这些东西太多了，它不会起作用，总会有一些东西出现，完全让我大吃一惊。
我认为这种趋势肯定会继续下去。
我认为除此之外，它们不仅会继续而且会加速得更快，无论我们是否采取任何行动，在宏观尺度上说都会发生。
作为一个机器人学研究员，或者你在任何子领域的身份，有一些机器学习的部分，在至少在不久的将来，你可能永远也不会接触到。
而那些部分将会看到巨大的突破，每周都会有新的能力上线。
你不仅可以从模型的引人注目之处看到这一点，还可以从进展的加速和发布新模型的时间尺度中看到。
为什么会有大型协作是许多团队共同努力，然后可以被所有人访问、使用和构建。
而这一趋势的最后一个成分更多地是与机器人相关的，但它是一个从在线机器人学习转变的巨大变革，在这个过程中，机器人在线收集经验并进行动作学习的方式发生了巨大的变化。
通过试错的方式，转变为离线环境，我们在这个过程中将数据生成过程与数据消耗过程解耦。
正如我们在所有这些其他基础建模领域所看到的，这些大型互联网规模的数据集是如此多样化且静态的。
我们只是一次性地获取它们，或者连续地多次获取它们，但我们会聚合成一个持续增长的连续堆叠。
在这里，我们看到的是来自Luther或Lyon 5B的配对图像文本堆数据集。
嗯，它们相当大，比你之前看到的要大得多，它们绝对是其他领域取得成功的关键因素。
我在训练这些大型基础模型。
现在回到机器人领域，我想简要地谈一下这种转变是如何发生的，因为留在一个句子里很容易。
是的，机器人的离线时间比在线时间长，对于许多从其他领域来的人来说，这种情况就像理所当然一样。
但是在机器人领域，这是一个很大的转变。
我认为对于很多人来说，机器人也一直与强化学习RL同义。
我认为越来越少地如此。
因此，我想带你们简要了解一下我的团队的历史。
顶部的幻灯片上写着谷歌机器人的简要历史。
当然，谢谢。
我认为这不仅仅是为了戏剧性的描写。
这实际上是试图引导您了解我们团队的思维在多年间是如何发生巨大变化的，以及这将如何影响我们在即将展示的具体项目中所做的设计决策、风险和研究方向。
谢谢。
所以在2016年，你们中的一些人可能已经看到了这个，我们有一个被称为“机械臂农场”的项目，七个KUKA机器人在一个房间里，全天候收集拾取数据。
而且，这是在现实世界中进行策略强化学习，我们是第一个团队，试图问，嘿，我们甚至能不能做到这一点，目标是能否在现实世界中实现端到端的机器人学习？
当时这是相当冒险的，这不是一个常见的观点。
从那时起，我们开发了几个有趣的研究方向，我们开始探索，我们研究了一些像Qt opt这样的东西，这是一种在连续控制动作上工作的Q学习方法。
同时接受视觉输入。
我们使用CycleGAN将基于模拟的图像转换为看起来真实的图像，用于Sim2Real。
我们研究了如何在现实世界中实现机器人更快、更高效地移动的并行控制。
对不起，您有问题吗？
是的，我很好奇，你提到了 24 -7 的数据收集，但我很好奇，你是怎么使用 SAM 的？
是的，好问题。
那个，我认为，基本上是，机械臂会从箱子里拿东西。
如果它们弄错了，东西掉了出来，嗯，我们会在第二天早上回来，整个房间里到处都是散落的物体。
所以没有重置。
但如果它们错过了一点，物体会掉回箱子里，希望它们能够再次被拾起来。
你会问我一个问题吗？
哦，是的，当然。
Chad，谢谢，我以后会这样做的。
这个具体的问题是关于这个 24 -7 机械臂农场，我们是怎么进行重置的？
答案是，嗯，我们没有进行重置，我们设计了箱子，使它们有点倾斜，所以如果物体稍微错过，它们会掉回箱子里，重新装备自己，也许还会添加更多与训练数据的差异。
但这是使用 Q -learning 进行的离线政策在线强化学习。
而且我们混合了模拟数据，再次部署。
接下来，我们大约在 2020 年左右进行了这种巩固阶段，当时我们想，好吧，这挺酷的，但我们想要离开箱子。
我们如何在更贴近人类日常生活的实际环境中执行更复杂的任务？
在那里，我们有点确定了这个办公室微型厨房环境。
如果你听说过著名的谷歌微型厨房。
我认为这就是我们决定运作的环境。
然后我们开始收集数据，我们扩展了我们的真实操作，我们在那里扩展了一些不同的方法。
我认为这里右下角的是更机械化的重置版本，我会说是Arm Farm。
在这里，我们有一个可以折叠一半的垃圾箱，这在现实世界中进行多任务强化学习。
垃圾箱会翻转一半，把物体从一边倒到另一边。
这样你就可以做更有趣的任务。
而Arm Farm只是拾取任何东西。
现在我们可以说，嘿，拿起胡萝卜，把番茄放在盘子上，然后垃圾箱会翻转，你就可以重置了。
其他一些工作关注多任务模仿学习。
这是BC0。
然后我们还研究了将强化学习与模仿学习启动结合的东西。
但是在2020年，我们再次意识到我们正在朝着许多不同的方向努力，我们想要 consolida。
我认为当时真正困扰我们的两件主要事情是，我们在所有这些方法中都遇到了两个主要障碍。
其中一些在现实世界中的粗略范围内达到了50到70％的平台。
而其他方法则需要非常特定的数据分布。
它们必须遵循政策，或者只能使用演示或者等等。
就像对所有这些不同方法以及所有这些不同缺点都有许多不同的微妙之处和陷阱一样。
所以我们提出的问题是。
我们对任何能够使我们以非常高效的方式解决任务的方法或策略都持开放态度，在现实世界中超过90％。
并且可以扩展到我们可以收集的某种数据。
也许这比学术环境更宽松一些，在那里你受到更多的资源限制。
但是最终，即使我们的团队也没有无限的资金。
我们仍然有一定数量的机器人，一定数量的操作者，并且受到物理定律的限制。
所以我们需要一种方法来获取更多数据，然后从中学习。
所以，2022年春季的几个月里，我们都在绞尽脑汁思考这个问题。
我们决定采用多任务模仿学习。
所以，这与24/7的手臂农场大相径庭。
这是我们解决问题方式的巨大进步。
我们发现，通过足够的细心呵护和爱，多任务模仿学习能够达到90%的准确率，并且随着更多示范而变得更好。
虽然这些并不是最便宜的东西，但随着额外的示范，它能够扩展，这是我们正在寻找的生命迹象。
这就把我们带到了不到一年前，我们团队决定这是未来至少在短期内的前进道路。
但也许，你知道，我们可以考虑一下我们现在所采取的方法在未来可能如何扩展，也许我们可以重新启动这些其他线索。
例如，如果现在我们将演示数据的收集或其他等与通过多任务模仿学习策略学习的方式分开，也许将来我们可以做类似的离线RL。
但我认为，从一个高层次来看，我只是，在短短几分钟内，就压缩了我们团队学到的六年非常痛苦的经验。
而且我认为，从我们今天所处的位置回顾，即使只是两年前，如果你告诉我我们今天正在部署的策略可以如此扩展，我可能不会相信你。
毫无疑问。
所以在我的教育中，你会给任何学生什么建议，而不是试图弄清楚如何得到一个结果？
好问题。
所以我认为任务调节在当时确实还是一个未解决的问题。
但我认为通过这项工作，BC0，我们发现语言至少在模板语言的表示中是足够好的，我们可以指导BC0超过80个任务。
所以它们非常模板化，比如摘葡萄或将葡萄移到盘子上或将布拖过桌子。
而且我认为这种表示仍然足够，你可以学到很多技能。
你基本上是把一个独热ID传递到你的策略网络中，它会学会模仿那个。
对于这80个任务中的每一个，我们会收集数百或数千个演示。
我稍后会详细谈到这个具体内容。
嗯，是的，今天，或者至少在2022年。
我们来做线下的方法。
我们让数据生成与数据消费解耦。
我们现在来总结这三个要点。
我们来看看机器学习扩展的设计原则，然后找出哪些经验教训实际上可以应用到未来的机器学习和基础模型的配方中。
我认为第一个教训非常重要，那就是高容量的架构，比如注意力机制。
第二个我稍后会讲的是数据互操作性、标记化、离散化。
第二个要素是这些模型本身的激增。
我们能否利用它们，因为它们会随着时间变得更好？
在这里我想推荐一下我的同事卡罗尔·豪斯曼的《痛苦教训2.0》，也就是痛苦教训。
理查德·萨顿提出的第一个是，你应该利用随着计算量增加而扩展的方法。
也许在当今时代，教训是我们应该利用能够利用基础模型改进的方法，因为它们会变得更好。
所以，在课程1.0和2.0中，有一件事情对我来说一直很清楚，那就是假设我有一组方法。
而且我想选择那些会随着更多计算或在这种情况下会随着更好的基础模型扩展的方法。
问题是，我如何真正决定哪些方法符合这些标准呢？
是的，好问题。
我认为，也许这是一个很好的问题，对于这个问题我没有一个好的答案。
哦，抱歉。
是的。
是的。
问题是，在1.0和2.0中的苦涩教训中，问题是，嗯，那很棒。
这就是教训，但我们如何真正决定哪些方法符合这个标准呢？
我想，你知道，我的答案是这并不总是显而易见的，有时候确实相当棘手，但也许，你知道，有时候你可以非常确信，哦是的，这绝对会随着更多的数据计算而扩展，有些则相同。
但基本上，你越硬编码，做出的假设越多，启发式方法越多，你就越依赖于特定基础模型的特定实现，也许这种方法不如假设一些非常抽象的输入和输出，并假设如何从这些输入和输出中得到改进的方法来得稳健。
也许算法本身甚至会完全改变。
所以我认为这就是我对视频课程2.0的看法。
但这绝对还有待定，我认为还需要时间来验证。
而我基本上，我想提出的一个观点是语言是我们可以利用苦涩课程2.0的方式。
如果你把语言作为所有这些基础相互通信的通用表示，无论是字幕还是生成或其他什么，我认为这是我们可以利用苦涩课程2.0的一种方式。
最后，第三个因素是离线机器人学习，将数据生成与数据消费分离。
把所有这些东西放在一起，我对于如何进行一次现代尝试，以体现智能的配方，大致是将这些大型离线数据集与高容量架构相结合，通过使用语言作为通用粘合剂。
在接下来我即将展示的作品中，我认为在某种程度上或多或少受到了这一理念的启发。
现在我们已经有了一种可能的方法。
是的，当然。
最重要的一点。
首先，我想知道的是，如果有的话，这些中的哪些目前是瓶颈，不是正确的词，这意味着受限制的。
明白了。
因为看起来我们已经有了我们的狗，我想，如果我们拥有高容量的架构，那么这些架构就相对只是语言。
看起来我们已经拥有了所有必要的组件。
那么为什么这不是一个成熟的产品呢？
嗯，问题是，嗯，这些看起来我们有很多这些成分。
那么为什么机器人技术还没有被解决呢？
嗯，所以我会认为实际上这里的观点，也许我现在对错的听众来说，但我认为这在机器人领域并不是非常明显的。 
许多人并不同意所有这些观点，更别说其中的两个或甚至任何一个了。
所以我认为，还有一个衡量这些组件成熟程度的标尺存在于机器人技术中。
它们的发展阶段非常不同。
我想说的是，我们可以稍后讨论一下，例如，数据规模或已经从其他机器学习领域渗透到机器人技术中的架构。
但我认为，人们对这些教训实际上采纳了多少，投资了多少，我们仍然处于非常不同的阶段。
是的。
是的。
对不起。
我很好奇要知道，并不是要求你点名道姓，但可能不同意所有这些观点的人。是的，我也可能会因为在几张幻灯片上的发言而惹上一些麻烦。
所以我稍后会详细解释一下。
是的，是的。
是的。
我想说的是，就我个人而言，而且，你知道，并不代表我的团队，但我的团队中很多人可能处于学习的极端阶段，以数据为驱动的基础模型为基础，让我们走得更远。
但我认为很多人并不相信这一点。
是的，很高兴讨论稍后的原因，也许在Zoom之后吧。
所以是的。
嗯，好的，那么，让我们继续深入，看看这个配方实际上可能如何渗透到具体的领域。
第一个是RT1。
这是我们小组的最新工作，致力于如何扩展模仿学习，让我们看看如何实际应用这些第一原理。
所以第一步是考虑我们实际上想要什么，让我们把自己置身于2020年春季的思维方式中。
我们已经收集了一段时间的示范。
这是大量的示范，像是一百万个，这是在一年半的时间里收集的，涉及许多机器人，涉及许多已经存在的任务。
这是昂贵的。
随着时间的推移，这实际上不会以疯狂的数量逐渐增加。
我们不会每天只是得到一百万个新的高质量示范。
这将随着时间的推移增长，但这并不是免费的。
而且，自主地进行这样的方式非常困难。
正如你早些时候看到的MTOP与箱子重置机制，或者DeepMind对RGB叠加的研究，他们试图进行自主重置。
而我们现在正在做的方式，或者至少对于这篇论文来说，是由 BC0 开创的人类遥操作，而且那也非常昂贵。
所以吞吐量会受到限制。
最后，BC0 使用了基于 ResNet 的骨干网络，效果相当不错，但发现它对训练分布非常敏感。
例如，当他们从一些遥操作者那里移除数据使数据更加均匀时，性能有所提升。
但这并不是我们喜欢的特性，对吧？
我们希望有更多的数据，即使它们不完全相同。
所以这里的教训是，模型需要具有鲁棒性和泛化能力。
很好。
所以我们的模型需要具有鲁棒性和泛化能力。
还有什么呢？
嗯，现成的模型速度相当慢。
如果我们采用其他领域的大型视觉Transformer，它们不会在真实机器人上运行。
嗯，我们需要以相当高的频率运行。
嗯，它们需要具有反应性，推理时间需要缓慢，因为我们所有的模型都是基于视觉的。
最后，嗯，我们希望我们的数据能够理解语言。
正如我所提到的，如果语言是普遍的粘合剂，那么我们的数据集已经包含了一些语言，而我们希望最终的模型是非常多模态的。
这是我们需要深入探讨的第一原则。
这意味着什么？
我们不能只是拿现成的东西。
我们可能需要从头开始设计，或者至少修改一些东西。
让我们借鉴一下我们在其他领域看到的最佳实践。
于是，我们进行了一些工作，得到了RT1的这种架构。
再次强调，这是一个由许多不同贡献组成的大团队，我将在这里简要介绍其中一些。
从高层次来看，RT1是一个机器人transformer。
它以三赫兹的速度运行。
它从机器人的RGB摄像头接收视觉输入，以及自然语言指令。
在那里，图像被转换并输入到一个高效的网络标记器中。
然后传入一个令牌学习器，我马上会谈到。
然后还有语言指令被标记。
然后它们被放入同一个transformer中。
最后，我们将离散化的动作作为令牌输出，并以三赫兹的速度发送到闭环中的真实世界中。
这个 transformer 是一个解码器。
我们使用了稀疏的分类熵目标函数来进行动作预测，通过应用因果掩码。
我们使用了预训练的 efficient net 骨干网络。
我们还使用了 TokenLearner 来加速推断。
再深入一点。
哦，抱歉。
是的，一个问题。
很棒的问题。
所以图像 token，在输入时，每个图像都是来自摄像机的高保真 RGB 图像。
我们将其分成了 81 个单独的补丁。
因此，每个补丁，你知道，它的空间就像方形那样。
但酷的是，token learner 在这里做的事情，这个东西，是我们团队先前的工作，它接收了大量可能的图像补丁，并动态地选择在任何给定上下文中更相关于手头任务的哪些图像补丁 token。
所以从这 81 个图像补丁 token 中，我们对其中的八个进行了子采样，以用于推断。
而且这一过程发生在每一个时间步骤。
该过程已经学会了在任何给定时刻哪些八个补丁是相关的。
否则我们会发送太多的标记，上下文长度会爆炸，我们将无法对机器人进行推理。
我们还传入了一个长度为六的图像序列。
当你在现实世界中进行时间上连贯的任务时，历史是非常重要的，物理学和物体相互关系以及与你的机器人的关系等细节真的很重要。
总的来说，模型的大小是3500万个参数，比很多其他庞大的互联网规模模型要小得多。
最后，这里的一个主要区别是动作离散化。
在此之前，我们的许多产品都采用连续控制。
而且，如果你考虑一下，我们的机器人确实进行末端执行器姿态控制和位置控制。
在那里，现实世界是一个连续状态空间。
但是，为了做到这一点，我们必须提出许多算法上的新颖之处。
例如，一个进行连续动作空间采样的CEM演员，以提出由Q函数评价的最高动作。
我们这样做两次，blah，blah，blah。
但是这是如此敏感，我们需要这样做才能让事情正常运行。
但现在我们刚刚决定，让我们只是将我们的行动放入垃圾桶。
只有256个离散的动作。
让我们将它们预测为令牌。
有任何问题吗？
是的，我要问的是，你提到你有关于速度和延迟反应的设计要求或工程要求。
你说这需要一个相对较小的模型，这是有道理的。
但在我们谈论基础模型时，扩展的一个信息是我们不希望被数据或参数数量所拖慢。
所以我想知道的是，你如何在你想要拥有大量参数和一个非常强大的模型的同时保持平衡。
嗯，另一件事是你想要非常快速。
是的，好问题。
为了重复一下，问题是，我们在推断时间方面设定了一个非常严格的限制，但在基础建模时的许多教训是你不应该对自己施加任何限制，无论是数据集大小、计算还是模型容量。
我认为我最初的回答是这是一个非常好的观点，我认为这将成为未来的一个严重瓶颈。
但对于我们最初的案例，我认为这更多是对这些原则进行探讨，甚至扩展到我们现在所看到的可能工作的更大范围。
已经有了这3500万，与之前使用的很多工作相比，例如 ResNet-34 等，这已经是巨大的了。
所以，这已经比很多其他选择要大得多。
也许至少现在来说，这是我们在短期内可以达到的最大规模，而不必考虑更多的技巧。
我想我更感兴趣的是，天哪，我明白了，是的，我们可以稍后再谈谈，也许我也很想听听你的想法，因为我们如何克服一些这些瓶颈是非常不明显的。
一。
年。
但其他一切。
您认为您看到了明显的。
在当前管道中的人类行为，仅仅是更大的模型，还是您认为除了像规模化和预算限制之外，还有其他因素？
是的，很好的问题。
我们对模型大小进行了一些消融实验。
我可能在几张幻灯片中有这方面的内容，但也许我们可以稍后回到这个问题。
如果不行，我也可以，是的，但是很好的问题。
嗯，这就是架构，我会稍后讨论一些消融和趋势，但也许，你知道，这是一个机器人结构，我应该给你看一些漂亮的视觉效果，对吧？
所以让我们看看我们做的一些评估。
我们与一些基线进行了比较。
一个是 Gato，你可能熟悉。
然后另一个是 BC0，基于 ResNet 的一个。
我们发现我们评估了未见过的任务与未见过的任务。
我们还添加了各种干扰对象。
我们的正常数据收集看起来像是左上角的这张图片，在一个灰色的桌子上放着三罐头。
基本上就是这样。
但是然后我们进一步推动它，加入了更多的对象，以至于桌子上杂乱无章，甚至作为人类有时候也很难找到你实际正在寻找的物体。
我们添加了桌子类，使纹理非常不同。
我们把它带到了全新的微型厨房，配备了全新的表面，发现 RT1 比这些其他不同的方法更加强大。
所以，抱歉，我只是要回答第一个问题。
Gato 数据是否训练了这个模型，还是 Gato 数据只是针对这个特定的机器人硬件进行了训练？
好问题。
问题是，Gato模型是否在我们的数据上进行了训练，还是已经包含在Gato中？
答案是，这些数据不包含在Gato中，所以我们只是在我们的数据上重新训练了Gato模型。
而且，是的，这里只是机器人在我们的微型厨房里出去做一些不同有趣的事情的另一种可视化。
你可以在这里看到，它是在一个设置上进行训练的，但然后它进入一个全新的厨房，全新的台面，新的物体，它能够相当稳健地完成所有这些任务。
我们还将其放入了一个长时间跨度的设置中，使用我们接下来要讨论的SACAN框架。
但在这些设置中，很多都是在混合所有这些泛化能力。
在这里左边的图表上，我们使用了我们称之为泛化水平的东西，受到了VIMA论文的启发，这些泛化水平基本上会同时改变更多的变化因素。
在这里，我们发现RT1是最稳健的。
是的，好问题。
我们稍后会详细介绍一些，但我认为在一个较高的层次上，远程操作员会得到一个结构模板，类似于动词，名词，动词，或者像是，像是拿可乐罐，或者把苹果移近海绵之类的命令。
他们以这种方式设置了大约700个任务，然后他们继续收集数据，测试完成。
然后，稍后我们确保成功的确是成功的，并且我们丢弃掉一些东西。
就像不安全的一样，例如。
哦，是的，为了这篇论文。
我们利用了130,000个演示来完成这项工作。
是的。
是的。
很好的问题。
我认为很多先前的工作也注意到，例如，问题是，你是否发现数据集中的轨迹是非常多模态的。
我认为你的意思是，要从A点到B点，我可以向左走，也可以向右走，也可以直走。
我认为这种多样性基本上是针对单个图像状态的，但是我的数据集有三种可能的标签，有时可能会产生非常糟糕的影响。
对于我们来说，我认为因为我们使用的是远程操作演示，所以数据比野外可能更为均匀，例如，有一种数据函数称为播放数据，操作员只是随心所欲地做，我们事后进行标记。
我认为我们的数据比那更加均匀。
但是我们并没有发现之前项目中出现的许多问题。
一个潜在的答案可能是它可能是架构本身。
但是我们可以稍后讨论这个问题。
很好的问题。
我们实际上确实有一个终止动作。
所以政策本身。
所以问题是，你如何确定一个情节何时完成？
而且政策能够预测终止，因为在每次远程操作会话结束时，操作员都可以点击一个按钮，标记为，情节完成了。
如果我从我的实验中拿走了那个，而我没有参与其中呢？
是的，我认为对于这些评估，我们是非常严格的。
但是肯定地，在某些情况下，也许如果我们只是为自己做实验，我们会有一个密集的奖励规模，比如，抓住物体并移动更近，抓住物体并几乎到达目标但最后出错了，我们会有一个类似于分级曲线的东西，但对于这些所有的统计数据，我展示的这些，要么是零要么是一，一个是完全完成，零是没有完全完成的，我认为令人兴奋的也许是谈论多模态方面，然后我们进一步推动了极限，我们决定在非常多样化的数据分布上进行训练，你回来了，对，好。
所以现在，你看到了训练在这台日常机器人上的 130,000 个演示，这是一台专有的移动机械手。
但是我们也在寻求在非常不同的数据分布上进行训练，具有非常不同的动作分布，非常不同的轨迹，甚至非常不同的视觉，物体，任务。
为此，我们包括了另外两个数据源。
一个是模拟数据，这在某种程度上是我们的机器人，但在 SIN 中，但外观有很大不同。
而且，这些数据是通过强化学习收集的，而不是通过远程操作演示收集的。
过去，我提到的所有雅思加强学习工作中，我们发现将这两种类型的数据结合起来是非常困难的，因为强化学习数据具有非常短的行动。
这非常迅速，非常优化针对特定的奖励函数，而人类收集的远程操作数据更加像人类，可以这么说。
最后，我们从2018年的许多年前重新启动了数据集。
如果你还记得库卡项目，那个机械臂农场现在已经多年没有运作了，但我们仍然保留了那些数据。
所以我们希望看到，一个不同的机器人，具有不同的动作空间，不同的物体，不同的视觉，不同的建筑物，仍然可以与我们最初训练的这个微型厨房数据集的数据相结合。
对我来说非常惊讶的是，R2-U1能够从所有这些非常多样化的数据分布中学习。
我以前从未见过这样的结果，例如，也没有其他架构，甚至其他学习方法像强化学习可以成功地在如此不同的数据分布上学习。
因此，我们进行了评估，例如，在组合概念方面，所以我们会让原来的日常机器人捡起只在项目中见过的物体。
或者我们只放入在模拟中看到的对象，并查看我们的策略是否能理解这一点。
所以它似乎可以在其他数据集中泛化对象和概念之间的联系，并将在其他数据集中看到的概念引入到现在的微型厨房中。
这是一个非常有趣的结果。
我有一个问题。
你是如何找到日常机器人的行动空间的？
好问题。
是的，我们只是对其进行了标记，并确保标记方案是可以互操作的。
我认为稍后我可以深入探讨这个问题。
是的，没错。
请注意，这并不意味着我们可以将一个机器人的确切动作发送给另一个机器人并让其执行。
这只是在数据集中，我认为甚至通过人工检查，你可以发现这些是来自两个不同的机器人。
所以，让我们看看我们现在都在这里的缩放规律的一些消融。
我们发现减少数据量会降低性能。
但更有趣的也许是任务多样性非常重要。
在这里，我们有两种不同的趋势。
绿线显示的是当你减少每个任务的总数时会发生的情况。
然后在这里，紫色曲线是当你减少任务总数时会发生什么的代表。
我们发现，拥有更多的任务相对于每个任务拥有更多的数据更为重要。
我认为这是一个可能会建议我们应该进一步扩展机器人技术的方式的教训，不仅仅是收集相同任务在相同设置下的更多数据，而是走出去，获得更多样化的行为。
好问题。
问题是你如何定义数据多样性？
在这个案例中，它只是遥控操作者接收到的唯一结构化模板命令的数量。
所以那700个模板命令，当我们开始减少它们，只训练500个或只训练300个时，性能下降的速度比我们采取相同比例下降的速度要快得多，所以我猜我对它非常熟悉。
因此，它看起来几乎像是大学的一种新方式。
是的，我不认为我们的问题是，数据大小和成功率之间似乎几乎有线性相关。
而我认为你知道，我们可以应用一些像你知道的，比如缩放法则，你知道，尝试曲线拟合，但我们没有过多地研究，因为你知道这是一种我们有点预期的趋势。
我们只是不确定它会对我们产生多大的影响，我觉得我对此没有真正的深刻见解，除了我们凭经验看到这种现象。
是的，好问题。
所以，问题是，也许这会无限期地继续下去，或者是关于2023年1月有什么神奇之处。
我认为这也许是我们开始将算法探索与实际考虑到扩展现实世界操作混为一谈的时候，当我们获得足够的数据时，我们的策略达到了，你知道，接近100%的饱和点。
我们说，好吧，让我们收集另一组数据。
所以我们基本上一直收集，直到它达到100。
然后我们转而做其他事情。
但有趣的是，在这一点上，我们对这个rt1架构押注很大，我们已经收集了一段时间的演示。
所以有可能我们收集的比我们需要的要多。
而且在某些情况下，实际上，您可以削减任务而不会失去太多性能，这是非常有趣的。
但总的来说，你将不得不获得三个数据，这可能在不同路径之间更为多样化。
有一些多条轨迹使用相同的路径。
是的，我的意思是，如果你只是在所有路径中使用相同的对象或者相同的视觉场景，但是考虑到感觉，我知道你可能会有问题。
是的，是的。
好问题。
问题是，是否所有任务在学习不同行为的能力和熵方面都是相等的。
是的，这绝对是真的。
有些任务要容易得多。
我们有一个任务就是拿起这个物体。
相比之下，它可能没有那么多有趣的东西可以挤出来，比如，把东西移到抽屉里然后关闭抽屉。
但是，是的，好问题。
好的，现在是消融实验。
我们还进行了没有大模型尺寸的训练。
我们没有进行预训练，没有使用离散动作，而是使用连续动作，没有历史记录，也没有使用Transformer。
我认为所有这些设计选择似乎都是必需的才能获得强大的性能。
哦，是的，当然。
是的，我觉得我所有的意思，就像而且，你知道，对于写论文来说，这似乎是我们可以从经验中找到的最好的事情。
那就是方法，然后我们会弄清楚为什么这些每一项都很重要。
所以，是的，我想这里可能有一个令人惊讶的事情，即自回归动作是有害的。
你可能会认为传入更多信息总是比传入更少信息更好。
但在这种情况下，也许在你之前的行动上进行调整实际上是在进行一种上下文学习。
它正在进行在线系统识别，以找出这些数据来自哪个遥控器，以及你如何可以过度拟合到那个特定的行动历史。
因此，删除那部分实际上更好。
有趣的一点是。
好的，然后。
也许为了时间的利益，我会尽量更快地浏览其他内容，然后我们也许可以在最后回答一些问题，如果可能的话，这样我们就有时间浏览所有内容。
接下来的工作，略微偏离了技能学习，而实际上转向了规划层面，我认为第一个项目借鉴了其他领域的设计原则和这种离线机器人学习范式，并将其融入到技能学习中。
我们是否可以将这个现在带到机器人系统的其他部分呢？
而这里的第一个工作就是SACAN。
如果你还记得，回到2022年的时间线，我们开始思考，哦，是的，我们如何扩展这种多任务模仿学习呢？
但与此同时，大型语言模型和其他类型的基础模型真的开始蓬勃发展，无论是Imogen还是Dolly2。
我们确实想弄清楚如何利用它们。
我们已经提出了这个我们寄予厚望的RTU2 .1设计，但从这里开始，我们开始探索如何在我们的全栈系统的上下文中利用基础模型。
这样做的问题是，天真地做这件事是不合适的，因为语言模型并不完全适合机器人。
例如，如果你是厨房里的机器人，你问一个语言模型，我把我的饮料洒了，你能做什么？
语言模型会给你一些不太相关的东西。
它会要求你吸尘。<SENTENCE_END>
它会要求你叫清洁工或者会道歉。<SENTENCE_END>
这些都不是机器人在你的厨房里应对你溢出的饮料所能做的事情。<SENTENCE_END>
那么，这就有两个问题。<SENTENCE_END>
一个问题是我们的机器人是受限制的。<SENTENCE_END>
它们在能做的事情上非常受限。<SENTENCE_END>
它们不能做所有的事情，但它们可以做一些事情。<SENTENCE_END>
然后第二个问题是语言模型也是受限制的。<SENTENCE_END>
它们不知道机器人看到了什么。<SENTENCE_END>
它们不明白它们身处一个机器人身体里，在一个微型厨房里需要在现实世界中做真正的事情。<SENTENCE_END>
所以我们需要让机器人说语言模型的语言，然后让语言模型说机器人的语言。<SENTENCE_END>
为了做到这一点，我们在相同的环境中呈现 Shacan。<SENTENCE_END>
请在桌子上放一张餐巾。<SENTENCE_END>
我们评估语言模型在我们知道机器人已经接受训练的一系列受限任务上的预测。<SENTENCE_END>
然后我们还采取了机器人的可供性函数。<SENTENCE_END>
一个功能函数是对于某种状态，机器人能够做什么以及它有多有信心能够在给定状态下成功完成任务的估计。
在我们的情况下，我们使用类似于强化学习中价值函数的东西，它有点包含了这种质量。
考虑到这两个值，这两个分数，我们有来自语言模型的信心，然后是机器人的信心。
我们可以将这些结合起来，然后希望合并的预测既对于高层指令来说在语义上非常相关。
找到一个苹果是请把一个苹果放在桌子上的第一步，但这也是机器人可以做的事情。
画面中没有机器人，但它知道它被训练去找苹果，所以它可以绕着找到它。
因此，希望我们可以在闭环中做到这一点，然后继续并预测语言模型的高层计划，该计划以机器人理解的功能函数为基础。
这里有一个SIGCHAN在做不同的事情的视频，但乐意稍后线下分享。
这非常酷，相信我。
这是我传播以来最棒的事情。
是的，然后一些数字。
我们在微型厨房中测试了超过10个独立导航和操作技能的非常长的视角指令，这些指令显示在右下角。
我们对此进行了数百次不同的评估，测试了许多不同的概念，包括重新表达，使用单一基元，通过绘制来自同事和朋友的指令等。
我们发现，在语言模型规划方面和执行策略方面都存在失败的情况，其中它会为当前情况预测错误的路径，即使在得到良好计划时，机器人有时也会出错。
总体而言，它仍然表现得相当不错。
现在让我们把这个带回到课程。
我认为这是一个很好的例子，说明我们如何利用互联网规模的基础模型，尤其是在它们变得更好的情况下。
当我们启动项目时，我们使用了一个名为Flan的Google语言模型。
在我们的实施过程中，Palm上线了，Pathways语言模型。
当那发生时，我们只需将其插入，性能就会免费提高，而无需做任何事情。
通过仅假设语言是API，计划只需是任何字符串。
它可以来自任何来源。
它可以来自人类。
它可以来自语言模型。
当我们改进那个语言模型时，系统整体变得更好。
在这里，您可以看到随着模型 LLM 的增大，我们的规划性能甚至变得更好。
还有一些酷炫的技巧，让它正常运行。
那么，我们实际上是如何生成这个计划的呢？
嗯，只是通过提示，就像这些天随着思维链的丰富以及更好的提示，只是给出一些伟大的机器人计划的例子。
现在，给我一个以这个高级指令开头的新计划。
我们看到机器人能够做所有事情，从理解不同的语言到要求它们进行非常复杂的推理，比如说，给我一些含咖啡因的东西，或者我不再摄取咖啡因了。
或者给我带点更好的，或者给我带点不健康的零食。
Seikan 能够通过所有这些进行推理。
但我认为那是我们团队与语言模型的第一次接触。
这是两个世界如何重叠的第一次探索。
肯定还有改进的空间。
所以在独白中，我们试图通过引入视觉语言模型进一步改进这些。
这里的想法是，你知道，我们在SACAN方面取得了非常高的计划成功率，但不幸的是，它并没有真正能够从失败中恢复过来。
我的意思是，语言模型实际上并不会得到世界上正在发生的事情的更新，所以如果它提出了这个计划，去桌子上拿一罐可乐给你，但你弄错了拿可乐的方式，把它掉在地板上了，它仍然会继续尝试把它拿给你，放到一边，但所有这一切现在都不再重要，因为你把可乐罐掉了。
所以在这项工作中，在我们的独白中，我们真的希望找出如何将来自环境的闭环动态反馈加入到这个规划过程中。
让我们以完全相同的例子为例。
现在，我们不仅直接打印每个指令，也许我们还可以从场景中添加一些反馈，这些反馈也可以用语言作为通用API来传达。
场景可以告诉你实际上有什么在里面。
也许机器人现在会问一个问题，而这个问题是一个语言模型在询问澄清问题，也许会听到一个人类的回答或另一个语言模型的回答。
然后，一旦学习模型具有足够的上下文，您可以预测动作或下一个要执行的任务。
或许您甚至可以添加一些诸如成功检测之类的东西，等等。
那么我们该如何做呢？
嗯，我们首先要实现的是我们所称之为被动场景描述。
只需使用现成的工程启发式，使用对象检测模型，例如Vylde，您就可以用文本描述场景，并将所有上下文传达给语言模型。
对于主动场景描述，这可能类似于视觉问答，如果您熟悉该领域的话。
语言模型实际上可以提出其在场景中感兴趣的主动查询，也许是为了确保它有足够的上下文来继续进行。
在这里，可以由人类提供答案，或者在将来，随着VQA模型的改进，它可以提供答案。
最后，对于成功检测，这对于让语言模型规划者知道何时重试某事非常重要。
在这里，我们接收第一张和最后一张图像，微调一个Clip成功检测器，并使用它向我们的语言模型提供二进制的成功或失败信息。
就结果而言，我们可以看到一个非常相似的SACAN长期评估，但有趣的是，我们实际上能够在机器人上实现所有这些不同的自动化反馈机制。
所以它能够推理并从中恢复。
在这里你看到，它会试图走向桌子，但人类实际上一直在说，嘿，我改变主意了。
然后它改变，人类再次改变主意，要求它来回走动。
机器人能够，你知道，也许在某种程度上我们正在折磨语言模型，但语言模型能够重新规划，并确保满足人类的意图。
我们还尝试过，我不确定这个视频是否显示了，一些敌对的输入情况，我走来走去，不停地敲击机器人手中的物体，强迫成功检测器告诉它，嘿，你弄错了，再试一次。
我们还在几个不同的领域尝试过这个，一个是模拟桌面操纵领域，另一个是真实世界的操纵领域。
我们发现这比SACAN要好得多，或者说仅仅使用视觉特征和类似剪贴板的东西相比更好。
而我认为在这里，嗯，这确实表明了我真的很欣赏的一个趋势。
嗯，在2018年，一位机器人学教授曾经说过，当他们审视所有不同的事物，阻碍机器人学习大规模扩展的事物时，他认为瓶颈在于高层语义规划，即关于常识推理的思考。
我认为在2022年和2023年，语言模型可以提供一种路径，说明这可以在某种程度上卸载，至少在过渡期内是这样。
我认为如果语言模型是API，那么当目标检测器变得更好、成功检测器变得更好、VQA变得更好，语言模型变得更好时，你可以将它们全部引入，并且它们充当一种救生衣。
如果你的机器人目前没有常识推理，这些其他模型可以充当脚手架和救生衣，使你达到他们当前喜爱的水平。
也许将来你会超越语言模型的知识，但在短期内，似乎我们可以利用它们加速我们在现实世界中所能做的事情。
现在从这一点上继续，我们已经看到语言模型如何进行规划。
我们看到了视觉语言模型如何帮助规划。
现在我们要转换一下思路，考虑视觉语言模型如何帮助机器人学习面临的其他瓶颈。
其中之一是数据收集非常昂贵。
正如我们之前提到的，我们确实有这个 130,000 次演示数据集，但是它是在一年半的时间内收集起来的，耗费了大量资源、时间和金钱，并且用了许多许多机器人。
当然，这些任务也有些受限。
我们使用了 700 个非常模板化的命令，这些是我们给远程操作员的指令，因为我们知道这样做会更具扩展性。
如果我们为每个模板化任务收集足够的数据，我们就可以完成特定的任务。
这就是之前有人问及的流程。
我们提供这个 PICH OCAD 指令。
操作员在现实世界中控制机器人，完成任务，将该情节标记为终止，然后，你知道，将其添加到这个大橙色数据集中。
这个大橙色数据集是我们在所有先前项目中用于训练控制策略的。
另外，我们考虑了添加一些众包的事后注释。
如果你对它很熟悉，回顾一下经验重演和目标调节的强化学习，你知道，也许机器人做了一些不仅仅是这种高水平的模板化指令。
我们可以请一个人更详细地描述机器人做了什么。
也许它拿起了桌子右侧的可卡因。
也许它拿起来然后把它打翻了。
也许它非常慢地将其移到了中间。
这个演示中包含的语义多样性很大程度上没有完全被这种高水平的模板化拿可卡因指令所捕捉。
所以我们用这些非常冗长的描述标记了这个大蠕虫数据集的 3%。
接下来，我们采用了在其他领域中已经看到的伪标签策略，比如视频预训练与其反向动力学模型。
但是我们把它应用于指令，应用于你的数据集中包含的语义内容。
所以第一步，我们在你的主数据集的 3% 的小标签数据集上预训练了一个剪辑模型。
然后，您可以使用那些训练好的BLM数据来标记以前的所有模板化指令演示，即那 130,000 个剧集数据集。
现在你有一个重新标记过的数据集，其中包含了许多有趣的语义指令。
然后，我们将所有这些数据集都输入到 RT1 中，只需训练一个语言条件行为克隆策略，就像我们通常做的那样，尽管通常我们只使用数据集 B，即橙色的那个，现在我们使用所有三个数据集。
最后，我们对全新、未见过的指令进行评估。
在先前的研究中，我们主要是在 700 个模板指令上进行评估。
但在这项工作中，我们实际上超越了那个范围。
你可以输入几乎任何你认为可能成功的东西，可以用你认为合适的方式表达它。
你可以添加拼写错误。
甚至可以通过引用语义概念来做。
你可以添加空间概念。
然后我们看它的表现如何。
这可能有效的原因，也许在视觉上来表示，是因为这里左边是 T-SNE 嵌入，右边也是。
它们是相同的嵌入，但在左边，它们按照用于收集该剧集的原始模板指令的颜色着色。
而右边则是视觉语言模型认为如果允许提供一个自由形式的自然语言标题并分配给该剧集的情况。
你看，左边有这些大团的可卡因，就像，你知道的，数百或数千集，但我们都只称它们为左边的可卡因。
然后我们可以扩展这些概念，并说，实际上，这一集正在捡起红色的可卡因。
这，这一集正在捡起皱巴巴的可卡因。
这一集正在捡起旁边装着薯片的可卡因。
所以你可以通过使用语言作为你考虑的概念扩展的多样性机制来更有效地利用相同的基础数据集。
例如，在中间你看到，你知道，打开顶层抽屉可以变成抓住并拉出顶层抽屉。
我们有像中间左侧的东西，用于底部一集从白碗中拿起绿色的大米片变成了从碗里拿起绿色的薯片袋，并把它放在桌子的左下角。
所以你得到了很多这些语义上的，你知道的，空间概念，现在将成为你的目标监督标签。
所以你可以写一本书。
这是后半部分。
你有你的那是重要的。
你正在看。
我认为我们有机会去。
我不知道。
那三个是什么。
是的。
好问题。
所以我想如果我可以稍微改一下，问题是实际上很困难，甚至可能是一个无法跟踪的问题，就是你如何把你在野外看到的所有语言概念映射到具体的类型的情节。
就像在这里，我可能会说我们确实把很多我们的先验和偏见引入到我们所说的左边。
你是指左边10厘米，左边2厘米，像单词的含义和这些定义，对我们来说意味着什么，对产生这些字幕的众包评分者来说意味着什么，对机器人来说意味着什么，对语言模型来说意味着什么，也许这些都略有不同，但希望至少如果它们大致相似，我们会获得方向上的正确改进。
所以我想说，这些具体的定义的微妙之处，以及这些词的实际语义含义。
我认为这也许超出了现在的范围，但也许我们会在更高的层次进一步深入。
我觉得基本上标准就很低。
我们有 700 个模板指令，基本上是 one hot IDs，我们只是想让它们更接近自然语言，即使只有一点点。
我认为至少我们正在尝试用这些自动标注的视觉语言模型来实现这一点。
我希望这能回答您的问题。
我们还与几个基准进行了比较。
在这里左上角，我们看看如果我们只在这 3% 的高级人类评级标签上进行训练会怎么样？
如果我们只在原始 RT1 数据集上进行训练会怎么样？
如果我们在这两者上都进行训练会怎么样？
如果我们在这两者上进行训练，再加上我们的 BLM 给出的所有预测会怎么样？
有趣的是，重新标记似乎在各方面都有所帮助。
我们只在对这个项目来说是新的新颖指令上进行评估。
这是机器人项目中第一次我们只测试了我可以随便输入的内容。
那就成为了测试集。
我们只需要确保它从未包含在训练范围内。
您在这里右边看到的所有有趣的例子，比如，将孤独的物体移动到其他位置。
我不知道这是怎么回事。
像举起黄色矩形这样的东西，谈论颜色，谈论将右边的苹果移动到左边。
这里实际上在场景中有两个苹果，而且在我们的训练演示数据中，我们从未收集过具有重复对象的场景，只是因为，你知道的，我们考虑到了这个多模态问题。
如果你只说拿可乐罐，而场景中有两个可乐罐，那将非常难以确定应该选择哪一个。
但是通过语言标记，现在似乎我们可以做到这一点。
所以，即使我们从未训练过含有两个苹果的场景，现在你可以对它们进行评估，并用语言指定你想要选择的是哪个苹果，而且它运行得相当合理。
最后，在这里的最后一个例子中，我觉得这很有趣。
一个单一的可乐罐，我们尝试做一种新颖的行为。
向左推动不是一个模板化的指令。
我们只有将可乐罐移动到靠近某处，其中某处是另一个对象，将可乐罐移动到苹果附近，苹果在你的海绵中。
所以仅仅将这种推动可卡因进入空气的动作是我们从未包括的，但也许它在其中一个标签中，也许像是如果你看到了将可卡因移到苹果旁边而苹果在左边，你会发现将可卡因移到海绵旁边而海绵在左边，模型可以推理并且可以像，“哦，左边意味着桌子的这一侧，而不是特定的物体。”
也许这就是正在发生的事情，但这非常不清楚。
正如我所说的，你知道，我只是，我想到了一些东西，我打字了，然后看看发生了什么。
我们确实希望将来更多地定量探索这一点。
左下角，当然，我认为是与非视觉增强进行比较。
所以也许你也可以仅从语言中得到这些有趣的概念，对吧？
在这里，我们添加了随机噪声，或者我们做马德里布式样，只是交换词语，或者我们甚至使用了一个LLM GPT-3来提出对现有说明的重新表述。
但我认为我的结论是，对于视觉语言模型来说，你真的需要视觉基础，以便说，“实际上，在这个特定的时间点，这个标题是事实准确的。”
而且这也许对机器人来说会是一件有趣的事情。
这个 fine tuning 过程同时提供了这两个方面。
是的，是的，绝对是。
这些只是五个评估指令的一些子集，但我们有超过 60 个。
我们没有像在 RT1 中那样进行完全数量的消融，例如，我们有这样一个看得见和看不见的任务集合，并且那是组合的。
你会看到，你知道，移动可口可乐靠近苹果，你会看到移动苹果靠近海绵，但我们会保留，移动可口可乐靠近海绵，并测试一下。
但在这种情况下，我认为我们可以做得更多。
因为我们的语言是完全自由形式的，你可以组合的组合空间只会更大。
所以我们确实试图回答你的问题。
我们尝试了一些组合评估，但在那方面肯定还有更多的彻底性可以做。
嗯，我的时间掌握得如何？
好的，还有 10 分钟。
嗯，也许我很快就会结束了。
然后，嗯，我要带走的是，对吧，两个部分，对吧？
第二课利用基础模型。
让我们把它们用作数据增强，小于三。
让我们确保我们的离线数据集足够健壮，您知道，其中存在这些不同的行为，并且您可以用语言描述它们。
如果您没有足够多样化的行为，无论您的标记有多好，您可能都无法引出您想要学习的所有有趣概念。
对我来说，这里可能最令人兴奋的是，实际上一些标签噪声是可以接受的。
众所周知，在监督学习和模仿学习中，您需要非常干净的标签，这些标签始终是100%真实的，对吧？
您不希望从一些大部分不准确的嘈杂数据中学习。
但在我们的情况下，似乎一些标签噪声是可以接受的。
视觉语言模型并不总是预测场景的事实准确描述。
我认为当噪声太大时，这肯定会造成影响，但在较小程度上，它似乎仍然可以接受并且足够健壮以处理这种情况。
因此，这就是对一些使用语言、基础模型和离线数据集在机器人系统不同部分的这一大配方进行了深入研究。
这就是一开始的那种提要，我希望你们至少能够看到我们的团队是如何尝试将这些原则应用到加速机器人在现实世界中学习的。
当我们看到这些不同类型的成分和教训如何整体映射到机器人系统的不同部分时。
对于技能学习，对吧，那就是我们谈论过的 R2 -C1。
对于规划，那就是 SATAN，然后通过视觉语言模型添加闭环反馈，那就是内心独白。
对于低级控制，我们今天没有谈论这个，但是我们团队的一项令人兴奋的工作实际上是使用语言模型来预测在机器人上直接执行的代码，也许作为低级控制器。
语言模型，它们阅读教科书，阅读原始股票，阅读 UR5 文档代码，它们可以为这些机器人编写代码，而我们可以执行那些代码。
对于数据增强，我们看到了一个带有视觉语言模型的旋钮。
而且，我这里没有谈论到，但是对于物体中心表示，对于像特定对象的特征激活图这样的东西，我们可以将它们用作任务表示，用于映射场景，而在 NLMAP 中，他们为我们查看的微型厨房周围的物体中心导航做到了这一点。
我认为，希望地，在接下来的几周和几个月里，我们还有几行和条目要添加到这里。
但我认为这种思维方式是一个非常令人兴奋的研究方向，它展示了你如何应用这些关于基础模型和离线数据集的大、高级概念。
当你看今天的机器人系统所存在的内容时，你会发现仍然存在许多差距和机会，我们可以从探索性试点开始，看看这可能会是什么样子，一直到更广泛的评估，真正地构建出健壮的系统。
我认为这两者都有价值。
所以我将总结，仅仅是说探索所有这些互补的方向非常有趣，但仍然存在一些重要问题，即我们如何进一步应用这些概念，以及这些趋势和想法在基础模型变得更好、更多数据集在线可用、更多数据被同质化、被标记化和可互操作的情况下如何发展。
我认为很多来自其他领域的概念，比如语言学和视觉以及所有关于在语言为基础的基础模型中开创性地提出的大规模问题。
希望这些想法可以渗透到机器人领域。
也许甚至机器人学可以通过提供具体的行为因果数据集来回馈，这可能会提高一些没有具体化的大型语言模型的推理质量。
有了这个，我想感谢大家抽出时间来，感谢戴夫和希亚邀请我，并且乐意回答关于论文的任何问题，或者也可以就高层次的问题交流。
非常感谢。
是的，很好的问题。
那么，我想问的是，那些需要更多语义推理的任务呢？比如以某种速度操作，或者可能需要数字推理在问题中自身。
我想说的是，对于很多常识推理，比如，你知道，连续扔掉三个罐子，我认为，语言模型现在在这方面做得很好。
所以对于正切规划器，它会预测，你知道，连续扔掉罐子三次。
但是对于低水平的技能策略学习，我认为那更多是更高方差的。
而且就目前而言，我们并没有真正考虑速度或者你如何做到的条件。
但是这绝对，也许是我们可以做的一些事情，如果你能重新标记，比如，慢慢拿起可乐罐与快速拿起可乐罐。
也许这是视觉语言模型可以识别的东西。
很棒的问题。
问题是，我们在什么尺度上看到像组合泛化这样的现象开始出现，也许你已经看到了一个块的颜色，然后你想在一个新颜色上进行评估。
我认为这是一个很好的问题。
不幸的是，我的答案会非常模糊。
这取决于。
这取决于你如何定义你的任务。
这取决于你数据集的规模。
这取决于你试图概括的概念。
我认为已经有许多尝试基本上将在学习和机器人学中概括的含义形式化，甚至在我们考虑的具体设置中也是如此。
我认为没有任何明确的趋势，可以说，哦，是的，这是我需要达到的数字，在这个数字上，你知道，我可以概括X、Y、Z维度。
嗯，你可以评估所有这些，但我不认为这会帮助你预测新的趋势，至少目前不会。
我认为我们可能，我知道这只是我在说话。
我会说，在我们可以开始对泛化能力做出非常广泛的概括性陈述之前，我们还差一个数量级。
我认为，你知道，再增加一个或两个零到我们的数据集大小，我们就可以开始谈论，在任务目标技能方面。
所以，嗯，嗯，嗯，嗯，嗯，嗯，嗯，嗯，嗯，非常敏锐的观察。
嗯，所以问题，问题是，在这里预测这些标量值的值函数，用于affordances，只存储了一定数量的任务。
那是瓶颈吗？
我会说是的，百分之百的缩放，你的系统能够执行的任务数量，然后可以提供给规划器作为其选择的自助餐。
那就是瓶颈，对吧？
无论你的规划器有多么出色，如果你只能做三个任务，它只能完成这三个任务的某些特定组合，以映射到高层指令。
因此，随着你添加更多任务，随着机器人的低级技能能力提高，你就像为机器人尝试执行的高级指令的覆盖范围增加精度。
这是我今天看到的主要瓶颈之一。
很好的问题。
那么你有尝试过使用RLHF或者RL进行RT1吗？
我想简短的回答是，我认为我们正在进行一些相关工作。
但是就目前而言，对于我们所有的项目，我们目前只是使用这个实现学习损失。
同样，我认为我们正在做的多任务限制是一种存在的证明。
它有效，虽然成本不低，但确实有效果并且可以扩展。
至少这是一个很好的起点。
而我们的主要希望在未来的几个月甚至几年内是能否超越这一点？
我们能够重新引入离线改进吗？
你知道，我是一个真正希望如此的RL人。
所以我可以重复一遍。
是的，好问题。
我想就任务平衡以及像仅文本数据是否足以帮助类似运动控制学习这样的问题进行讨论。
我想我希望当我们的模型经历了机器人领域和语言领域的出现时。
在某个时候，也许这些推理概念将开始在两者之间进行转移。
我会指向一篇有趣的论文，我认为，维基百科能够帮助加强并从Shane和其他一些人那里学到东西。
他们预先训练了一个大型策略网络，就像，在维基百科上进行自回归标记预测。
只有文本，并且他们使用它来初始化像Atari游戏这样的控制。
而且这确实有所帮助。
所以，你知道，也许这是哲学的，但也许决策推理之间存在着一些可以在文本和行动数据之间转移的东西。
好问题。
嗯，我完全同意。
你知道，当你执行长达几分钟的任务时，比如清洁整个房子，传入六张图像是不够的，然后你只能传入最后的两秒，像，拜托。
所以我认为，随着我们的任务变得更加复杂和长远，这肯定会是一个限制。
嗯，在这里我认为这又是另一个待解决的问题，就是上下文链。
我们有高维图像，即使使用令牌学习来减少我们通过的补丁数量。
仍然，你知道，非常高维，我们很快就达到了上下文链的上限。
我们能做到吗？
我们如何，你知道的，超越这个？
也许是像检索transformer或其他一些机制。
很好的问题。
我认为我们希望在未来探索这个。
但是由于这种上下文长度限制，仅仅使用这六张图片，我们已经接近上下文长度的容量极限，更不用说，你知道的，传递整个零样本行为、我们希望看到的少样本行为的轨迹。
所以2BD。
是的。
谢谢大家。
