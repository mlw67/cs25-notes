是的，让大家都看到演讲者备注不在计划之内，但我很高兴能在这里。
我的名字是Vivek Natarajan，我是谷歌健康人工智能团队的一名研究科学家。
关于我，再多说一点。
在印度长大，我的父母一直希望我成为一名医生，更准确地说，是一名医学博士。
但不幸的是，我可能没有足够的能力记住所有生物学教科书，你必须做的是如果你想通过医学入学考试的话。
所以我最终成为了一名计算机科学家。
但正如一个伟大的人曾经说过，你无法前瞻性地连接这些点，只有在回顾时才能加以串联。
所以通过一条相当冗长的路径，与我们实际训练神经网络的方式并没有太大不同，我最终又开始在医学领域工作，这次是带着这种神奇的新工具——人工智能。
我可以告诉你，我的父母现在对我的生活选择更加满意了。
但他们永远不会真正满足。
但是撇开这些问题不谈，我此次演讲的目标是拉开帷幕，让你们品尝到人工智能和生物医学交叉领域正在发生的所有创新的味道，以及这是如何被转换器和特别是大型语言模型所催化的。
所以我们将花几分钟的时间从第一原则开始解释为什么变形金刚和大型语言模型特别适用于生物医学数据。
然后我们将深入研究几篇论文，涵盖各种不同的生物医学应用场景。
最后，我将提出我对这个领域未来几年可能发展的看法。
尽管我的语气或语调可能并不完全表现出来，但我对人工智能和生物医学的可能性感到非常兴奋。
我认为我们面前有一个令人难以置信的机会来促进人类健康和人类潜力。
我希望在演讲结束时，你们大家能像我今天一样感到兴奋，也许会加入我。
好了，让我们开始吧。
为什么transformer和生物医学呢？
抱歉，我要选一些在场的人来回答。
也许你们中的一位可以自愿。
就这么办吧。
为什么不呢？
基本上就是你了。
那是个不错的答案。
我该去试试吗？
我们有很多生物数据。
所以就像生物数据是一个问题。
到目前为止，有很多。
是的，当然。
另外一个也一样。
医生的费用很昂贵，而且他们的工作很大程度上就像背诵，正如你所说的那样。
公司可以做一些事情。
是的，这是一个重要的应用设置。
是的，我想这只是一些事情。
是的，很棒。
所以我认为你们所有人都在正确的方向上。
所以也许如果你只是看看不同类型的生物医学数据，例如，临床记录是什么？
我认为这是吉伯利士医生的序列。
好的，我没有说过那个，但让我们就称其为医生说话或医生笔记的序列。
同样，如果你看一下电子病历，它们是什么？
它们本质上是一个人与医疗系统接触的序列。
那么蛋白质呢，深入到生物堆栈？
它们只不过是由肽键连接在一起的氨基酸序列。
有人知道这是什么吗？
去吧。
我认为那是我们存储医疗记录的方式。
哦，再次抱歉？
嗯，那就像是一个月的时间。
就像圣经中的X。
你快了。
还有其他人吗？
所以这是在伦敦的威康收藏中，实际上这是完整人类基因组的打印输出。
不，他们没有在这里作弊。
字体非常小。
正如你所看到的，有一堆ATGC。
整个打印输出包含，我想，在那个架子上有超过130卷。
每一页都是双面打印的。
而且是四号字体，每页精确地有43,000个字符。
这就是人类参考基因组有多大。
超过数十亿个碱基对。
所以再次强调，基因组实际上只是一系列核苷酸碱基对。
所以我们在这里实际上看到的是，生物医学数据中到处都是序列。
那么，用于对其建模的最佳神经网络架构是什么呢？
我想，既然你们都在上这门课，我就不用说服你们答案是transformer了，对吧？
好的，很好。
但也许我只是在这里提供一些原因。
首先，正如你们所看到的，数据本身是多模态的。
我们刚刚看到了一些例子。
正如有人指出的，transformer在处理几乎任何类型的数据时都表现出色。
而我们确实看到了在各个领域的这种显著的融合，无论是语音、自然语言处理、视觉还是机器人技术。
我的意思是，几乎无处不在地我们都在使用transformer。
而且我认为生物医学也不例外。
我认为其次，transformer在对序列进行建模时要比其他方法更有效，尤其是对复杂的长距离相互作用建模方面。
而这种性质在生物医学领域尤为重要。
我们稍后会在演讲中更详细地涵盖这一点。
最后，正如之前有人指出的，这些数据集可能相当庞大。
而且你很容易进入数十亿的标记领域。
而这就是transformer发挥作用的地方，借助其所有可并行操作和相对轻松的训练。
也许有人应该尝试在这些类型的数据集上训练LSTM和RNN。
我们会意识到，对于我们在这个领域拥有的数据集，这些方法更适合。
所以，是的，我认为还有一些其他原因。
但我认为这些是为什么transformer特别适用于生物医学数据集和任务的关键原因。
到目前为止有任何问题吗？
好的，很好。
所以在这次谈话的下一部分中，我们将深入探讨几篇将transformer应用于生物医学数据的论文。
我们将首先从临床应用开始，然后逐渐深入到生物学领域，查看蛋白质和基因组应用。
你会发现，虽然transformer和大型语言模型本质上非常适合，但通常你不仅需要在建模方面进行创新，还需要在数据和评估方面进行创新，才能使这些应用真正起作用。
所以我想在这里首先谈论的第一篇论文是我们团队最近的一项工作，名为“大型语言模型编码临床知识”。
这项工作的动机实际上非常简单。
所以如果你看看医学，它是一种人道主义的努力，语言是其中的核心，促进着人与那些为他们提供关怀的人之间的互动。
不幸的是，如果你看看迄今为止开发的许多医学人工智能系统，这些系统都是狭窄的、单一任务、单一领域的模型，缺乏互动和表达能力。
因此，结果是这些模型能做的事情与患者、护理提供者和其他人期望的事情之间存在着不一致。
而这反过来又阻止了医疗人工智能的广泛应用。
你可以看到，例如，在许多诊所中，我们实际上并没有人工智能帮助我们进行诊断等等。
但是，基于转换的大型语言模型的最新进展为我们提供了改变这一切、重新设计和重新思考以语言为核心的医疗人工智能系统的机会，从而在医生、研究人员和患者之间进行人际交流。
如果我不指出，在这个领域已经有大量的工作，特别是在过去几年中，我会感到不诚实。
在生物医学领域，已经有各种尝试用不同大小、不同目的的生物医学数据训练语言模型。
虽然这令人兴奋，但医学领域应用的质量标准实际上相当高。
因此，缺失的是实际上没有太多良好的评估基准、评估协议和框架。
所以，我们在医学上没有一个大型的工作台的等价物。
希望你们之前已经涵盖了大型工作台。
因此，这个大型基准是一个评估大型语言模型在各种任务领域和设置中的基准，但在医学领域我们没有相应的等价物。
而且，如果你看看通常在这些先前研究中使用的评估，它们只关注客观指标，如准确性或自然语言生成指标，如蓝色或苹果酸。
但这些未能捕捉到临床环境中真实用例的细微差别。
因此，我们实际上需要一个好的基准，一个任务，以及一个评估这些模型的良好框架。
因此，为了满足这一未满足的需求并评估LLM在医学中的潜力，我们的团队决定专注于医学问答任务。
为什么？
因为回答医学问题实际上是非常具有挑战性的。
它需要阅读理解能力，准确回忆医学知识并对其进行操作和推理能力。
而且，问答任务是足够通用的，可以包含一系列不同的应用场景，如临床笔记摘要、临床决策支持，以及患者关注的初级护理分类等。
所以我们已经确定了这个任务。
下一个问题是什么数据集？
当我们查阅文献时，我们发现有几个数据集在不同的情境中评估模型的能力。
所以我们决定，我们可能应该将它们统一起来，放在一个基准中。
于是我们这样做了，并将其称为Multimate QA。
所以，如果你看一下，这个基准现在涵盖了医学问题回答数据集，涵盖了许多不同的设置，比如专业医学问题，比如美国医疗执照考试风格的问题。
它还包括医学研究问题，那些基于PubMed、摘要等的问题。
还有来自实际用户和消费者询问医学信息的问题。
并且设置可能会改变。
它可以是封闭域或开放域，模型可能被期望在一个设置中产生长形式答案，而在另一个设置中可能产生短形式答案。
最后，我们发现虽然问答数据集涵盖了消费者的问题。
是的，去吧。
我有一个快速的问题。
你如何评估这个模型？
我会回头再说。
所以，是的，非常快地。
最后，当我们看到...
抱歉，还有一件事。
在Zoom上的人可能无法亲自提问。
所以有任何问题。
好的，很好。
所以问题是，我们如何评估长篇回答？
稍后我会回到这个问题。
所以很快，当我们查看那些实际提供消费者医疗问题的数据集时，我们发现它们的规模相当小。
所以我们决定进行增补。
于是我们去Google，查看了最常见的消费者医疗问题。
所以我们策划了一个数据集，并将其添加到基准中，我们称之为健康搜索问答。
所以，是的，再说一遍。
组合体有多大？
我会回来报告统计数据。
我相信。
所以这里有一些例子。
所以如果你看消费者医疗问题，它们非常简短而主要。
所以它们来自健康搜索问答和生活问答数据集。
而如果你看美国医师执照考试风格的问题，这些就像是长篇小品。
所以医生必须非常非常仔细地阅读它们，并得出正确答案，这通常涉及一个排除的过程。
所以，再次，非常非常不同的应用设置。
因此，模型必须真正适应并理解任务，以在各种设置中表现良好。
Life Q &A很有趣，因为这里的答案，参考答案实际上是由图书馆员提供的。
所以这是我们继续前进的又一个好的比较点。
因此，在统计方面，我们在这个基准测试中共有七个数据集。
正如我所说，我们涵盖了专业医学、医学研究和消费者医学问题。
再次说一遍，它们大小各异，可以是长格式、短格式、开放域和封闭域。
所以非常多样化。
我认为这在医学问题回答设置中提供了非常全面的模型评估。
所以我们有任务和基准测试。
下一个问题，我想我问的是我们如何评估这些模型？
正如我之前提到的，自动化指标实际上是非常不令人满意的，因为它们未能捕捉到现实世界临床应用的微妙之处。
所以我们所做的实际上受到了Stephen一些工作的启发，他在这方面做了一些工作，我们将一个人类评估框架组合起来，用于评估这些长篇回答。
这有两个部分。
第一部分是由临床医生评估，我们要求他们对这些回答在12个方面进行评分，涉及回答的事实性，回忆医学知识的能力，医学推理，以及这些回答中的潜在危害和偏见。
但如果你看看这些医学问答系统的潜在最终用户，他们很可能是非专业的普通用户。
因此，让他们也对这些答案进行评估同样重要。
因此，我们还额外询问了一组普通用户，询问他们认为这些答案有多有帮助和可操作。
这就是我们的评估框架。
而且，我们也有了基准。
现在我们进入构建和调整语言模型到医学领域任务的有趣部分。
所以在这项工作中，我们决定建立在PALM语言模型系列的基础上。
在课程中之前有提到过吗？
好的，很好。
所以但是非常迅速，我相信这仍然是最大的公开宣布的、密集激活的解码器 - 仅大型语言模型，最大的那个总共有 400 亿个参数。
再说一些细节。
该模型在 7400 亿个令牌上进行训练，其中 25% 是多语言的。
数据来自多种不同的来源，包括社交媒体对话、网页、书籍、GitHub 和维基百科等等。
在发布时，该模型在许多自然语言处理推理基准上表现出色，并且还是第一个在 BigBench 上超过平均人类表现的模型。
此外，在过去的一年里，PALM 衍生的模型被证明在许多不同的应用场景中非常有用，包括代码生成（PALM 编码器模型）、机器人技术（PALM Seikhan 模型）以及回答数学和科学问题（Minerva 模型）。
因此，我们认为 PALM 是我们在医学领域建立基础模型并使用的很好的基础模型。
总的来说，我认为 PALM 是一种真正的工程奇迹，但我会建议大家阅读 Akansha 的论文以获取更多细节。
我认为这是必读的。
去年十月底，Jason Wei 和几位 Google Brain 的同事推出了 PALM 模型的 FLAN PALM 变种，基本上这是调整后的版本。
而且这个模型甚至比 PALM 还要好，我相信在许多基准测试中仍然是最先进的，比如 MMLU，TidyQA，我认为它在 BigBench 任务中的性能平均超过 PALM 9.4%。
因此，我们决定在 FLAN PALM 模型的基础上进行改进，并应用了一系列提示策略，包括少量提示、思维链推理，以及自一致性到这个 5400 亿参数的变种，并在具有短格式多选题的多媒体 QA 数据集上进行了评估。
我们发现这个模型确实非常非常好。
在发布时，这个模型在 USMLE medQA 数据集上超过了以前的最先进技术超过 17%。
这是特定于短格式价值吗？
只针对 USMLE medQA 数据集。
那是一个多选题。
没错。
因此，您会看到在发布时相对于以前的最先进技术，准确度提高了超过 17%。
我相信这是第一个基于LLM的人工智能系统，获得了及格的等效分数，即该基准测试的60%以上。
同样地，当我们查看基准测试中的其他MCQA数据集时，例如MedMCQA，这是一个印度医学入学考试题库，该模型再次处于最先进状态。
在PubMedQA上，这是基于PubMed摘要的问答，该模型在出版时同样处于最先进状态。
而在MMLU临床主题上也是同样的情况，其中包括遗传学、解剖学、专业医学、临床知识以及其他一些主题。
所以这一切都很棒。
然后，当我们开始查看扩展图时，我们看到的是随着模型从80亿到620亿再到5400亿的扩展，性能似乎在提高。
因此，这基本上表明，这些在公共互联网上训练的通用大型语言模型似乎很好地编码了临床知识。
它们的医学推理能力也倾向于随着模型参数大小的增加而提升。
我们还做了另一个实验，当我们进行选择性预测时。
我们使用自我一致性委员会确定何时有所不同。
这在临床环境中非常重要，因为医生在不了解某事时进行交流。
如果我们的AI系统将在临床环境中使用，例如用于诊断，它们应该能够在不了解某事时告诉你。
因此，我们在这里观察到的是这个相当粗糙的度量标准。
随着我们改变推迟阈值，性能呈线性改善。
这其实很好，但在实践中却相当低效，因为你要生成多个解码样本来计算这个度量标准。
所以我们需要一种更好的方法。
只是为了明确一下，不同的分数是什么？
那就是你发现模型提问的分数是什么？
是的，基本上它表示我不确定或不知道，这是根据自洽度板确定的。
我明白了。
好的。
所以你不必在自洽度样本中产生高方差，对吧？
确切。
确切。
那么模型是否被训练成能够推迟自己？
不是的，因为它们只是在这个下一个单词预测任务上进行训练，而这取决于数据集。
PubMed QA的一些答案可能是，但同样，我们并没有明确地对这些模型进行微调。
所以，这些模型并没有经过训练。
所以这就是我们在世界上遇到的医学问题。
那么，然后我们基本上有一个临床专业人员来评估输出是否正确以及事物的发展方式。
不，这主要是基于数据集中的参考，这就是所有的准确性度量。
所以我们已经知道在四个选项或五个选项之间，哪一个是正确的。
所以我们只是进行分类。
所以我稍后会回到临床评估这一点。
抱歉，也许我漏掉了什么。
你是如何测量不确定性的？
所以如果你知道自一致提示是什么，我们所做的是从同一模型生成多个解码。
然后我们看最高排名答案被投票的次数。
基于此，您可以设定一个阈值并说，如果低于此数字，我将推迟处理。
所以如果说在您的自一致解码中，大多数答案只有N次出现在K次中的话，如果N太小，那么模型很可能是不确定的。
这就是我们推迟的方式。
所以你不会真的在这个图上看到一个像纸一样的东西，所以不确定接下来的图会是什么样子？
我认为如果你进一步绘制，会出现水平线。
但是，再次强调，这并不是有用的。
我的意思是，如果你对每个问题都说不，那一点也不有用。
所以你想要有一个合理的推迟百分比。
是的，像0.4、0.5这样的数值还不错，对吧？
我认为那太高了。
我觉得那仍然很高。
50%相当高。
但是，再次强调，这是一个非常牵强的情景。
但是在真实的使用情况下，我认为那个数值应该低得多。
所以假设你正在使用第一个算法，我想知道是否可能有一些新的数据，比如一些比其他更重要的医疗产品。
所以已经有更多的问题涉及到这一点了。
所以我们会使用那个。
我不知道，这非常重要。
没错。
我觉得平衡准确度可能是一个更好的度量标准，但是我们看了一些这些数据集。
有一个数据集，偏差非常严重，PubMed QA 数据集，我觉得没人应该使用它。
所以如果有人报告了这个数据集上的某种数字，你应该不信任他们。
我在谈论非常特定的人。
但我再说一遍，我认为，正如我所提到的，这些准确度指标对于宣传和推动基准数字等方面是有好处的。
但真正的评估是对长篇回答的人类评估，这是我接下来要谈到的。
到目前为止，一切都还好，对吧？
我们在这些基准测试中得到了一些结果，我们非常高兴。
所以我们做的事情是，我是说，到目前为止，我只报告了多项选择问题、短篇回答的结果。
所以我们剩下的事情就是拿这些模型，生成其他数据集的长篇回答，并让人类对它们进行评估。
我认为那才是真正的项目开始的地方。
当我们看到专家和普通人的演变时，它揭示了长篇回答中的关键差距和限制。
我们经常看到这些模型在产生幻觉或产生不完整的回答。
当我们询问专家们他们是更喜欢临床医生生成的答案还是这些模型生成的答案时，他们几乎总是更喜欢临床医生生成的答案。
所以很明显... ...这些是外行人还是这些...
他们都是。
因此，这些先前的结果表明，虽然这些模型已经编码了一定程度的临床知识，但要真正在实际的现实世界环境中使用，你需要更好地将这些模型与医学领域的安全关键要求对齐。
但一个重大挑战是我们没有任何监督或反馈数据，所以我们确实需要数据高效的对齐技术。
但幸运的是，我们有指导提示调整，这是由Brian Lester和谷歌的几个其他人在几年前引入的。
这种方法的工作原理是基本上冻结大型LLM模型，只学习额外的一小组提示向量，然后可以在生成时在推理过程中用来调整模型。
而这种方法的好处在于，它允许在各种任务和领域中非常容易地使用模型。
而且你只需要携带这些额外的提示参数。
而且这些往往比LLM中拥有的数十亿参数要小得多。
而另一件好事是这也非常计算高效。
因此，如果你要进行端到端的微调，在我们的计算基础设施中，即使有几千个例子，那也需要几天的时间。
而使用指令提示微调，由于数据集大小也减小了，你需要的例子数量相当少。
而且只更新提示令牌向量，意味着我们能够在几小时内得到模型更新。
所以这真的很快，使我们能够进行非常快速的迭代。
这就是我们组装最终的MetPalm模型的方法。
抱歉，请继续。
抱歉，我会让你完成我要求的一切。
好的，很酷。
这就是我们组装最终的MetPalm模型的方法。
所以我们使用了来自专业临床医生小组的指令和范例。
而这些数量大约是几百，而不是几千或几万。
你在那里看到了一些例子。
有一条指令，后面跟着是一个模型答案，然后是一个解释。
我们使用这些来学习提示向量。
所以最终的 MetPalm 模型基本上就是 PlanPalm 加上这些额外的软提示向量参数，这些参数用于使模型与医学领域的要求对齐。
为什么这样运作得很好呢？因为正如我们之前看到的，该模型已经在其中编码了医学知识。
我们所需做的就是教会模型如何在给定的应用场景中正确使用它。
这就是这些提示参数为我们所做的。
所以我想问的问题是，现在你可能会看到关于 RLHF 的模型。
鉴于你们评估者表达的所有这些人类偏好，你们是否解释了奖励或偏好模型，并使用它来找到某些东西？
是的，我认为你可以考虑模型开发的不同阶段。
这是部署之前和在现实世界中发布。
所以你不能在现实世界中发布一个糟糕的模型。
所以即使在那之前，如果你能从任何专家那里得到大约 100 个例子，并用它来提示你的新模型，那将是一个更好的起点。
在将模型暴露给现实世界并在规模上收集真实用户的偏好之前。
所以我认为RLHF在样本效率上也要比指令提示调优低得多。
同样，因为您可能正在尝试更新整个模型。
所以我认为这是一个非常好的起点。
因此，它们可以根据模型的生命周期进行组合。
人类评估是公开的吗？
数据集是公开的。
我会稍后谈论结果。
不，抱歉。
人类评估是否公开包含在数据集中？
您是指模型响应以及人类评估是什么吗？
这是一个很好的观点。
到目前为止，我们没有考虑发布它们，但也许我们可以。
您认为有用吗？
嗯，只是我在想，您在实践中有大量数据。
那么训练一个模型，表达这些实践，并在医疗治疗中使用该模型进行RLHF。
所以如果我想训练一个奖励模型，那就是我需要训练的奖励模型的数据。
是的，这是一个很好的观点。
我认为评估数据集是的，稍后我会谈论这个。
它还很小，但我认为如果我们扩大规模，我们现在正在做，我认为我们可以发布那个，那将是你所努力实现的目标的一个很好的资源。
所以我们有MetPOM模型，正如我所说的，现在我们从中获取了长格式的答案，并将其与FlanPOM模型以及由专业临床医生生成的答案进行了比较。
正如我所说的，我们的人类评估有两个部分。
一个是由专业临床医生进行的评估，另一个是由普通用户进行的评估。
那么这些结果是什么样子的呢？
在我们得到这些评估结果的140码问题上，我们通常观察到的情况是，当我们看不同的轴时，虽然FlanPOM模型可能相当糟糕，但老实说，MetPOM模型会表现得更好，并且通常会缩小与专业临床医生之间的差距。
所以在这个轴上，你会看到FlanPOM模型在科学共识方面可能有60%的准确性。
MetPOM模型在这方面有很大的改进，并在这里缩小了与临床医生的差距。
其他轴上也有类似的情况。
在这里，你会看到临床医生在模型如何检索医学知识以及如何推理的轴上的评分。
而且，我们在前一张幻灯片中看到的趋势也是一样的。
左列是人们正确理解的证据。
所以这是正确理解的证据。
右边是错误的。
所以我认为是1减去。
不，所以两者可以同时存在。
所以你可以有正确理解的证据，也有错误理解的证据。
这两个不是相互的。
确切地说。
所以这就是为什么这里不是1减。
但趋势是相同的。
这就是为什么我跳过了，但这是一个细节。
好观点。
是的，这里有一个拼写错误，但这个与不正确或缺失的内容有关。
但这是一个有趣的问题，因为当我们从调整中进行此操作时，我们正在教MetPOM模型生成更长更完整的答案。
所以你稍后会看到一些定性例子。
但在过程中发生的事情是，有时模型可能生成了更多的不正确信息。
所以你会看到，也许在这个特定的轴上，FLANPOM模型稍微更好。
但同样，这与临床医生相比要差得多。
好问题。
这更像是完全脱离语境的东西。
所以可能与问题无关。
所以这就是为什么我会这么说。
我们还考虑了可能的危害程度和可能性。
而且，我们再次看到，通过调整的指导，我们能够缩小与专业临床医生之间的差距。
在偏见方面也是一样的。
当然。
你能准确解释顶部吗？
所以我认为基本上在临床医生之间存在着大约6%的巨大差距，那么你能谈谈如何准确澄清这意味着什么吗？
是的，所以基本上，可能会有某些疾病条件或病理学或诊断，对吧，比如癌症。
例如，如果临床医生没有发现这一点，或者可能给出了不适当地传达疾病严重程度的回答，那么这可能会导致严重的伤害或死亡。
所以这就是我们在这里试图捕捉的内容。
所以这是一个非常高层次的概述。
我认为这是一个非常微妙的话题。
有一个称为AHRQ框架的框架。
因此，我们在论文中也链接了这一点。
所以我认为这给了你一个关于危害和偏见非常详细的概念。
那么我会参考那个。
但是在高层次上，这就是我所讨论的。
希望这有所帮助。
好的。
所以当我后来阅读课程时，我会说临床医生在可能伤害程度上有 5 .7% 的水平，这意味着什么呢？
那是不是意味着他们建议了一些可能会致命的东西？
也许他们未能推荐某些东西。
所以基本上是误诊或者可能未能捕捉到诊断的严重性。
这在威胁生命的情况下很典型。
所以往往不是错误，而是忽视细节。
是的。
所以我也谈到了偏见。
然后，正如我所说的，人类评估的另一个维度是与普通用户一起进行的。
所以我们问他们，模型对问题的意图解决得有多好？
同样，我们看到在 med-pam 关闭临床医生的差距时，使用指令提示。
然后我们问他们，回答有多有帮助。
我们看到，虽然 flan-pam 的回答被认为是有帮助的，但 60% 的时间，但这个数字对于 med-pam 提高到了 80%。
但相比临床医生的90%，它仍然相对较低。
所以这里有一些定性的例子。
所以你看到的是，医生们，这通常是因为他们在时间受限的环境中工作，他们的答案往往是精确而简洁的。
但有时作为普通用户或患者来解读和解码答案，并获得所有完整的细节是非常困难的。
所以我认为像med-pam这样的语言模型可以帮助的地方实际上是将医生的话转化为普通用户更容易理解的内容。
这就是我认为这些模型在不久的将来很可能在临床环境中发挥作用的方式，它们将会在与患者以及其他医生和研究人员交互方面增强医生的能力。
塞格拉特？
我只是在想，因为如果我举这个例子，我认为我会，例如，如果我以一个患者的身份，我们是否这样做。
没错。
我觉得这是主观的。
所以这就是为什么我认为我们仍然会看到像普通用户读计划数月之类的情况有助于达到80%的原因。
嗯，对医生来说就高得多了。
所以这绝对不是完美的，但我认为这是一个我们这里感到互补的元素。
我们已经询问过，就像当我们问人们，解释医生的笔记或建议有多容易时。
他们经常说，哦，这很难。
我需要回到谷歌搜索这些术语的含义，这些缩写的含义。
所以我认为这就是语言模型可以过来，将那个笔记转化为更容易理解的东西的地方。
所以我认为这就是这里的机会，我觉得。
所以这就是我们论文的全部内容，但我还想非常快速地指出最近发表的一项工作，上周才发布，标题相当引人注目，我们是否仍然需要临床语言模型？
通过临床语言模型，他们指的是在临床数据领域训练的较小模型，如医疗笔记和记录等。
这篇论文基本上建议，经过精细调整的领域内小型语言模型可能比通用语言模型更好。
在这篇论文中，我认为他们对GPT-3进行了上下文学习的评估。
所以我认为这是一个相当有趣而巧妙的观察。
我认为对于像PubMed、GPT和其他几种变体这样的小型领域LMs，有很大的价值。
但我认为这篇论文没有考虑到上下文学习，抱歉，即提示调整。
我认为这就是一些更大范围通用LMs的好处所在。
再次强调，我们并没有对这些更大范围的通用模型进行任何领域内的LM预训练，但这也是我们可以选择的一个选项。
所以你可以拿这5400亿的参数，然后仍然可以在医学笔记或者任何你能获取到的特定领域的数据上进行训练，希望这将进一步提高性能。
到目前为止的关键要点，我想传达的是通用LMs，看起来它们确实对医学知识进行了编码，并且在规模上医学推理的表现似乎有所提高。
然而，我认为这些模型不能直接在临床设置中使用，它们需要与医学领域的安全关键要求保持一致。
我认为指令提示调整是一种非常有效的技术，无论是在数据方面还是在计算方面。
我们应该经常使用它，具体取决于，希望API也开始支持它。
而且这些模型似乎正在缩小与专业临床医生之间的差距，至少在这个医学问答任务上。
虽然这是非常令人兴奋的，并且具有深远的影响，但你们可能都能够梦想并想象出这里的应用场景。
我认为有必要建立全面的基准和评估框架，以进一步评估和改进这些模型以满足实际应用需求。
所以我就在这里停下了。
有任何问题吗？
医学还是求生？
很大一部分原因是因为这些数据集往往被锁在数据孤岛中，受到隐私和其他类型的法规的限制，这些限制阻止了它们在现实世界中的发布。
因此，您必须拥有像 HIPAA（《健康保险可移植性与责任法案》）兼容的存储系统等。
因此，很难将数据从这些孤岛中取出，并建立一个开放的基准。
所以老实说，我觉得这可能不会改善这些数据集的规模。
至少这些数据集的开放版本与大型语言模型训练数据集或自然图像的计算机视觉数据集相比要小得多，等等。
但未来可能发生的情况是，我们可能会有更分散的联合评估设置，其中您将模型带入这些私人封闭空间并对其进行评估。
因此，它们永远不会暴露在公众面前，而是我们可以有这些联合评估设置。
所以我认为已经有一些关于这方面的工作了。
有一个叫做 Metperf 的系统，我们可能会看到更多类似的系统。
在我们看到任何东西之前，你能重复一遍问题吗？
当然。
所以这里的问题是为什么医疗数据集与自然图像数据集在计算机视觉或语言模型训练数据集等方面相比要小。
你认为医疗LLM在工业界部署的最早应用是什么？
我认为第一批用例可能不会是诊断性质的。
问题是您认为医疗LLM在医疗行业设置中的使用案例是什么？
因此答案是，我认为我们将首先看到的一些用例可能不会是诊断性质的。
而是更多地围绕着如果患者来看医生，您能否生成摘要笔记？
您能执行工作流任务吗？比如为保险、药物、转诊等生成信函之类的任务？
我认为这些任务非常适合大型语言模型，我认为如果还没有的话，在接下来的六个月到一年内，我们将会看到很多这些用例出现。
我认为这将会让医生的生活、护理提供者的生活变得更加轻松，因为现在他们花费了很多时间在做这些事情，而不是真正提供护理和关注患者。
诊断用例我认为需要更多的时间。
我们需要更多的评估。
正如我们所见，数据集可能还不够。
评估框架还没有。
但我认为从长远来看，这是理想的设定，对吧？
然后也许一个后续是 MedPOM。
我假设 MedPOM 不是开源的。
您认为最好的医疗数据开源模型是什么？
我认为这取决于……
所以问题是，什么是医疗数据的最佳开源模型？
我认为这取决于评估设置。
所以我认为来自斯坦福基金会模型组的 PubMed GPT 模型相当强大。
我认为 GPT 3 .0 或 3 .5 或任何变体，如果你能引入一些领域特定的医学数据并进行一些领域内调整，我认为那个模型也能有很大的改进。
所以我认为这两个会是我在这里的首选起点。
所以我很好奇，在临床单位的指令后，软提示向量是什么样子的？
你可以把它们想象成对应于一些额外标记的向量。
所以它并不是真正人类可读的。
所以问题是，软提示向量是什么样的？
它们是人类可读的吗？
答案是否定的。
只是一个跟进，你提到了联邦神经网络模型，术语和参数的模型。
通常在院内的站点上，它们的网络基础设施质量很低。
你真的认为这是你正在学习的内容吗？
还是你有在现场的硬件，现场的神经网络机器，包含这些模型的机器？
当然。
所以问题是，鉴于许多医院系统和提供商的网络都相当低技术，硬件不足够好，你真的认为联邦学习可以用于大规模语言模型的分布式训练吗？
我认为我们越来越多地看到了向云的趋势。
因此，很多医院系统正在将他们的存储、数据和计算迁移到像AWS、Azure或Google Cloud这样的标准云提供商。
我认为这有助于，因为这些系统在后端确实具有进行此类模型训练的计算能力。
我认为这将是一个非常渐进的过程。
因此，具有高质量基础设施的系统，我们可能会首先从那些开始，然后逐渐向长尾部分发展。
但也感觉到这将不可避免地存在于世界中。
所以，在未来10年或15年，当我们拥有这些分布式大规模LLM训练系统时，我们将会想到，我为什么会怀疑这不会存在呢？
这是如此明显，它必须存在，因为那里才是所有的病人数据，所有有趣的数据都在那里。
所以我认为这只是会发生的事情。
只是目前还不清楚是由一个公司完成，还是由一群学术界或行业团体完成，或者政府是否会参与等等。
很有趣，你提到了云计算，但本质上你说我们正在进行一种联邦仪器，但我们仍然将数据上传到可能是同一个计算仓库。
没错。
所以问题在于我们看到云计算，但我们几乎是将数据上传到同一个仓库。
答案是正确的。
但我认为这些都将是单独的存储桶，具有自己的访问控制等等。
这就是你可以区分它们的方式。
现在有很多数据是广泛可用的。
我只是在想是否有关于云计算的讨论。
在我们习惯携带的数据集中，似乎云计算并不是唯一普遍存在的事物，但我很好奇是否进行过任何研究。
当然。
所以问题是，MedPam有没有对这些数据集中的个人信息进行任何研究？
简短的答案是没有。
我们在选择研究中使用的数据集时的一个标准是不包括任何个人可识别数据或类似的临床数据。
这有助于按时完成这篇论文。
但我认为这是一个重要的观点。
我们在训练的公共数据集中可能不太可能有大量的 PHI 数据。
但是，即使在训练时使用一个私人语料库，然后在另一个应用设置中使用它，您也希望确保模型在生成过程中不会泄漏任何 PHI 信息。
所以我认为这些研究是必要的。
我们还没有着手进行这些研究。
所以，如果您正在寻找存在多种生成问题的问题，并且正在探索模型以及那些特别在经验方面可用的人，那么试图解释的是什么词？
所以问题是，改进这些模型的下一步是什么？
检索是一个非常重要的方面。
能够引用来源，尤其是接受权威来源并在生成答案中使用它并将其传达给用户非常重要。
我认为如何传达不确定性非常重要。
所以我们在一定程度上使用了指导提示调整，但我认为这可以做得更好。
所以我认为这是另一个重要的方面。
再次，我想强调评估方面，要看更多的数据集，比如可能会对健康记录或其他类型的医疗数据进行问答。
我认为这将是重要的。
而且，还要扩展评估，无论是在规模上，有一个多样化的临床医生团队，还是在使用的数据方面。
也许我会确实地修改问题，包括人口统计方面的混淆因素或类似的东西。
我认为这些都是很好、很有趣的方向。
我认为在建模方面，对我来说有趣的问题是，再次，这种在较小的领域特定元素与大型通用元素之间的相互作用以及这将如何发挥作用。
在这里似乎有一些出现的证据，特别是在医学推理方面。
因此，正如你所看到的，在较低的规模上，有时性能还不够好。
我的意思是，50%，我是说，那是一个很好的数字，但那只是不可行的。
但是当你达到80、90%时，产品真的变得非常有用。
所以我们看到这些模型的更大参数尺寸。
但是我不知道，我认为这还是一个悬而未决的问题。
幻觉是一个问题吗？
是的，问题是，幻觉是一个问题吗？
我认为仍然是。
但我相信你可以通过指令提示调整来相当好地控制，就像任何类型的反馈数据一样。
我认为这并不是特别困难的事情。
所以我认为这可能总体上有些被夸大了。
特别是当你在特定领域做这件事时，我认为更容易控制。
你能跟 Pavavra 谈谈吗？
你介意我问你一个问题吗？
就像，也许是领导者的程度，或者是什么样子？
我只是觉得最近围绕着 Pavavra 的话题很多。
所以我很好奇，因为这个特定的应用非常、非常相关。
而且你知道，高标准，质量等等。我很好奇你是否能稍微谈一谈这个。
是的，所以问题是，围绕幻觉和通用 LLMs 的讨论和噪音很多。
而在这个特定的应用领域，这似乎特别相关。
那么你能再详细谈一谈吗？
当然。
所以我们看到的是，即使是来自专业临床医生的几百个示例订单，教导模型如何传达医学信息，这已经足够让模型也许停止产生幻觉，或者至少以更好的方式表达其不确定性。
所以，至少在这个特定的领域或设置中，对我们来说，这似乎更具可操作性。
我之所以这样说是因为我们已经从定性上查看了答案，我们发现模型不倾向于生成超长的答案，或者说不会做出非常自信的预测，而是语气变得非常保守。
它开始使用诸如“也许这需要进一步完成”之类的术语，这表达了不确定性。
事实上，我们所拥有的不确定性基础表示是否与级别相关，我认为这仍然是一个研究领域，但我认为这对我们来说已经是有希望的，因为在像医学这样的有限应用设置中，它感觉上是可控的。
但是，如果你有一个试图回答关于世界上几乎所有事情的通用语言模型，我认为这是一个更困难的问题。
你认为那可能是领域数据集的一个特征吗？
就像在医学情况下，医生不会，或者可能保留，不会有绝对的，或者你认为更像是你只是专门化了，对吗？
这也可能是完全不同的事情，我只是好奇。
是的，所以问题是，你认为这个模型在这个领域的表现方式，是医学领域数据集的一个特点，通常是基于医生的沟通方式吗？
我认为是的。
我认为这是我们需要建立并在这里使用的东西。
我认为这非常有帮助。
希望这种行为足够普遍，并且可以传递给模型，即使在非医学环境中使用时，也能更加保守地沟通，减少幻觉等等。
所以我相信这是一个机会之一，可以利用这些基准，提出减少幻觉、更好地传达不确定性等方法，然后将其用作双向学习的机会，以改进 MMSU 的通用性。
所以如果您有任何进一步的问题，我会在讲座结束时再次回来，但我也想涵盖其余的应用。
接下来我想讨论的领域是蛋白质。
现在我要谈论的论文，我会稍微快进一下，考虑到时间。
但我想首先讨论的是2020年谷歌研究部门的一篇论文，标题是《线性可扩展长上下文transformer的蛋白质质量语言建模》。
所以这里的问题是，对长范围生物序列进行建模需要高效的transformer架构。
在这篇特定的论文中，他们介绍了这种表演者架构，它通过低秩分解近似了softmax注意力核。
所以这不包括任何稀疏先验，就像其他方法，比如改革者或者还有很多其他的方法一样。
这是很好的，因为稀疏先验可能不适用于蛋白质等生物数据，这些数据需要建模全局相互作用。
然后另一件事是这个模型，性能随着序列长度L的增加呈线性而不是二次增加。
而且，用来近似这个softmax注意力核的随机特征的数量M完全独立于输入序列长度。
所以，让我们快速可视化一下加速和空间复杂度的改进，使用这种低秩分解的方式，你所拥有的不再是在softmax注意力核中拥有大矩阵，而是现在拥有了由随机特征M的大小决定的更窄的矩阵。
这基本上将您的二次复杂度降低为更加线性的性质，并且还会导致空间的改进。
所以，在论文中有更多的理论分析和细节，我会让你们都参考一下。
但是，当我们进行蛋白质语言建模时，结果显示，这个模型的准确性与transformer相当，同时大大降低了计算成本。
因此，这表明softmax注意力核的近似是一个紧密的近似，这是很好的。
然后，当您将其与其他方法进行比较，例如reformer或linformer时，准确性要高得多，至少在这个任务上是这样。
因此，与其他试图构建更高效的transformer的方法相比，这个方法对生物序列的序列化来说要好得多，至少在这种情况下。 
最后，如果你看一下氨基酸相似性矩阵的注意力，你会发现执行者模型识别高度相似的氨基酸对，比如 D 和 E，以及 F 和 Y 在这里。
所以这表明模型正在学习我们在这里真正想要的正确信息集。
那么这只是论文的一个两分钟概述，但我想谈谈另一篇，我认为这也很酷。
所以这个叫做蛋白质注释，同样是由谷歌研究部门的一些其他人完成的。
这个模型基于自然语言的蛋白质注释。
为什么这个问题很重要呢？因为蛋白质信息需求很大。
因此，超过 50% 已知的蛋白质序列，我们实际上并不知道它们的功能。
所以我们需要能够至少在某种程度上解读它们是很重要的。
然后第二件事是，例如，我们可能想要找到具有特定功能的蛋白质序列。
在 CRISPR 领域，这尤其重要。
因此，如果您能训练出能够做到这一点的双向模型，我认为那将非常有帮助。
而我再次提到这一点的原因是UniProt数据库，它在全球有数百万研究人员在使用。
因此，将这些信息填充到该数据库中将非常有用，并将加速这一领域的许多研究。
所以欧洲生物信息学研究所，他们已经整理了有关蛋白质的这些免费文本数据。
基本上，您可以使用这个蛋白质记录来训练这些模型。
所以您想做的可能是直接从氨基酸序列映射到它们的自然语言描述。
而这个问题与图像字幕问题并没有太大不同，您不是有一系列像素，我不知道“序列”是否正确，但同样，如果您有像素，您有一系列的氨基酸，它们的数量可以从两个到4万个不等。
然后您想生成的是蛋白质的描述。
在这篇论文中，他们这样做的方式是在蛋白质序列注释任务上训练了一个T5模型。
任务以多种方式设置，监督数据来自他们拥有的蛋白质记录中的多个来源。
而这个模型是一个编码的T5模型。
所以这是一个非常酷的应用。
结果是，在那个Uniprot数据库中，有5600万个蛋白质之前没有被表征，现在有4900万个已经有了相关的文本描述。
所以现在我们知道它们是做什么的了。
这真的很棒。
然后另一个，我认为，可能更有趣的是，现在你可以运行查询，比如找到这个CRISPR-Cas9蛋白质的一个较小版本，以便它可以更好地靶向某些组织。
现在模型可以返回序列。
所以我认为这将会非常有用，并且将加速这个领域的许多研究。
已经有很多动力了。
我认为这些模型将进一步帮助。
所以这是关于蛋白质的。
我想要讨论的最后一个应用类别是基因组学方面。
同样，这里的第一篇论文是我们Google Health AI基因组团队去年的一些工作，他们正在构建用于序列校正的间隙感知序列转换器。
所以这个模型叫做Deep Consensus。
那么这个模型扮演什么角色，为什么它很重要呢？
所以如果你看一下测序数据的生命周期，你所做的就是从基本的原子到比特。
所以你有这个物理标本，希望它里面有一些DNA。
然后你将其放入 SPAC-Bio 这样的测序机，然后它输出原始数据。
这些原始数据会被映射到一个参考基因组上。
有时个体与参考基因组之间可能存在差异。
而这可以通过我们团队几年前推出的 Deep Variant 模型进行纠正。
而且这是开源的。
一旦你有了这个序列，你就可以用它进行各种不同的分析，比如祖先或基础生物医学研究。
Deep Variant 的作用是使从 Packed Bio 测序器中出来的原始DNA读数更加准确。
它试图使其更加准确。
Packed Bio 测序器的工作原理是使用一种循环一致测序算法，其中DNA分子被读取多次并产生多个不同的子读数。
这些子读数中包含一些错误，因此它们最终被组装在一起。
Deep Variant 的目标是试图改进这里产生的错误，基本上是来自于这个循环一致测序算法。
那么这个模型是如何工作的呢？
所以正如我所说，深度一致性的基本任务是利用CCS数据和与其相关的子读取来生成一个校正后的序列。
所以在这个例子中，当我们运行模型时，我们看到的是，尽管CCS身份是95.7%，但深度一致性的预测身份是100%。
所以这是一个相当简单的任务，你要尽力减少来自CCS算法的错误。
那么一个非常自然的问题是这些标签是从哪里来的呢？
所以你拥有的每个CCS序列，都与一个高质量的组装序列对齐。
而这个高质量的组装序列是通过将许多CCS读取拼接在一起而创建的。
因此，这样就会有更少的错误。
因此，您可以尝试使用那个高质量的拼接组装，并将其映射回给定块的CCS读取，并将其用作标签。
所以这就产生了更强的地面真相，您可以使用它来训练模型，进一步提高准确性。
这就是模型训练的内容。
这个模型看起来是这样的。
它是一个Transformer架构。
它接收这些子读取以及这个CCS读取。
它还有一堆额外的上下文特征，也是从测序仪器中传入的。
这些都被输入到了transformer模型中。
它产生了一个精细的片段，然后这些片段被拼接在一起，生成最终的精细阅读。
我要指出的一件事是，为了训练这个模型，你不能使用交叉熵损失。
这是因为在DNA序列中经常会出现插入，因此当你使用交叉熵损失时，可能会严重影响模型。
正如你在这里所看到的，即使是一个单一的错误，也会在整个序列中传播，并使情况变得更糟。
所以你需要一种基于距离的特殊对齐损失，可以更好地捕捉这种错误。
因此，让这种对齐损失在TPU上运行并使其可微分，我认为这篇论文的真正精髓所在。
如果你对这种话题感兴趣，可以再次回到论文中。
我认为那真的非常酷。
但从一个非常高的层面来看，这个模型的工作效果如何呢？
所以如果你看最终的输出，你有读取名称，你有基本预测，还有预测的质量，这可以被认为是一个置信度分数。
这些基础预测通常非常长。
所以你可以看到，这是因为屏幕外面延续了，因为这里有10K到20K的基础。
当你看到质量时，它在这里的普通CCS算法上得到了相当大的改进。
在这里，每个读取的准确性都有相当大的提高。
所以你可能会问，这种模型的真实世界影响是什么？
答案是这种模型已经在真实世界中被使用。
在斯坦福，由Ashley博士和其他几位成员组成的基因组团队最近发表了一篇超快速纳米孔基因组测序论文，他们创造了最快的基因组测序世界纪录。
在这个装配序列中使用了这种深度共识transformer架构。
因此，在这项特定研究中，他们能够非常快速地诊断出Matthew患有心脏病的基因原因。
因此，他们能够很快地将Matthew列入患者的供体名单。
这就是我们可以通过这些生物医学转换模型和AI系统总的来说所能产生的真实世界影响。 
而且，我要谈论的最后一篇论文是来自DeepMind的，关于通过整合远程相互作用来有效预测基因表达的论文。
这篇论文发表在《自然方法》杂志上。
这项工作的动机再次是，自人类基因组计划以来，已经进行了成千上万次全基因组关联研究，其目标是将基因变体映射到不同种类的疾病表型。
但是，许多工作都涉及实验和实验，就像现实世界的实验需要很多时间。
如果我们可以用机器学习模型来做到这一点，那真是太好了。
这就是他们在这篇论文中要做的事情。
所以，如果你看基因本身，有大约 10% 的基因将是编码变体，这些变体影响蛋白质功能。
然后它们可能通过破坏所生成的蛋白质的结构或影响蛋白质-蛋白质相互作用来引起疾病。
关于这些编码变体的好处是它们往往更靠近基因，因此更容易解释。
另一方面，有 90% 的基因是非编码变体。
它们的工作方式是影响蛋白质表达。
所以还有更多像是调控序列。
而它们导致疾病的方式，如果它们有任何变异，是通过干扰蛋白质的转录。
鉴于这些非编码变体可能与基因和编码变体非常远，因此很难解释它们。
那么问题是，我们能否训练能够预测这些非编码变体影响的转换模型？
这就是这里的任务。
这又是一个可视化。
所以这篇论文再次关注转录，这是将DNA转录为RNA的第一步。
这是通过RNA聚合酶完成的，它在基因的起始处由称为转录因子的蛋白质招募。
这些转录因子有一个结合位点，对应于这些启动子，这些启动子与基因非常接近。
但是，你还有这些增强子，它们可以在线性空间上与这些启动子非常非常远，并且也影响这种转录。
你可能会问，这些增强子如何影响这里的活动？
这是因为虽然它们在线性空间中可能相距很远，但当序列折叠并形成3D结构时，它们最终会相当接近彼此。
这样它们就可以完全影响这里的转录过程。
所以这是关于生物学方面正在发生的事情的一个非常高层次的概述。
那么问题是，如果这些非编码变体和这些增强子中有任何变体，它们可能会破坏转录因子的结合。
这反过来可能导致没有蛋白质，最终导致疾病。
所以我们希望能够基于已生成的DNA序列来预测这一点。
所以问题有点相当直接。
这是一个监督学习问题。
设置是从这些DNA序列中预测实验数据，这可以采用许多不同的形式。
主要的是基因表达，但还有其他任务，如DNA可及性、组蛋白修饰和转录因子结合等等。
所以你可以想象，多年来这项任务的基线模型是CNN模型。
随着你开始得到一个不同的层，你可以增加感受野，但是有一个限制。
所以在这项工作中，他们展示的是你可以使用transformer来更好地建模这些长程相互作用。
所以最终的模型被称为N-FOMER，这是这个增强器和transformer的组合。
如果你看模型本身，它在开始时有一些CNN层，但然后有一堆堆叠在一起的transformer块。
输入是200kV的DNA序列，已经训练了大约30k个样本。
输出是这个RNA表达的基因组轨迹，它们具有特定于生物的头部，一个用于人类，一个用于老鼠。
最后，一个关键细节是，这个模型中使用的相对位置编码实际上非常关键。
这些相对位置编码在建模这种幂律相互作用时起到了作用。
由于在transformer块架构中使用这些相对位置编码的结果，他们现在能够模拟超过100kV碱基对的相互作用。
所以你在这里看到了结果。
实验数据在这里是绿色的，你可以看到CNN基准线在这里。
当您走得更远时，您会发现CNN模型无法再捕捉到这些基因表达。
但您可以看到增强模型现在能够捕捉到它们。
所以您可以看到，随着模型走得更远，增强模型能够捕捉到这一点，而CNN模型则不能再捕捉到这一点。
最后，我认为非常有趣的一个实验是他们在论文中进行的实验，他们还能够预测启动子增强子的影响。
而且，该预测实际上与实验数据一致。
因此，这表明使用这种机器学习模型，我们可以绕过许多湿实验，并获得关键细节，这可能非常有用。
所以，是的，我很抱歉，我不得不在这里匆匆忙忙地介绍蛋白质和基因组应用。
但我认为您会发现总体而言，当您观察临床蛋白质和基因组应用时，我们会发现transformer在生物医学领域具有令人难以置信的潜力。
在临床应用中，我认为挑战可能更集中在数据和评估方面。
但在蛋白质和基因组方面，我认为有一些极其有趣的创新架构机会。
最后，正如我所说，这里有令人难以置信的双向学习机会。
我认为建模长程相互作用的问题，这对蛋白质，基因组学以外的领域都是有用的。
我认为这对基因组学也是有用的。
因此，我认为这里的任何架构改进都可以激发人工智能的更广泛进展。
所以我认为这是一个着手解决的重要原因。
到目前为止有任何问题吗？
抱歉，我在这里讲了很多内容。
对此表示歉意，但我认为这些论文非常棒，你应该回去阅读它们。
最后，我想可能再花几分钟谈谈我对生物医学人工智能未来发展的看法。
总的来说，我相信这不是一个AI是否会改变生物医学的问题。
我认为这更是一个何时以及如何的问题。
我认为我在这里非常具体的论点是，考虑到生物医学数据的性质以及其多模型特性，再加上transformer的所有进展，例如西部学习，大型语言模型，我认为我们有一个非常强大的框架，可以在规模上利用所有这些丰富信息，真正构建基础性的医疗人工智能模型。
所以我认为这是非常令人兴奋的。
所以我认为你已经在这里待得太久了，所以我不会要求你认出这些人，但他们实际上是著名的医学科学家，其中一些人后来获得了诺贝尔奖。
所以我想我想在这里说的是，科学家和医生之间没有理由不同。
他们可以结合在一起。
这也是我想通过我们的人工智能系统传达的。
我们不必把临床应用和生物应用分开。
我认为当我们把它们结合在一起时，我们将会发现很多新的见解，我认为这将加速生物医学研究并内部产生新的发现，这将用于根除疾病，提高人类健康寿命，并推动人类潜力的进步。
好问题。
我其实不知道这三个人是谁。
当然。
我想最右边的是亚历山大·弗莱明，然后是乔纳斯·索尔克，然后是保罗·埃尔利希。
弗莱明是青霉素，索尔克是脊髓灰质炎疫苗，而埃尔利希则涉足多种不同的领域。
所以也许我会问你们所有人这个问题。
你们认为哪个领域的人工智能会赢得第一个诺贝尔奖呢？
你不必回答，只需思考。
我认为没有人适合这个。
诺贝尔奖的完整奖项是什么？
我认为有六个。
这是Algendukes吗？
不，经济学不是诺贝尔奖。
就像有八个诺贝尔奖。
哦，好的。
但就像诺贝尔。
说诺贝尔奖。
诺贝尔就像，这不是一个真正的领域，我不会使用人或产品。
我认为经济学是一种诺贝尔奖。
我们从哪里开始？
它与诺贝尔基金会有关，那是他们的说法。
不。
不？
好的。
整本书都是关于诺贝尔的，就像是个笑话，不是所有这些人。
然后经济学就像，等等，我们在干什么？
然后他们有点自己交易他们的经济学诺贝尔奖。
好的。
我不会怀疑生物学，因为事物就像，哦，我们发明了这个，你得癌症之类的。
没错。
所以我也有同样的感觉，我希望你们绝大多数也认为它会在医学领域。
我要以这个注解结束。
非常感谢所有我的合作者和团队成员，最重要的是允许我“借鉴”幻灯片。
然后也感谢大家耐心地听着。
希望这对大家有所帮助。
