很高兴今天有Angela Phan和我们在一起。
她是Meta AI Research在纽约的一位研究科学家，主要专注于文本生成的研究。
目前她正在从事语言建模和开发线上人工智能代理产品的工作。
最近的研究项目包括"No Language Left Behind"，今天她将简要介绍一下，以及面向无文字语言的通用语音翻译和La Ma Too。
所以，让我们为Angela鼓掌。
好的。
非常感谢大家。
当我收到这封电子邮件时，我想，哦，我应该谈谈La Ma Too。
但后来我注意到你们有Sharon，她是一个比我更好十倍的演讲者。
所以我想，好吧，或许不是La Ma Too。
但后来我想也许我可以介绍一下我们做的一个项目，叫做"No Language Left Behind"，这可能与这门课程非常相关。
当你考虑很多文本生成技术时，直到最近，大部分都集中在英语上。
但实际上，全球有3000多种书写语言。
对我来说，这实际上非常具有个人意义，因为英语是我的第三种语言。
所以这真的很重要。
是的，所以这也非常具有个人意义。
当你考虑一些贯穿其中的多语言技术时，它并不是说我们从未涉足过多语言。
是的。
实际上，说到生成式人工智能，我认为翻译实际上是生成式人工智能最成功和最普遍的应用之一。
我的意思是，最终，翻译模型就像是条件语言模型。
所以当你考虑像旅行之类的事情，或者我妹妹在学西班牙语。
就像是在做她的西班牙语作业一样，今天我们有很多现成的工具。
像是谷歌翻译覆盖大约130种语言。
微软翻译大约110种。
自从我之前获取这些统计数据以来可能已经有些过时了。
但是“No Language Left Behind”项目始于一个非常简单的要求，好吧，全球有3000种语言。
也许要达到全部3000种会相当困难，因为其中一些语言非常罕见，没有很多人说这些语言。
但是仍然有数以百计的语言，被数百万人使用。
所以我们就像，好吧，没什么大不了的。
就像，让我们从今天拥有的大约100种语言开始，然后再翻一番吧。
要真正实现这种覆盖范围的翻倍需要什么条件？
当然，你知道，仅仅说你支持一堆语言并不是目标。
对。
我们实际上想要创建高质量、安全的翻译，可供人们使用。
就像如果你今天要去度假，你的本能就是掏出手机，使用谷歌翻译应用。
因此，这个项目的背景是翻译领域实际上取得了很多进展。
所以在历史上，人们一直关注我们所说的高资源语言。
这些并不一定是世界上使用最多的语言。
但是当我们说高资源时，意味着拥有最多的数据。
你可以想象一下欧洲议会或欧洲议会的翻译等内容。
这些为很多翻译发展奠定了基础。
最近，有更多的关注放在低资源语言上。
这在研究界得到了推动，与像加纳NLP、Masakane、美国NLP这样的团体一起。
所有这些都是非常令人振奋的发展。
因此，这导致了许多新数据集的开发，以及对现有数据集的批评，还有对新语言的研究。
通常这些语言是人们真正使用并且非常关心的语言。
我们发现这一切非常令人振奋。
因此，在研究院（FAIR），我们聚在一起开始思考，好吧，实际上我们说一些相当低资源的语言，从加泰罗尼亚语到阿萨姆语等等。
因此，我们把这当作一个大型的、充满激情的研究项目。
所以今天我想简要介绍一下我们解决这个问题的高层方法，这有点跨学科。
我想谈谈我们实际上是如何创建能够支持这种工作的数据集的。
当然，我想谈谈模型，因为这是关于Transformer的课程。
关于这一点，我认为在翻译方面作为一个研究方向，实际上有很多创新已经完成。
我认为原始的Transformer论文就是其中之一，它使翻译始终成为一个非常有趣的研究领域。
因为我觉得这是一个非常成熟的研究领域。
所以这有点像，好吧，如果你的架构在翻译中起作用，它可能在很大程度上都有效。
这也是我对翻译研究感到兴奋的原因之一。
然后我想谈一下评估，比如我们如何实际测量和确保这些翻译的质量对人们是好的和安全的。
然后我想以一些关于未来方向和希望我们将来可以研究的事物的高层次想法结束。
所以我想从我们的方法开始。
我认为研究中最重要的事情是要知道我们正在解决一个真实的问题，特别是当它与人们非常接近，比如翻译。
而且我认为在许多领域，比如当我在从事设备人工智能方面的工作时，例如，我觉得我心中有一个研究问题，但它与实际将模型放在手机上的实际问题非常脱节。
所以这对我们来说真的非常重要。
因此，我们实际上通过一种类似社会科学或社会学的方式开始了这个项目。
而且我们实际上做了很多与低资源说话者的访谈。
所以我们与大约44位不同的母语人士会面，这些人讲36种不同的语言，涵盖整个北美地区。
我会说其中很多人都是美国的移民，因为那在招募方面是最容易的一类。
我们了解了许多关于他们如何处理低资源语言以及他们对技术需求的不同看法。
因为我认为很容易就会觉得，嘿，我有这个很酷的背景，我有这个很酷的问题，我想解决它。
但我认为实际上与这些人交流是非常重要的，如果这是一个需要解决的问题。
所以我们了解到，人们普遍担心低资源语言可能正在经历衰退的状态，部分原因是很多教育正在转向印地语、英语或者汉语这样的语言。
人们对被纳入现有翻译系统感到非常兴奋。
人们说他们一直试图在他们已有的语言中使用谷歌翻译或微软翻译。
但最终，他们发现质量真的不够可靠。
所以如果你想想，就像，我本来要说当我还在高中的时候，但你们可能比我小很多。
所以大概10年前左右，你知道，当你尝试用谷歌翻译做你的西班牙语作业时，你的西班牙语老师总是能够辨别出来，你知道，这不是人类写的翻译，直到你被扣分。
但是对于今天一些高资源语言来说，情况并非如此。
所以我认为，就像机器学习中的所有事情一样，它真正始于数据的角度。
就像，为什么我们不能在数百种语言中训练模型或在数百种语言中训练大型语言模型呢？
这是因为我们没有支持它的数据。
所以我想首先谈一下评估数据集，因为我认为把评估做好非常重要。
然后我会谈一下训练。
所以对于这项工作的评估数据集，我们开始了FLORAS项目。
FLORAS代表Facebook低资源，我想现在我们被称为META，但我认为FLORAS不是一个很好的改名。
所以我们仍然称它为FLORAS。
这是我们最初在EMNLP的第一篇论文中仅针对两种语言启动的项目。
许多年前，所以最初只针对尼泊尔语和僧伽罗语，后来我们在一个版本中扩展到了另外两种语言。
之后，你知道，我们考虑了很多，好吧，FLORAS对社区来说真的非常有用。
我们如何将其扩展到100种语言？
所以这是我们做的后续工作，我认为我们在ACL或WMT上发表过。
然后在这个项目中，我们想，好吧，我们如何从FLORAS 101扩展到FLORAS 200，真正实现翻倍效应？
那么FLORAS是什么？
嗯，名字就说明了。
这是专注于低资源语言的。
所以我们确实包括一些高资源语言，如德语或印地语等，几乎也是为了校准效应。 
但是绝大多数关注点都集中在这些较低和中等资源的语言上。
这是第一个大规模的多对多机器翻译评估数据集，这意味着我们将所有英语句子进行翻译，然后翻译到所有语言，这意味着您可以评估任何语言的交叉对。
所以例如，中文到法语，我在法国生活了很多年，对我来说非常个人相关。
当然，200种语言也在名称中。
有广泛的不同领域和主题。
我认为在设计评估数据集时这一点很重要，这对任何对语言建模研究感兴趣的人来说都是非常重要的，因为人们训练机器翻译模型的方式和人们使用它们的方式通常是非常不同的。
所以，如果您只在例如新闻中对您的数据集进行基准测试（在翻译研究中非常常见），那么您就不会真正意识到人们谈论各种各样的事情并进行不同的随意对话，他们需要翻译官方文件等等。
这也是一个文档级的数据集。
我认为目前社区广泛利用的情况并不是这样的。
但翻译的方式是，你可以有文件级别的上下文。
翻译人员被提供整个文件进行翻译。
我们还提供整个文件进行评估。
我们从同一段落中翻译多个句子。
因此，这是一个潜在的研究方向，我们希望确保覆盖需要更多上下文的模型，因为很多翻译工作是在句子级别进行的。
那么我们如何确保这个数据集的质量呢？
所以第一步是我们拿到一个文件。
嗯，实际上，第一步是对语言标准进行对齐。
这非常重要，因为当你翻译法语或中文时，我认为大多数人都对如何产生好的法语或好的中文有着很好的理解。
并且有很多专业翻译人员在这些语言中受聘。
但是当你去处理资源较低的语言时，并不一定存在着一个光辉的翻译行业来翻译一个资源较低的语言。
因此，首先要做的一件事实际上是对什么是高质量的翻译进行对齐。
所以这里实际上存在很多挑战。
有一些低资源语言存在不同的竞争语言标准，或者在不同地区语言使用方式存在很高的差异。
这一步是相当关键的。
然后我们将文档发送给一组翻译人员，他们进行第一步翻译。
然后我们进行一些自动检查，你知道，如果输入句子有10个词，而输出句子有300个词，很可能出了些问题，你知道的，所以我们将它发送回去。
否则，我们将其发送到另一组完全独立的翻译人员那里进行审核。
所以他们试图评估这个的质量。
如果质量不达到足够的标准，它将被发送回原始的翻译人员进行编辑，他们会逐一处理所有的反馈。
然后如果足够好，它就会进入我们的数据集。
所以这里存在许多挑战。
第一个，当然，就是找到翻译人员，还有找到更多的翻译人员。
我们遇到了一个问题，例如，在某个国家互联网不可用。
而且，你知道，这涉及到很多招聘。
另一个问题，当然，是语言标准化。
我想我之前简要提到过，但在理解高质量翻译方面确实存在很多不同的挑战。
例如，低资源语言布列塔尼语。
就像有两个竞争的团体，讨论如何书写布列塔尼语。
所以解决其中一些问题非常困难。
最后一件事是实际上存在很多变体，即使是像阿拉伯语这样的语言也是如此。
比如，阿拉伯语，像摩洛哥阿拉伯语与约旦阿拉伯语之间存在很大差异。
还有一些地区，他们说同样的语言，但由于历史原因，他们使用不同的书写系统。
因此，我们实际上做的一件事是，如果有多种书写形式的语言，我们支持进行多种书写系统的集合评估。
我认为这真的很重要，因为如果你正在构建一种基础技术，而你只选择了一个，那么我认为你就会有风险，就像自然地支持其中一个，而我们真正应该是一种更中立的技术提供者。
所以这是我们探索的一个很重要的问题，同时也探索了阿拉伯语的不同变体。
这也是开源的。
如果你只是点击这个链接，你可以下载所有的文本文件。
评估完成后，我想谈谈我们如何收集其中一些训练数据集。
我想先谈谈我们创建的数据集，叫做NLLB种子。
这个想法就是，它是一个真正的高质量翻译的种子数据集，而这些语言实际上什么都没有。
为什么呢？
因为，嗯，你不能从零开始。
你知道的，你得从某个地方启动。
很多人一直在使用圣经作为启动的方式，但这是非常有限的领域。
显然，是非常宗教的文本。
所以我们为那些真的没有任何东西可供启动的语言创建了这个数据集，叫做NLLB种子。
它只有大约5000个句子。
所以这并不是什么疯狂的事情，但它支持很多不同的用例，比如训练语言识别模型或句子编码器以及语法语言模型，就像我即将在我们的数据集流水线中讨论的所有这些内容一样。
所以它涵盖了43种语言，大约6000个句子。
我们决定抽样的方式是专注于非常通用的内容。
维基百科有一篇文章，如果你要用一种新语言开始一个新的维基百科，我想维基百科有大约309个维基百科，最后一次我查过的时候。
这里有一份每种新语言的维基百科都应该有的文章列表。
所以我们就是从这里抽样原始内容的。
当然，如果你想下载，它也是开源的。
所以我们最终采取的方法来获取大规模的训练数据是使用挖掘。
这不是我们在这个项目中首创的东西。
我们有很多不同的之前的工作。
所以我们是从Wikimatrix开始的。
我们想，嘿，在维基百科和不同语言中有很多不同的句子，我们应该能够匹配起来。
所以我们试图通过维基百科来获取机器翻译训练数据。
我们在CC矩阵项目中将其扩展到了网络，然后我们将其扩展到了所有交叉对上的非常非常大规模的挖掘。
在这个超越以英语为中心的多语言机器翻译项目中，我们真的试图摆脱以英语为中心的枢纽语言。
这整个数据挖掘的工作方式是侧重于句子对齐。
所以大家可能都非常熟悉这个，因为这就是现在构建语言模型的方式。
就像你拿到了common crawl或者其他开放源码的网络转储，我不知道，比如red pajama或者你想要用的CC net，现在想用什么都可以。
然后你拿到了所有的数据，提取了所有的文本，你知道，涉及到很多HTML解析等等。
而且我们的想法是要试图找到可能是翻译的匹配文本。
所以我们将其全部分成句子。
我们使用不同的句子编码模型嵌入它们。
然后我们进行匹配，试图在多语言空间中理解这些句子是否匹配。
因此，对此的一个最大挑战之一是句子编码的质量非常重要。
所以，如果您的句子编码不太准确，那么在这个多维空间中匹配意思相同的想法就是不可能的。
所以，在这个项目中，我们试图做的一件重要的事情就是努力提高句子编码器的质量。
我们做的一件重要的事情是用掩码语言建模来训练句子编码器。
您可以在左边看到这一点。
但我们还使用了多语言蒸馏，您可以在右边看到这一点。
以前的句子编码器方法以及研究界的趋势是尝试将所有语言都嵌入同一个句子编码器模型中。
例如，XLMR项目就是朝这个方向发展的。
我认为它被广泛使用。
当您训练低资源模型时，其中一个挑战是，您的大量高资源数据会压倒您的低资源数据。
所以，您最终得不到非常高质量的用于这些语言的句子编码器。
所以我们最终做的是，我们有一个多语言教师模型，然后我们蒸馏了一堆针对不同语言家族的低资源的学生模型。
所以这使得质量可以相当高。
所以蒸馏的工作方式是，老师模型和学生模型都看到相同的数据。
然后我们试图最小化它们生成的句子嵌入之间的余弦损失。
我认为你可以在这里问的一个重要问题是，为什么需要进行多语言蒸馏？
为什么不能只训练一堆不同的学生模型，比如每种语言家族一个？
就像为什么要关心蒸馏呢？
原因是，如果你要使用一堆句子编码器进行挖掘，重要的是它们都存在于相同的嵌入空间中。
你知道，如果你训练一个单独的模型和另一个单独的模型，它们之间没有任何约束，所以你无法对所有数据进行挖掘。
我们发现的其中一件事是，通过从同一个老师模型开始，并尝试使用余弦损失来最小化嵌入之间的距离，你能够拥有这个受限制的空间，在这个空间中，你可以对每种语言与其他每种语言进行挖掘，即使你有不同的学生模型。
所以这个Y轴上的图表显示了挖掘的错误率。
更低意味着更好。
在X轴上，它显示了一堆不同的低资源语言。
所以，例如，第一个是乌尔都语，第二个是泰卢固语，第三个是他加禄语，依此类推。
这里的灰色条是原始的激光论文。
这是一篇我们大概在2018年左右发布的论文，我们列举了所有这些语言，将它们包括在内。
但正如你所看到的，对于这些语言，错误率非常非常高。
所以即使它们被包括在内，也无法用于高质量的应用。
而蓝色条是我们根据我刚才在上一张幻灯片中描述的技术训练的激光模型。
你可以看到，我认为最重要的一点是你几乎看不到蓝条。
所以即使对于那些人们之前认为我们已经嵌入的先前的语言来说，它也非常有效。
那么现在，这种事情如何融入到围绕这种方法的整个数据流水线中呢？
其中最重要的一点是，当你从网络上下载数据时，你并不真正知道它是什么语言。
这就是今天所有大规模语言模型训练中所涉及的大规模数据清理的一部分。
所以我们识别不同语言的方式是通过简单的分类模型，称为语言识别模型。
我认为这是一个分类模型。
所以人们认为这比实际上要容易。
但我认为一些主要的挑战是有很多不同的语言，它们以许多不同的方式书写，而网络文本非常随意。
因此，实际上训练一个能够推广到它们的良好分类模型可能会非常困难。
所以我们所做的是，你知道，我们有我们的语言识别（LID）训练数据，然后我们生成了一个语言识别模型 LID。
然后我们实际上进行了人工评估，标记来自语言识别系统的错误，通过迭代改进这个在网络文本本身上以提高特定模型的质量。
然后在我们生成这个 LID 模型之后，我们插入所有我们的常见爬网数据，其中网络箭头出现，并且我们进行大量的过滤和清理。
这样就产生了一个巨大的单语数据语料库，您可以随后用于训练任何东西。
之后，我们训练我们的编码器，就我在前文所描述的，然后我们将这个单语数据转换成我们称之为心灵的文本。
所以这些是我们认为彼此是翻译的大量数据集。
最后，我们实际上试图验证这些是否是真实的思维文本，方法是训练非常小的双语翻译模型，以查看质量如何。
我认为这很重要，因为数据开发周期和最终使用的任务，你不希望完全将其分开。
今天进行大型语言模型训练的一个类比是，在进行预训练时，你不希望有人只是提供给你一些数据。
你不同数据集的数据混合非常重要，在这里非常相似。
我认为我们在这里的一个亮点是真正关注了语言识别模型的人类评估，因为如果你更准确地知道它是什么语言，这实际上会提高所有底层数据的质量。
而且，整个数据管道实际上是在这个库中开源的，并且我们有一篇描述它的EMNLP论文。
我认为这很重要的原因是，我认为数据清洗实际上是驱动模型质量的基础性事物，人们的数据管道就像是，我有这个脚本和这个其他东西和这个其他东西。
所以，我认为能够重新创建并重新运行它是非常重要的，作为你后续研究的一部分。 
这就是为什么我们将其开源的原因。
对于低资源语言的一些反思，尽管我们进行了大规模的挖掘，我认为单语数据是限制因素。
有许多语言在网上没有大量的文本写作，因此要获取大量数据可能非常具有挑战性。
此外，我认为对于一些独特文字的语言，如果数据量不够大，要得到良好的表示是极其困难的。
还有一些语言，它们历史上是用一种新的文字书写的，但现在政府希望用全新的文字书写，比如古老的俏皮文字。
因此，没有太多内容来代表这些文字，所以学习表示形式是困难的。
此外，即使在进行挖掘后，我们创建的许多内容也是在一个相当有限的领域，通常是宗教内容。
好的，现在我们讨论了数据，我想稍微过渡一下，谈谈一些建模工作。
仅仅是从高层次上开始，我认为在谈论大规模、多语言建模时有三个主要挑战，这些几乎也适用于语言模型。
第一个挑战是对低资源语言进行有效的数据增强。
你如何防止低资源语言数据在你看完所有德语或俄语单词之后完全被淹没？
我认为还存在模型的可扩展性问题。
即使你训练非常大规模的模型，如何防止不同语言的表示相互干扰？
这也导致了最后一个观点，如果你给模型非常有限的容量，那当然它可能没有能力对所有这些不同的语言进行建模。
所以你也需要加速模型的规模。
对于那些可能以前没有见过翻译系统的人，我不知道你们中有多少人，我们使用标准的序列到序列模型。
输入文本，合唱的事情是您想要翻译的内容，然后有一个transformer解码模型，通过一个张力机制，进入一个transformer解码模型，然后它以自回归方式解码实际的翻译，您可以在这里看到它是黄色的。
所以我想谈谈当我们将其馈送到模型时数据的外观。
所以有几种不同的方式，您可能想考虑数据。
所以您可能想要思考，好的，是不是有人看了它并决定这两个句子是翻译？
还是它们是嘈杂的？
此外，它的大小是否受限？
您还可以思考的另一件事是，数据质量是否取决于其他因素？
这就是模型相关的事情，如果是这种情况，那么数据质量可能受到该依赖关系质量的限制。
所以我认为您可以思考一下理想的数据集。
就像，人类已经审查了其中的每一部分。
一点噪音都没有。
我们有无限的数量，并且它不依赖于任何其他模型。
它只是纯粹的质量。
但实际上，更接近我们拥有的是这些。
所以我们有许多不同的数据源。
我们有我在演讲中讨论过的种子数据，这是一小部分真正高质量的人工对齐数据。
但唯一的问题是它的规模有限。
就像每种语言有 6,000 个句子。
我们有公共的双语数据。
这是人们多年来在翻译工作中创建的数据。
你可以从 Opus 语料库中下载，例如。
大部分并未经人类审查，因此非常嘈杂。
在许多语言中，它只是来自《圣经》，所以规模相当有限。
你有我们挖掘的数据。
所以这也不是与人类对齐的。
但它确实有一个模型依赖。
它依赖于句子编码器的质量。
我们还有来自回译的其他两个数据源。
回译的想法是一种在机器翻译中广泛使用的模型增强技术，其中你使用模型生成伪翻译，就像银牌数据一样。
我们使用两种不同的技术来生成这些回译，这也取决于用于进行翻译的底层模型。
这是一张高水平不同数据源的图片，以及您应该如何思考质量和不同轴。
那么，如果我们把它们全部放在一起，我们会得到什么呢？
这里的Y轴是训练对的数量。
而X轴则是按资源排序的语言。
因此，您可以看到在左侧，您有一些低资源语言，比如Wolof。
而在右侧，您有一些高资源语言，比如法语。
巅峰当然是英语。
因此，如果您只看看公开可用的内容，这就是您得到的分布。
然后您会很快看到一个巨大的下降。
然后，如果加入我们通过挖掘和回译创建的数据，我们的目标基本上是使分布更加均匀一些。
当然，在极低资源的一侧，这非常困难，但我们的目标是使分布更加均匀，这样您甚至在看到德国数据的三个分片之前，不会立即对低资源语言进行过度拟合。
考虑到这种数据策略，我想稍微谈谈专家混合模型。
所以这是我们在翻译领域积极探索多年的一件事情。
关于一些正在进行的辩论，比如，对于大型语言模型，你想要稀疏的还是密集的架构，我们可以进行平等的讨论。
但基本上，专家混合使规模变得巨大，因为你不必仅仅扩展你的密集主干模型。
但你可以拥有许多不同的独立专家，你可以为每个标记激活它们。
它还允许你避免语言干扰，因为这个想法是不同的专家，它们可以专门针对特定的语言。
不幸的是，它增加了大量的容量，所以很容易过拟合。
所以我要谈一下这种过拟合现象。
我们要讨论的顶部图表是关于刚果语言的。
然后底部的语言集是法语。
所以你真的想比较顶部的低资源语言和底部的高资源语言。
所以如果你只是采用你的密集模型，传统的transformer，序列到序列的架构，这就是你所展示的图表。
所以在低资源语言上有一点过拟合，但你可以用标准的dropout技术来规范化这个问题。
所以这并不是一个大问题，在法语上基本上没有真正的问题。
然而，当你从密集架构切换到基于令牌级的MOE架构时，你会在低资源语言上遇到严重的过拟合问题。
所以这里的绿线只是在没有使用dropout时演示过拟合的情况。
然后如果你添加dropout，你会得到稍微好一些的性能，但仍然有相当严重的过拟合问题。
基本上，到了12K次更新，继续训练就没有什么意义了。
你基本上在浪费GPU。
因此，我们实际上花了很多时间来研究如何正确规范化这些MOE架构，使用这种特定的掩码技术对决定在你的MOE架构中路由到哪个专家的门控函数进行规范化，以试图消除一些这种过拟合效应。
所以如果你看右上角的图表，紫色线，你仍然会看到一些成功的规范化。
我们做的另一件事，来控制过拟合效应，实际上在今天的语言模型中被广泛使用的是课程学习。
这个想法是，当引入新语言时，我们要如何分阶段？
我们尝试训练了一个基本模型，然后开始测量语言何时开始过拟合。
然后我们将它们基本分成了不同的部分。
对于像法语这样的高资源语言，你希望尽早开始，并且需要在整个过程中进行训练。
但对于像沃洛夫语这样的低资源语言，也许在大约10万次更新之后，它就完成了。
所以其余的时间只是在过拟合。
因此，实际上你训练得越多，情况就越糟。
因此，我们的做法是将一些低资源语言推迟到训练计划的后期。
因此，你首先训练高资源语言，然后是中等资源语言，然后是低资源语言，最后是非常低的资源语言。
因此，在理论上，到最后，所有内容都已经训练完成，并且不像没有这种技术的情况下那样过度拟合。
所以我想展示一些结果。
首先，我想展示现有数据集的结果。
所以在我们讨论200种语言之前，让我们先谈谈100种语言。
这是 Flores 101 的开发测试。
对比至关重要，因为这是社区中现有基准的所在之处。
而在200上，当然，我们可以提出任何东西，因为这是对那个领域的首次研究。
所以第一列是从英语翻译出去，比如从英语到中文，从英语到冰岛语，诸如此类。
第二列是从英语翻译成英语，所以从中文到英语。
第三列，XXYY，翻译任何不涉及英语的交叉对。
而最后一列是平均值。
所以如果你看第一组行，这是对覆盖87种不同语言的模型进行的比较。
所以有这篇论文MTM 100。
还有这篇DeepNet论文。
所以你可以看到平均BLEU分数。
BLEU是一种标准的翻译度量标准，本质上是单词重叠的度量。
所以我们在这里看的是BLEU分数。
因此，你可以看到最后一行，NL将是200。
即使我们覆盖了200种语言，BLEU分数远高于一些现有的工作。
现在，如果我们看101种语言，那时只有微软的DeltaLM论文涵盖了这么多的语言。
因此，如果您在所有不同的交叉集上进行比较，同样地，您会发现这个无语言落后模型在 BLEU 方面更加强大。
关于这些 BLEU 数字的方差，有一件事情需要非常快速地了解，我认为这很重要，那就是它是否具有统计学意义。
我认为大约 0.5 BLEU 类似于您会看到的一般误差范围。
因此，如果它高于这个值，通常就是统计学上显著的度量改进。
好的，现在我想谈一下关于 FLORAS 200 结果的一点。
所以这里类似的，就是英语翻译出的第一批列，然后下一批列是英语翻译过来的。
然后您有您的交叉对，然后您有您的平均值。
所以我们也有这个 BLEU 度量。
我们还有一个基于 C、H、R、F++ 的字符级度量，这在翻译社区中很常用。
因此我认为看着这些数字，当然，就像之前的幻灯片上没有基准工作可以比较一样。
所以，您知道，当我们稍后进行人类评估时，情况会更具体一些。
但我认为，通常这类数字的一个经验法则是，大约30左右就可以相当可用了。
我认为另一件事是，如果将这些监督对比与零样本对比一下，我认为我们在零样本上并没有看到很大的下降，这表明模型有一定的泛化能力，即使在训练过程中没有直接看到那个翻译对。
另一种校准的方法是与谷歌翻译进行比较。
如果与谷歌翻译进行比较，不留一种语言的效果要比翻译成英语好得多，但翻译出英语的效果不如谷歌翻译。
虽然如果你把一切都平均起来，结果会好一点。
我想谈谈人类评估，以补充我们在自动评估上的一些讨论。
所以我认为，自动评估指标很快，对于研究迭代非常有用，没有它我们无法前进。
但人类评估才是真正的王道。
所以我们在AMTA上发表了一篇论文，介绍了如何使人类评估在不同语言对之间保持一致且可扩展性强。
我认为这与我在谈话开始时提到的评估数据集的观点有关，在那里，你知道，如果你是一位专业的德语翻译，你真的很擅长评估你的德语翻译质量。
但除此之外，你知道，没有太多的一致性。
如果你用五分制来评估翻译，你知道，就像在两种语言之间翻译的是五分，而在另外两种语言之间翻译的是三分，这两者真的可比吗？
因此，我们对如何使这个更具可比性进行了整个实验方法论。
所以我现在想展示一些关于此的结果。
这里的Y轴，度量标准称为XSTS，是我们进行人类评估的某种度量标准。
这里的Y轴实际上是差值。
所以任何事物，你知道，都是一个五分制。
所以这是一个差值，而不是原始分数。
这里的X轴是我们评估的许多不同的翻译方向。
所以灰色集合是翻译成英语。
绿色集合是翻译非英语方向。
比如法语到沃洛夫语。
然后蓝色集合是从英语翻译出去。
因此，你要寻找的是正的增量，表示我们的建模架构要好得多。
所以增量之间的差异就像是一个基线transformer模型，只是在我们所有的数据上训练，与我们创建的最终的不留言语的模型之间的差异。
所以数据实际上对它们两者来说都是一样的。
这就是我们得到所有 200 种语言的方式。
所以我们只是在这里测量模型改进的人类评估。
所以你可以看到大多数增量是相当明显的。
有些不太明显，比如，你知道，祖鲁语到英语。
我们似乎没有太多改进。
但总的来说，像这样的改进是可以通过人类评估来检测到的。
你可能还会问，像是，好的，在这里的统计显著差异是多少，大约是零点二到零点三加减之间的某个值是相当明显的。
而在零点五以上，就非常明显了。
我还想要评估的一件事是，评估模型有许多不同的方面。
而我认为，如果你看所有不同的类似LLM排行榜或透明报告之类的东西，你会很快内化这个过程。
但我们刚刚看到的只是非常高层次的摘要数字。
而它们并没有真正告诉你，到底有哪些错误，它到底能否被人们有效使用？
它是否是人们可以依赖的安全工具？
因此，我们真正关注的一点是用户安全，其中一些体现在我们进行的一些有关毒性的工作中。
而这里的驱动因素是，并非所有的翻译错误都是相等的。
因此在covid期间，有一个引起轰动的翻译。
但covid期间的信息是，你必须洗手。
但翻译的结果是，你必须握手，我认为这与你想要做的事情完全相反。
其他类型的测量错误也非常重要。
所以，如果你在告诉某人他们想要走多远，然后你的翻译是，嘿，你想旅行500公里。
这是一种完全不同类型的问题。
因此，在处理毒性方面，这是我们工作的重点之一，我们收集了所有 200 种语言的不同毒性列表。
那么为什么我这么关心毒性呢？
我认为这是用户安全的问题。
如果你输入一些完全良性的文本，然后输出却是亵渎语言，我觉得这真的很出乎意料，而且会破坏对系统的信任。
这对人们来说是一种极为糟糕的体验。
话虽如此，这也是一件非常非常具有挑战性的事情，因为它在文化上非常特定。
因此，在某些语言中是蔑称或侮辱的事物，在其他文化中可能并不具有普遍性。
这意味着这类事物非常难以创建。
我之所以对这个方向很感兴趣，还因为我认为它对各种不同类型的检测和缓解工作都是广泛有用的，而不仅仅是在翻译的背景下。
因此，即使我们是在翻译的背景下开发的，它在其他类型的自然语言处理应用中也可以广泛使用。
这也是开源的。
你可以下载它。
你必须输入一个小密码，这个密码在 GitHub 存储库中，以免你意外下载并发现你的计算机上到处都是脏话文件。
好的，我想最后谈一点关于未来方向的想法。
在我谈到那之前，有一篇长达190页的论文详细写出了所有这些内容，如果你感兴趣的话可以查阅。
所以我认为我真的对一些未来的方向很感兴趣。
其中一些也非常适用于诸如语音之类的东西。
我认为其中一个是更明确的多语言。
所以我认为很多多语言方法都是这样的，嘿，我们有这个对一种语言效果很好的东西。
让我们尝试将其扩展到许多不同的语言。
然后我们会把它们都放在同一个建模桶里，然后希望模型学到所有这些不同的表示。
但我认为有很多潜力来明确地引入这个事实，即你知道它是多语言的，而且在架构上更多地考虑。
因此，有可能捕捉到更多语言之间的细微差别或不同语言之间的关系。
另一个是持续支持每个人。
我认为这个项目反映出的一个问题是，你知道，从100到200已经相当具有挑战性了。
但是，超越了很多我们在这里开发的技术并不一定具有可伸缩性。
这实际上也启发了我们在语音翻译方面的一些工作。
所以，如果你最近看到了像无缝的 M4T 发布或者像未书写的语言这样的东西，我们做了很多福建话的建模。
我认为这个方向非常合适，因为许多人想要使用的语言都是口语为主，并不一定是主要用于书面表达的。
然后我认为我仍然非常热衷的最后一件事就是持续增加模型的易用性和培训，并且让社区民主化。
所以，在这项工作中，我们尝试做的一件事情就是非常清晰地写下我们所做的一切，甚至是像数据管道之类的东西都开源。
因此，你可以获取我链接的所有仓库，你知道，像一个庞大的文档。
但我认为如果有人尝试为他们自己的语言重现这个过程，而且很多人已经这样做了，就像我并不是说这种情况没有发生过，但如果你想要这样做，那将会非常非常困难。
因为涉及到了很多不同的事情。
所以我认为我们看到的大部分情况是人们下载了基本模型，然后对其进行了调优，以适应他们自己的语言。
但要想将更多的语言添加到系统中是相当困难的，因为所有的部分都非常复杂。
因此，我觉得对于整个翻译社区来说，关键问题是我们如何简化许多这些事情？
我认为这就是很多基础建模创新可以帮助我们实现的地方。
所以，是的，我有机会发表这个演讲，但当然这项工作是由我在这里引用的一个庞大团队的人在做。
如果你想使用其中任何内容或想要了解更多信息，那么一切都可以从这个主要的GitHub仓库中FairSeek中找到链接。
然后你可以随意点击其他的内容。
但是，如果有任何问题或其他类似的事情，也许我会把话题转给Stephen。
好的。
感谢你的精彩演讲。
是的。
如果有任何问题，请随意取消静音并提问。
你们是不是咨询了很多像是母语人士关于脏话和这类的东西？
比如，你们是如何获取低质量语言或低资源语言，并确保翻译正确的？
是的，是的，这是一个非常好的问题。
我的意思是，我认为在整个开发过程中咨询大量的母语人士是最重要的。
因此，我们最初的一部分工作就是采访一大群人，了解他们在高质量翻译中所期望的内容。
然后，我们雇佣了一个完整的专业翻译团队，花了相当长的时间来寻找，在整个过程中进行咨询。
而现在，一些类似于毒性列表的东西也是开放给社区的。
因此，如果你提交了一个拉取请求，我们会尽量验证它是否是一个有用的补充，然后尝试将其合并进来。
我们现在在现场有一个问题。
我们看看那个问题很快会提出来。
所以我会发言。
那么，你们大部分时间是花在数据管道状态上吗？
是的，是的。
好问题。
我觉得问题是，你大部分时间都花在数据管道状态上了吗？
最后大约是50-50，一半是数据处理工作，另一半是驱动工作，然后另一半是建模和评估工作。
因为一旦数据确定了，那么在建模方面就会有很多的迭代，来确定我们应该使用多少数据？
比如我们应该如何划分数据？
我们如何防止过拟合？
什么是正确的架构？
但很多工作都放在了数据方面，因为我认为如果你没有高质量的数据，你就无法得到一个好的模型。
而对于数据挖掘，你如何挖掘数据？
你使用像Selenium这样的工具，或者如何挖掘网络？
是的。
所以对于网络，我们从Common Crawl开始。
我们下载了所有不同的Common Crawl转储，然后我们使用HTML解析器。
我认为现在，你知道，如果你下载了，例如，红色睡衣数据集，他们做了很多这样的解析工作。
然后我们设置了大规模的管道。
比如你可以使用Spark来处理这些事情，比如分割所有不同的句子，运行语言识别。
你知道，你可以进行不同的启发式清理。
有些语言很难确定什么是句子。
比如我认为在泰语中，没有句号。
所以你必须使用不同的模型来确定什么是句子，并解析其中的一些内容。
然后我们最终得到了我们的单语数据转储。
什么是Common Crawl？
这是你用于数据集的软件吗？
哦，是的。
Common Crawl有点像是网络的开源版本，我想，可能是每季度运行一次。
我得查一下。
但是，如果你去像Common Crawl点org这样的网站，你可以下载它。
但警告，它非常庞大。
我有一个问题。
你可能已经简要提到过这个问题，但我想知道聊天GPT和GPT-4在这方面的表现如何。
比如，只是更多的规模和预训练数据对低资源机器翻译也有帮助吗？
是的，是的，好问题。
事实上，已经有一些关于这些系统如何工作的研究进行了。
我认为对于资源丰富的语言来说，扩展规模实际上是非常有益的。
我认为其中一部分原因是模型具有某种固有的泛化能力。
因此，人们谈论不同语言中的不同事物是挑战之一。
所以，看到另一种语言中的知识实际上有助于泛化。
但在资源匮乏的语言上，是的，性能相当困难，特别是在一些翻译基准上。
我也认为，以翻译为目标进行训练的语言模型在翻译基准上的表现往往更差。
因为语言模型大致捕捉到相同的东西，而翻译模型，你真的要更加努力地对齐意义。
但是，对于资源匮乏的情况，仍然是相当具有挑战性的。
但是，有趣的是，对于大多数英语语言模型来说，实际上可以做出合理的其他语言的输出。
因为在你的英语特定数据中不可能消除其他语言。
所以像法语或德语之类的语言将会有合理的效果。
所以，只是为了澄清，你说通过翻译目标训练的语言模型效果更好，对吗？
因为它们往往表现更好。
就像如果你为翻译任务进行微调，它往往会表现更好。
这与一些在上下文中进行少量示例的情况相比是有道理的。
是的，没错。
确切地说。
确切地说。
另一个问题是，你觉得这与在特定专业领域进行微调相似吗，这些领域可能也缺乏数据和资源。
以及领域特定的术语等等。
是的，我是说，我认为如果我们现在重新开始这个项目，我认为那也会是我们首先探索的事情之一。
或者至少是一个非常强大的基线，如果你拿一些数据然后尝试微调或者尝试进行领域适应。
我认为这也是一些检索型方法用于翻译的地方。
但也有大型语言建模工作，你试图有一个单独的领域，你可以在其中检索一些文本进行适应。
我认为所有这些方法都非常有前景。
太好了。
还有其他问题吗？
关于幻灯片上变量性的一个快速问题。
我觉得你展示了一些零射击的峰值结果，比起基础模型要高。
你认为这是因为在那些低资源语言上可能仍然存在一些过拟合吗？
是的，好问题。
所以对于我们的大规模挖掘，我们不介意每一个可能的交叉对。
比如冰岛语，可能不是最受欢迎的翻译方向。
所以我们没有考虑所有的200乘以200，因为这会导致组合爆炸。
这就是零射击结果的来源，你不需要，在这个对中我们没有训练数据的方向。
但是模型已经看到了输入和输出。
所以我认为这些结果相当不错。
嗯，对于某些语言来说，它们是不错的，这表明了泛化能力。
并且不是每一个配对都那么重要，但其中许多并不是很好。
所以你会看到总体上，性能较低，尽管在某些语言上它可以表现得比你期望的要好。
但这是因为它已经看到了输入和输出。
这并不是零-shot学习，完全没有见过的语言。
有一个问题是，你们是否也做一些与音频信息转录相关的工作？
是的，好问题。
所以在这个项目中，不，转录工作并不多。
但是我们有一个后续工作，实际上就在大约一个月前发布了，叫做无缝M4T，这是一个针对语音和文本翻译的联合模型。
在这个项目中，我们确实利用了大量音频转录，因为这也有助于我们桥接口语数据和文本数据，以便一起利用它们。
只是为了澄清一下，监督式微调相比其他方法效果更好吗？
实际上，在这项工作中，这是几年前的事情了，所以监督式微调并不像现在这样常见。
但我认为在文献中，如果你想使用大型语言模型进行翻译，目前最好的方法是进行一些监督式微调。
我只是在想，因为人类学习的方式并不仅仅是通过看不同语言中相同事物的对应并记忆如何从一个语言映射到另一个语言。 
我们在一种更无监督的方式中学习，如果我们知道两种语言，那么我们就可以自然地在它们之间进行翻译。
但我想对于语言模型来说，拥有监督的例子确实有帮助。
是的，我认为，随着基础模型的质量不断提高，质量可能会得到改善，你就不需要越来越少的微调。
我是说，我认为这就是开放式AI的方法，如果你拥有最好的基础模型，那么你就不需要太多领域特定的微调。
我认为，你知道，就像在我开始从事文本生成时一样，有翻译研究人员，总结研究人员，问答研究人员，他们的工作方式都很不同。
但现在，就像，它都是由同样的基础东西驱动的。
你不再是一个专业的总结研究人员。
是的。
我认为那很有道理。
我们还有其他问题吗？
有问题吗？
Peran，还有其他人有问题吗？
我想没有了。
好的，很好。
好的。
嗯，非常感谢你，Angela，再次进行这场非常有趣而精彩的演讲，感谢你抽出时间，我们希望，是的，我们希望你能保持联系。
如果有人有任何其他问题，请随时与Angela联系。
非常感谢今天能够邀请我。
再见，大家。
