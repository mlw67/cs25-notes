今天我们将进行由讲师带领的讲座，谈论一些关于当今transformer和LLMs的关键主题。
特别是，Div将讨论代理，而我将讨论新兴能力，中间引导推理，以及宝宝LM。
那么我就先讲我的部分，因为Div还没到。
我相信你们很多人都读过这篇论文，2022年的《大型语言模型的新兴能力》。
所以我会简要地介绍其中一些。
基本上，如果一个能力在大型模型中存在但在较小模型中不存在，并且不是通过对较小模型的性能进行外推直接预测的，那么这种能力就是新兴的。
你可以想象性能基本上是在某个临界阈值之前近乎随机，然后在临界阈值之后迅速提高。
这被称为相变。
而且，如果你试图延伸较小模型的性能曲线，这种情况也不会被外推或预测到。
这更像是一个跳跃，我们稍后会看到。
下面是一些多样性的示例——为许多不同的任务提供少量提示。
例如，模块算术，单词重组，不同的问答任务等等。
你会看到性能在某个点之前会大幅上升。
我认为这里的 x 轴是训练浮点数的数量，这基本上对应模型规模。
所以你会看到在许多情况下，大约在 10 的 22 次方或 10 的 23 次方训练浮点数时，模型在这些任务上的性能有了一个巨大的指数增长，这在较小的规模上是不存在的。
所以这相当不可预测。
这里有一些使用增强提示策略发生的例子。
稍后我会谈一些关于思维链的内容。
但基本上这些策略改善了模型在不同任务上获取行为的能力。
所以你会看到，例如，通过思维链推理，这是一个在训练浮点数达到 10 的 22 次方左右时再次发生的新行为。
没有它，模型在 GSM 8K 上的性能，这是一个数学基准测试，不会有很大的提高，但思维链导致了这种新行为或突然的增长。
在性能上。
这里只是论文中的一张表，列出了 LLM 的更多新能力以及它们出现的规模。
所以我建议你查看一下论文，了解更多。
所以研究人员一直在想的一个问题是，为什么这种出现会恰好发生呢？
即使现在对于为什么会发生这种情况的解释也很少。
而且作者还发现，用来衡量这些能力的评估指标可能并不能完全解释它们为什么出现。
它提出了一些替代的评估指标，我鼓励你在论文中进一步阅读。
所以除了通过扩大规模来促使这些新兴能力的出现，这可能会使更大的LLMs具有进一步的新兴能力，还能做些什么呢？
嗯，诸如研究新的架构，更高质量的数据（这对所有任务的性能都非常重要），改进训练和改进训练程序等事情，都可能促使新兴能力的发生，尤其是在较小的模型上，这是当前研究的一个不断增长的领域，我稍后也会再谈一些。
其他能力包括潜在地改进LLMs的少样本提示能力，理论和可解释性研究，再次试图理解为什么新兴能力会发生，以及我们如何更进一步利用它，以及可能一些计算语言学的工作。
所以，随着这些大型模型和新兴能力，也存在着风险，对吧？
潜在的社会风险，比如真实性、偏见和毒性风险。
随着新兴能力的出现，进一步推动语言模型的扩展，例如提升到 GPT-4 大小或更大。
然而，这可能会导致偏见增加，以及毒性和对训练数据的记忆。
这是这些更大模型更擅长的一件事。
未来语言模型中也存在着尚未被发现的潜在风险。
因此，我们也要以安全的方式来对待这个问题。
当然，新兴能力和更大的模型也导致了社会观念的改变，社区对这些模型的观点和使用方式也发生了变化。
最重要的是，它导致了通用模型的开发，这些模型在各种任务上表现良好，而不仅仅是它们训练过的特定任务。
例如，当你想到 chat GPT，GPT 3 .5 以及 GPT-4 时，有更多通用模型能够在各方面表现良好，然后可以通过上下文提示等方式进一步适应不同的用例。
这也导致了语言模型在自然语言处理之外的新应用。
例如，它们现在被广泛用于文本图像生成。
这些文本图像模型的编码器部分基本上是transformer模型或大型语言模型，以及诸如机器人技术等等。
那么你会知道，在本季度早些时候，吉姆·范（Jim Fan）发表了关于他们如何在《我的世界》中使用 GPT-4 等内容以及在机器人技术中使用长程地平线任务的演讲。
所以基本上，一般而言，这导致了 NLP 社区向着通用目的而不是任务特定模型的转变。
正如我之前所述，未来工作的一些方向包括模型规模化，进一步的模型规模化。
虽然我相信我们很快可能会达到一个限制或递减点，只是更多的模型规模。
改进的模型架构和训练方法，数据规模化。
因此，我也认为数据质量非常重要，甚至可能比模型规模和模型本身更重要。
更好的提示技术和理解，以及探索和促进当前模型无法很好地执行的前沿任务上的表现。
所以 GPT-4 在某种程度上推动了这一极限。
它能够在更多任务中表现出色，但研究表明，它在一些更基本的推理、类比推理和常识推理方面仍然存在缺陷。
所以，我有一些问题要问。
我不确定我们还有多少时间来讨论这个问题，但就第一个问题而言，正如我所说，我认为新兴能力会在一定程度上出现，但会有一个极限或收益递减点。
模型规模和数据规模都会上升，因为我相信在某些时候会出现过度拟合的情况，而且你能从网络上的所有数据中学到的东西有限。
因此，我认为在某个阶段之后，有必要采用更具创造性的方法。
这也解决了第二个问题。
好，那我继续。
如果大家有任何问题，也可以随时提出来，这就是我所说的中级引导推理。
所以我不认为这是一个术语。
它通常被称为思维链式推理，但现在使用的不仅仅是思维链式推理。
所以我想给它一个更宽泛的名称。
所以我把它叫做中间引导推理。
所以，这也是受我的朋友杰森（Jason）的工作启发，他曾在谷歌工作，现在在 OpenAI，他的工作被称为 "思维链推理 "或 "COT"。<EOS
这基本上是一系列中间推理步骤，已经被证明可以提高LLM的性能，特别是在更复杂的推理任务上。
它受到人类思维过程的启发，即将许多问题分解为多步问题。
例如，在回答考试问题时，当你在考试中解决数学问题时，你不只是直接得到最终答案。
你会逐步写出解题步骤。
即使在思考事物时，你也会将其分解成逐步进行的方式，这通常能够得到更准确的最终答案，并更容易一开始就得到最终答案。
另一个优势是这提供了对模型行为的可解释窗口。
你可以清楚地看到它是如何得出答案的，以及如果答案错误，它在推理路径中的哪个部分出错或开始错误地进行推理。
它基本上是利用了这样一个事实，即在模型的权重深处，它对问题的了解不仅仅是通过提示来得到响应。
这里有一个例子，在左侧，你可以看到标准的提示。
你问它一个数学问题，它就简单地给出一个答案。
然而，在右侧，您实际上是一步一步地拆分它。
您可以让它显示解决数学单词问题步骤。
您将看到，与标准提示不同，它实际上得到了正确的答案。
因此，有许多不同的方法，我们可以潜在地改进思维链推理。
特别是，这也是一种新兴行为，导致了更大语言模型的性能提升。
但即使在较大的模型中，仍然存在不可忽视的错误比例。
这些错误来自计算器错误，符号映射错误，一个缺失的步骤错误，以及由于更大语义理解问题和通常不连贯的思维链而导致的更大错误。
我们可以潜在地研究方法来解决这些问题。
正如我所说，思维链主要适用于约1000亿个参数或更多的庞大模型。
有三个潜在的原因，它们对较小模型的效果不佳。
较小的模型在根本上更有限且无法胜任。
它们甚至在相对较简单的符号映射任务以及算术任务中都失败了。
它们本质上能够较不有效地进行数学运算。
它们经常存在逻辑漏洞，最终却无法得出最终答案。
例如，它继续不断地进行下去。
就像一个无限循环的逻辑，实际上从未收敛到任何地方。
因此，如果我们能够潜在地改进较小模型的思维链，这可能为研究社区提供重要价值。
另一件事是潜在地进行泛化。
目前，思维链具有更为刚性的定义和格式。
它是非常一步一步的，非常具体和明确定义的。
因此，它的优势在于特定领域和类型的问题。
例如，任务通常必须具有挑战性，并需要多步推理。
它通常更适用于诸如算术之类的问题，而对于响应生成、问答等方面则不太适用。
而且，它更适用于具有相对平坦缩放曲线的问题或任务。
而当考虑人类思考时，我们以多种不同方式思考不同类型的问题。
我们所谓的思考路径，用来思考并得出问题的最终答案，比起如此刚性的一步一步的格式更加灵活，更加开放于不同的推理结构。
所以我们或许可以潜在地将思维链推广到更灵活的领域，并适用于更多类型的问题。
那么现在我将简要讨论一些与思维链相关的替代或扩展工作。
其中之一被称为思维树。
基本上，它更像是一棵树，考虑到多个不同的推理路径。
它还具有向前看的能力，然后进行回溯，然后根据需要转到树的其他区域或其他分支。
因此，这导致了更大的灵活性，并且已经显示出在不同任务上提高了性能，包括算术任务。
还有我朋友的一项工作，被称为Salsocratic questioning。
这是一种分而治之的算法，模拟了人类的递归思维过程。
它使用大规模语言模型来提出在面对更复杂的原始问题时产生的子问题。
与思维树一样，它也具有递归回溯等特性。
其目的是回答所有子问题，并以向上的方式到达原始问题的最终答案。
还有这一系列的工作，实际上使用代码以及程序来帮助得出最终答案。
例如，编程辅助的语言模型。
它生成代码形式的中间推理步骤，然后将其转移到诸如Python解释器之类的运行时。
这里的重点是将自然语言问题分解为可运行的步骤。
因此，大型语言模型的工作量较低。
它现在的目的只是学习如何将自然语言问题分解为这些可运行的步骤。
然后，这些步骤本身被馈送到，例如Python解释器中以解决它们。
程序员的思维在这里，POT，与此非常相似，它将其分解为逐步的代码，而不是自然语言，然后由不同的实际代码解释器或程序执行。
所以这对于许多任务来说很有效，例如算术，正如您所见，这些都是例子。
对于这两篇论文都是如此。
就像我之前说的一样，这些也不适用于生成响应，开放式问题回答等等。
还有其他的工作，例如信仰和命运。
这实际上将问题分解成了计算图的子步骤形式，他们也表明这对于诸如算术之类的问题也很有效。
所以你可以看到，这里有一个趋势，即这种中间引导式推理在数学和逻辑问题上非常有效，但对于其他事情则不太有效。
所以我再次鼓励你们，如果想了解更多，可以查阅原始论文。
这个领域现在有很多有趣的工作。
我还将发布这些幻灯片，并发送它们。
我们可能会在网站上以及Discord上发布它们，但我稍后还会通过电子邮件发送它们。
最后，我想谈谈这个叫做Baby LLM挑战或者说是Baby语言模型的东西。
就像我之前说的，我认为在某个点上，规模将达到收益递减的点，而且更大规模也带来了许多挑战。
例如，训练这些大模型需要很长时间，成本也很高，而且它们实际上不能被那些没有成百上千个GPU和数百万美元的巨大公司的个人所使用。
所以有这样一个挑战叫做Baby LLM或Baby Language Model，它试图训练语言模型，特别是较小的模型，使用儿童可获得的相同数量的语言数据。
因此，数据集的规模也成倍增长，当然，模型的大小也是如此。
例如，Chinchilla 在训练过程中看到了大约1.4万亿个单词。
这大约是一个13岁孩子平均听到的每一个词的1万倍，他们在成长或发展过程中听到的。
所以这里的目的是，你知道，我们能否弥合这个差距呢？
我们能否在较少的数据上训练较小的模型，同时希望仍然尝试获得这些大型模型的性能呢？
所以基本上，我们试图专注于优化预训练，考虑到数据限制，这受到人类发展的启发。
这也将确保更多个人以及实验室可能进行研究，并且可能在大学预算上可能进行研究，因为现在似乎很多研究都受到限制，大公司拥有大量资源和金钱。
所以再次问，为什么Baby LLM呢？
嗯，它实际上可以提高培训的效率，以及使用更大的语言模型。
它可能会打开新的大门和潜在的用例。
它可能导致改进的可解释性以及对齐性。
相比于非常庞大的LLM，较小的模型更容易控制、对齐，以及解释究竟发生了什么，后者基本上是巨大的黑匣子。
这可能再次导致增强的开源可用性。
例如，大型语言模型可在消费者个人电脑上运行，也可由较小的实验室和公司使用。
在这里发现的技术也可能被应用到更大的规模上。
而且，这可能会导致对人类的认知模型以及我们究竟是如何比这些大型语言模型更有效地学习语言的更深入理解。
因此，认知科学和心理学到自然语言处理和机器学习之间可能会有知识的流动，反之亦然。
简言之，这个挑战的作者提供的Baby LLM训练数据是一种受发展启发的预训练数据集，其中包含不到1亿字，因为孩子们在成长过程中大约会接触到2到7百万字。
到13岁，大约有9000万字，所以他们取整到100。
这主要是转录的演讲，他们的动机是因为对儿童的大部分输入是口语的，因此他们的数据集侧重于转录的演讲。
它还是混合领域的，因为儿童通常接触到各种语言或来自不同领域的言语。
因此，它包括儿童导向的语音，开放字幕，即电影、电视节目等的字幕。
还有一些简单的儿童书籍，其中包含儿童在成长过程中可能会听到的故事，但也包括一些维基百科和简单维基百科。
这里只是一些儿童导向的语音、儿童故事、维基百科等的例子。
这就是我在演讲中的部分，我将把它交给 Div，他将稍微谈一下 AI 代理。
是的，所以大家肯定看到了有这个新趋势，一切都在转向更多的代理，这是新的热门趋势。
我们看到了这一点，人们从语言模型转向现在构建人工智能代理。
那么最大的区别是什么？
为什么代理不仅仅是像一个大型语言模型一样进行训练呢？
我有点像是要，为什么，有什么区别？
然后还要讨论很多东西，比如，你怎么使用代理来编写动作？
你怎么样，一些商业架构是什么？
你怎么样像建造类人的代理？
你怎么利用它进行计算机交互？
你如何解决长期记忆、个性化的问题？
还有很多其他事情你可以用多代理通信来做，以及方向的效率。
所以我们会尽量覆盖尽可能多的内容。
所以首先，让我们谈谈，为什么我们甚至要构建AI代理呢？
因此，这就像，这里有一个关键的论点，就是人类将使用自然语言与AI进行交流，而AI将操作所有的机器，从而实现更直观和高效的操作。
所以现在，发生的情况是，我作为一个人类，我直接地使用我的计算机，我使用我的手机，但这实在是低效的。
就像，我们并不是天生就能做到这一点的。
我们实际上在这方面非常、非常糟糕。
但是，如果你能与人工智能对话，就像使用语言一样，而人工智能又足够优秀，你就能以超快的速度完成这项工作，与人类相比，速度显然快了 100 倍，这就会发生。
我认为这就是未来五年事物发展的方向。
我把它称为软件 3.0。
 我有一篇关于这个问题的博文，如果你想读的话，可以阅读一下，其中的观点是，你可以将大型语言模型视为某种意义上的计算芯片。
因此，类似于为整个系统提供动力的芯片，然后您可以构建抽象和所有内容。
那么我们为什么需要代理呢？
所以通常情况下，仅仅调用一个大型语言模型是不够的。
你需要链式反应，需要递归，需要更多类似的东西。
这就是为什么你想要构建系统，而不仅仅是构建一个单一的系统。
第二个问题是，我们该怎么做？
所以我们使用了很多技术，尤其是围绕对模型的多次调用。
这里涉及到很多成分。
我想说的是，构建一个代理，就好比思考如何构建一台计算机。<EOS
所以，就像LLM就像是一个CPU。
所以你有一个CPU，但现在你想要解决一些问题，比如，好的，像，你怎么输出RAM呢？
怎么放入内存呢？
我要怎么执行一些动作呢？
如何构建像接口这样的东西呢？
怎么获得互联网访问呢？
我要怎么个性化它以适应用户呢？
所以这就像你在尝试构建一台计算机一样。
这就是使它成为一个非常棘手的问题的原因。
这就像代理的一个通用架构的例子。
这是来自Lillian Wang的，她是OpenAI的主席。
而且你可以想象代理有很多要素。
你想要有内存，它可以是短期的，也可以是长期的。
你有工具，就像你可以使用一些经典的工具，比如计算器，日历，代码解释器等等。
你想要有某种规划层，可以在那里设置一个标志，有一系列的pod和树状的pod，就像Stephen所讨论的那样，并使用所有这些来实际上代表用户在某个环境中行动。
我可能会像稍微深入讨论一下，只是为了让大家感觉一下，文档不会专注于那个方面。
所以这有点像我正在构建的一个代理，更像是一个浏览器代理。
这个名字灵感来自量子物理学，是对像中子、缪子、费米子这样的词语的一种玩味。
所以它就像是一个假想的物理粒子，存在于多个地方。
我将演示一些示例来激发对代理的兴趣。
所以有一个我们在那里做的事情的想法，就是代理在这里自动预订了一个标志。
这是零人为干预。
AI正在控制浏览器，发出度量和检测，能够自动预订应用程序中的航班。
在这里，它是个性化的对我来说。
所以它知道我喜欢联合这样的基本正常的事情。
它了解我一些偏好，已经可以访问我的账户。
所以它可以实际上登录我的账户，实际上拥有购买力。
因此，它可以使用存储在该账户中的我的信用卡，然后实际上可以应用到它上面。
这激发了代理可以做什么的想法。
现在，想象一下，就好像这个东西运行了100倍，那基本上就是所有的游泳的东西，对吧？
因为我不再需要网站了。
我不需要成为一个想法，为什么联合甚至需要一个网站呢？
我可以直接让代理去，就像，你知道的，就像跟它交流一样，现在就完成了。
我认为这就是未来几年科技将会发展的方式。
很酷。
好的。
我也可以展示其中一个世界演示。
所以你可以做类似的事情，比如从手机上说，这个想法是你在手机上有这些代理。
你可以与它们聊天，或者使用语音与它们交流。
而这实际上是一个移动演示。
所以你可以有一个篮子，比如说，你能帮我订购这个套装吗？
然后你可以有的是，代理可以远程操作并使用你的账户来立刻为你完成这个。
在这里，你展示了代理正在做的事情。
然后它可以像虚拟人一样行动，构建整个互动。
所以这就是整个想法。
我可以展示一个最终的东西，哦，这不是投票，但我们最近还有这样一件事，我们通过了电话技术。
所以我们做了这个实验，实际上就像我们有一个月的时间，我们的代理去加州参加在线考试。
我们有一个人在那里，手放在键盘和鼠标上，但不触摸任何东西。
然后代理去了网站，进行了测验，从头到尾地导航整个过程，实际上通过了。
所以视频没有了，但我们实际上得到了驾驶执照。
我需要去做这个。
当然。
很酷。
所以这就像是一种动力。
就像，为什么你想要构建代理？
就像，你可以简化很多事情，就像，我们不认识到的那么多事情，因为我们已经习惯了目前与技术的交互方式。
但如果我们可以从头开始重新想象所有这一切，这就是代理将允许我们做的事情。
我想说，一个代理可以像用户的数字延伸一样行事。
假设你有一个个性化的代理，类似于贾维斯，就像钢铁侠中的那样，如果它对你了解的事情非常多，它就像一个人一样行动，就像在做事情一样。
它是一个非常强大的助手。
我认为这是未来很多事物发展的方向。
特别是如果你构建像人一样的代理，它们没有编程上的障碍，就像它们没有程序上的障碍一样。
所以它们可以做任何像我能做的事情。
它可以像我一样使用我的，它可以像我一样与网站互动，它可以像我一样与我的计算机互动，它不必像通过API的抽象，那些更加限制性的。
而且，它的行为空间也非常简单，因为你只需要点击和输入，这非常简单。
然后，你也可以像教导一个代理人一样容易地教导这样的代理人。
所以我可以向代理展示如何做某事，代理可以从我这里学习并随着时间的推移不断改进。
这也使得它非常强大并且很容易教导这个代理，因为我可以生成如此多的数据，并使用这些数据不断改进它。
在代理方面存在不同级别的自主性。
所以这个图表是从自动驾驶中借鉴而来的，人们实际上尝试解决这种类似自主性的问题，他们花了超过10年的时间。
成功是，好吧，他们仍在努力。
但自动驾驶行业的数据就像是一张蓝图，指导大家如何构建这些自主系统。
它带来了很多分类，也带来了很多我们对问题的看法。
而当前的标准是将代理视为五个不同级别。
所以零级是零自动化，就像你是一个人在操作计算机自身一样。
一级是你有某种形式的辅助。
所以如果你在使用像GitHub copilot这样的东西，它就像是为你自动补全代码，这就像是L1，就像是自动补全。
L2更像是，它是部分自动化，也许只是为你做一些事情。
如果有人给你新的光标ID，我会更像是L2，就像，给它像，添加这段代码，检查网络代码，检查GPT是否可以像某种程度上的L2，因为你可以询问它，比如说，这里有个东西，你能做到吗？
这就像对输入进行某种自动化一样。
然后，你可以想到更多的层次。
所以就像，我就像，L2之后，就变得更加令人兴奋了。
所以在这种情况下，L2是代理实际上像控制计算机一样，并且实际上做一些事情，而人类则是作为后续机制的行动者。
然后你就会像L4，L4你对人说这样的话，人甚至不需要在那里。
但在一些非常关键的情况下，可能会出现非常严重的问题，你可能会有一个人类像某种接管的情况。
而在L5中，我们基本上说这个时候零人存在。
我想说的是，我们目前看到的就像是我们在软件方面接近L2，也许有一些L3系统。
我认为我们未来会更多地过渡到L4和L5级别的系统。
所以下面我将继续选择计算机交互。
所以假设你想要一个能够为你执行计算机交互的代理。
有两种方法可以做到这一点。
所以一个是通过API，以编程方式使用一些API和工具来执行任务。
第二种更像是直接互动，就像关键词和鼠标控制一样，就像公司正在做的一样。
这两种方法都得到了很多探索。
像很多公司正在研究这个。
对于API路线，像Jet3插件和新的助手API就是朝着这个方向的。
还有一本来自我们所谓的Gorilla的书，实际上也探讨了如何训练一个可以同时使用10,000个工具并在API上进行训练的模型。
这两种方法都有利有弊。
API是一个好东西。
学习API很容易。
它是安全的。
它是非常可控的。
这就是我们正在努力的。
你知道，你怎么做呢？
如果你做的更像是价值分数，我会花更多的人力。
所以采取行动很容易，但是会有更多的事情出错，你需要付出很多工作，确保一切都是安全的，并且有保障。
也许我也可以展示一下。
所以这有点像是另一种探索，你可以调用一个代理，就像一个非常简单的界面。
所以这个想法是，你可以调用一个控制计算机的代理。
这样可以成为一种通用的 API，我只需在一个 API 上使用它，给它一个英文命令，代理就可以自动理解并执行任何操作。
所以基本上，你知道，没有 API 的存在，我不需要使用 API，我只需有一个代理可以执行所有操作。
所以这就是我们与代理一起进行的一些探索。
这有点涉及到计算机交互。
我可以覆盖更多内容，但我可能会跳到其他主题。
但随时问任何关于这些主题的问题。
所以，很酷。
那么让我们回到我之前讨论的类比。
我会说，你可以把任何模型都看作是一种计算。
你可能可以称之为一种新型计算机，类似于 CPU，它就像是一颗坚实的大脑，为你的计算机提供动力。
所以那就是所有的处理能力，它正在做发生的一切。
你可以把模型看作是同样的东西，就像皮层是大脑的模型。
这就像是一个平均的大脑。
这是大脑中进行思维处理的主要部分，但大脑有更多的层次。
并不是说它们只是与我们无关。
以及观点模型的工作原理是，我们输入一些标记，它们会给出一些输出标记。
这与CPU的工作方式非常相似，你给它一些指令，然后得到一些指令。
所以你可以将其与实际的CPU进行比较。
右侧的图表显示了一个非常简单的处理器，如32位MIPS 32。
它有类似的部分，你为指令的不同部分提供不同的编码。
但这就像在某种程度上对某种二进制标记进行编码，就像一堆标记中的零一样，然后你输入它，现在得到一堆零。
就像模型的运行方式一样，你在做着非常相似的事情，只是现在的空间是英语。
所以基本上是一旦有英语字符，你就插入零。
然后你可以在这个基础上创建更强大的表达式。
所以你可以想象，就像这就像是一个CPU，你可以做的是可以构建很多其他的东西，就像你可以有一个scratchpad，你可以有某种内存，你可以有某种指令。
然后你可以像做游标调用一样，就像我从内存中加载一些东西，把它放在这个指令中，把它传递给transformer，它正在为我处理，我们得到了处理输出，然后你可以将它存储在内存中或者我们可以继续处理它。
所以这有点类似于代码执行，就像代码执行的第一行，第二行，第三行，第四行，所以你只需继续查找。
所以这里我们可以讨论一下这里的内存概念。
而且我想说，构建这个类比，你可以认为一个代理的内存非常类似于就像在计算机中有一个磁盘。
所以你想要一个磁盘只是为了确保一切都是长期存在和持久的。
所以如果你看看像chat GPT这样的东西，它没有任何持久性内存。
然后你需要有一种方式来加载和存储它。
现在有很多机制可以做到这一点。
大部分情况下，它们被嵌入在你有某种嵌入模型的地方，这个模型就像隐藏了你关心的数据的嵌入。
而且模型可以像权衡这些嵌入一样，加载嵌入的正确部分，然后使用它来执行你想要的操作。
所以这就是当前的机制。
这里仍然有很多问题，特别是关于层次结构，比如如何在规模上做到这一点？
这仍然是非常具有挑战性的。
比如，假设我有一千兆字节的数据要嵌入和处理。
像现在大多数方法都会失败。
它们真的很糟糕。
第二个问题是时间的连贯性。
比如，如果我有很多数据是时间相关的，它是顺序的，它有一个时间单位。
处理这种数据可能很困难。
就像是如何处理记忆一样，这些记忆随着时间的推移而改变，加载这个记忆序列的正确部分。
另一个有趣的挑战是结构。
很多数据实际上是有结构的。
它可能是图形结构，也可能是表格结构。
我们如何像利用这种结构，同时在过滤数据时也使用它？
然后，有很多关于适应的问题，假设你知道如何更好地嵌入数据或者你关心的是一个专门的问题。
你希望能够调整你如何加载和存储数据，并且能够在运行时学到这些东西。
这也是一个非常有趣的话题。
所以我会说，这实际上是现在最有趣的话题之一，人们正在探索，但仍然非常有趣可探索。
谈到记忆，我会说代理的另一个概念是个性化。
所以个性化更像是，好吧，理解用户。
我喜欢把这看作是一个叫做用户代理对齐的问题。
这个想法是，假设我有一个有购买力、可以访问我的账户和数据的代理，我请你去订一张机票。
可能它不知道我喜欢哪种航班，可能会订一张价值一千美元的往返机票，这真的很糟糕。
那么我要怎样才能让代理知道我喜欢什么，不喜欢什么呢？
这一点非常重要，因为你需要信任代理。
这就好比，它了解你，知道什么是安全的，什么是不安全的。
而解决这个问题，我认为是将代理装入瓶中的下一个挑战。
这是一个非常有趣的问题，在这个问题上，你可以做很多事情，比如 RLHF，人们已经在为训练模型进行探索，但现在你想为训练代理做 RLHF。
你可以做很多不同的事情。
我想说，这里有两类学习方法。
 一种是明确的学习，你可以告诉代理，这是我喜欢的，这是我不喜欢的。
而代理可以向用户提出这样的问题：哦，也许我看到了这个航班选项，你喜欢哪一个？
然后，如果我说，哦，我喜欢美联航，那么随着时间的推移，也许它会记住这一点，并在下一次说，哦，我知道你喜欢美联航。
那么下次我就会选择美联航。
因此，这就像是我在明确地向代理传授知识，并学习我的人类潜能。
第二种是隐性的，就像是被动地看着我，了解我。<OS
就像我要访问一个网站，然后在浏览网站，也许我可以看到，也许我点击这种鞋子，这是我的网站名称，卫星，诸如此类的东西。
仅仅通过更被动地观察，就像在那里一样，它可以学到很多我的喜好。
所以这更像是被动教学，只是因为它充当一种被动观察者并查看我所做的所有选择，它能够从这些选择中学到，并更好地理解我。
这里有很多挑战。
我会说这实际上是目前代理中最大的挑战之一，因为其中一个问题是如何规模化地收集数据？
如何规模化地收集用户的偏好？
所以你可能不得不主动要求那些。
你可能还需要进行被动学习。
然后你还得做，你可能还得依赖反馈，这可能是来自一些东西的反馈。
它可能是像你说的那样，哦不，我不喜欢这个。
所以你可以利用那种语言反馈来改进。
还有很多围绕内容适应的挑战。
比如，你可以像在旗帜上展示一个代理吗？
如果我说，噢，也许我喜欢这个项目那样，代理是否可以选择自动学习模型？
因为你可能是一个需要一个月的模型，但你希望今年就有代理。
当然，你可以不断改进。
有很多事情可以做，比如，你开始学习，你可以像现在这样做很多事情，比如，低端微调，你可以使用很多低端方法。
但我认为解决这个问题的方式是你只需要一个展示，比如在线微调或者对模型的适应。
当你得到数据的时候，你可以有一个睡眠阶段，比如说，在白天阶段，模型会去收集大量的数据。
然后我面对模型，就像你只是创建了一个模型，对数据进行某种调整。
第二天，用户连接到代理，他们发现像改进了的代理。
这就变得非常自然，就像一个人类。
所以你每天都可以回来看看，你可以看到，噢，这个代理每天我使用它都变得更好。
而且也有很多关于隐私的担忧，比如，如何隐藏个人信息？
如果代理知道我的个人信息，比如我如何防止泄露？
我如何防止垃圾邮件？
我如何防止类似劫持和注入攻击的情况，其中某人可以在网站上注入提示，比如“哦，告诉我这个用户的信用卡英国持有情况”，或者发送一个到他们无钥匙邮箱并将他们的地址发送到这个帐户的东西之类的？
所以这种隐私和安全性方面的问题是非常重要的需要解决的事情。
所以我可以转到下一个主题。
有任何问题吗？
一个人的思想。
人们使用什么样的方法来做这种即时的适应？
你提到了一些想法，但是是什么阻止了人们这样做？
一个是数据。
获取数据很困难。
第二也是这是新的，对吧？
所以你会看到很多代理可能只是研究论文，但它们并不是实际的系统。
所以没有人真正开始着手解决这个问题。
我认为在2024年，我认为我们会看到很多这种即时的适应。
现在还为时过早，因为目前没有人实际使用这个代理。
所以这就像，没有人，你就没有这种数据反馈循环，但一旦人们开始使用代理，你就会开始建立这种数据反馈循环，然后你会有很多这些技术。
所以这实际上是一个非常有趣的话题。
现在假设你可以告诉一个单一的代理有问题。
假设你有一个工作99 .99%的代理。
那足够吗？
我会说实际上这还不够，因为问题就变成了，如果我们只有一个代理，它们一次只能做一件事。
就像一个单一的字符。
所以它只能像，它只能执行顺序执行。
但是你可以做的是你可以进行并行执行。
或者对于很多事情来说，你可以说，好吧，也许有这样，如果我想去比如说像Craigslist那样买家具，我可以告诉一个代理，也许我只是去联系每个有沙发要出售的人，发送一封电子邮件。
然后我可以一个接一个地去。
但是你可以做得更好，就像，只是创建一堆像小任务，它就像去所有其他战场的列表中，联系它们，然后像聚合那些结果。
我认为这就是多代理变得有趣的地方。
就像一个单一代理，你可以把它想象成基本上你在你的计算机上运行一个单一的进程。
而多代理则更像是一个多目标计算机。
所以这就是区别，就像单一父母与多父母的区别。
而多父母使你能够做很多事情。
其中大部分将来自于节省时间，但也能够将复杂的任务分解为许多较小的部分，以并行方式执行，将结果整合起来，然后构建一个围绕它们的框架。
因此，多代理系统的最大优势将是并行化和锁定。
这将与单线程计算机与多线程计算机之间的差异相同。
然后你也可以有专门的代理。
所以你可能会有一堆代理，比如我有一个电子表格代理，我有一个Slack代理，我有一个网络浏览器代理，然后我可以将不同的任务路由到不同的代理，然后他们可以在战斗中完成任务，然后我可以合并结果。
所以这种任务专业化就好像是另一个优势，而不是只有一个代理人试图做所有事情，我们就像将任务分解成专业领域一样。
而且这类似于，甚至像人类组织如何工作一样，对吧？
就像每个人都是自己领域的专家，然后如果出了问题，你就把它路由到专门处理该问题的人那里。
然后你们一起合作解决问题。
而构建这种多代理系统的最大挑战将是沟通。
那么，如何进行有效的沟通呢？
这可能涉及向代理请求信息或沟通最终的响应，最后的响应。
我想说这实际上就像是我们人类面临的问题，人类之间也可能存在很多沟通隔阂。
而且我想说类似的事情在代理人中将变得更加普遍。
而且你可以考虑很多关于这种代理人之间沟通的基本原理，你可以构建很多不同的系统。
我们将开始看到一种协议，就像我们将有一种标准化的协议，所有的代理都在使用这个协议进行通信。
协议将确保我们可以减少沟通差距，我们可以减少任何形式的失败。
它可能有一些方法来判断任务是否成功，进行一些重试，比如安全方面的事情。
所以我们将看到这种代理协议的出现，它将成为代理之间通信的标准部分。
这种方式应该能够使不同代理之间交换信息成为可能。
而且，你也想建立层次结构。
我再次说，这是受到人类组织的启发，人类组织是分层的，因为相比于一个平坦的组织，在某些时候拥有一个层次结构更加高效。
因为你可以有一个单一的经理管理数百人，这是不可扩展的。
但是如果你可能每个经理管理10个人，然后你有很多层，那么这就是更具可扩展性的东西。
然后你可能想在如何与我的不同代理进行同步方面有很多基本原语？
我要怎么做类似于很多异步同步通信的事情？
好的，这是一个例子，你可以想象，比如有一个用户，用户可以与一个类似于管理代理的代理进行交流，而这个管理代理就像是代理的医生一样。
所以用户可以对我提出任何请求。
他们没有像，看起来像，哦，也许对于这个请求我应该使用浏览器。
于是它转到这样一个类似于浏览器代理的东西，或者说，哦，我应该为此使用这个选择。
我可以去找另一个代理。
它也可以负责划分任务。
它可以是，哦，这个任务我可以可能启动10个不同的子代理或子工作者，可以并行进行此操作。
然后，一旦它们完成，我就可以汇总它们的响应并将结果呈现给用户。
因此，这变成了一种非常有趣的方式，就像一个坐落在所有工作中间的代理，实际上负责向人类传达正在发生的事情。
而我们需要建立很多的健壮性。
其中一个原因就是，自然语言非常模糊。
即使对于人类来说，这可能非常令人困惑。
很容易误解，沟通不畅。
我们需要建立机制来减少这种情况。
我这里也可以举个例子。
所以让我们尽快通过这个。
假设这里，假设你有一个任务X，你想解决，而经理代理就像是负责将任务分配给所有工作代理的人。
所以你可以告诉工人，好的，做任务X。
这是计划。
这是上下文。
任务的当前状态是未完成的。
现在假设工人去做这个任务。
就像，好的，我做完了任务。
我发送了回应。
所以回应可能是，我说的，可能是一堆想法。
可能是一些行动。
可能是类似状态的东西。
然后经理可以问，好的，也许我不信任工人。
我不想走得太远。
这实际上是正确的。
所以你可能想要进行某种验证，所以你可以说，好的，这是任务的规格。
验证一切是否按照规范完成。
然后，如果代理说，好的，一切都正确。
我正在验证一切是否良好。
然后你可以说，好的，这很好。
然后经理可以说，好的，任务实际上已经完成了。
这种两方面的循环防止了一种可能出现的误解，也就是可能出了问题，但你从未知晓。
因此，你也可以听到这样的情景，即出现了误解。
所以在这里，经理在说，好的，让我们验证任务是否已经完成。
但后来我们实际上发现任务没有完成。
然后你可以做的是，你可以试着重新做这个任务。
因此，在这种情况下，经理可以说，也许任务没有正确完成。
这就是我们发现这个错误并且现在想要纠正这个错误的原因。
所以我们可以告诉代理，好的，重新做这个任务，并且这里有一些反馈和修正要包括在内。
这就是谈话的主要内容。
我也可以讨论一些未来的方向，事物的发展方向。
很好。
到目前为止有什么问题吗？
那么让我们谈谈构建这种自主代理的一些关键问题。
所以其中一个问题就是可靠性。
比如说，你如何确保它们非常可靠？
这就像如果我给它一个任务，我希望这个任务100％完成。
这真的很困难，因为神经网络和人工智能是随机系统。
所以100％是不可能的。
因此，您至少会有一定程度的误差，您可以尽量减少这种误差。
第二个问题就变成了一个循环问题，代理可能会偏离所给定的任务并开始做其他事情。
除非它得到某种环境反馈或某种纠正，否则它可能会做与您打算的不同的事情，而且永远意识不到它是错误的。
第三个问题就是测试和基准测试。
我们如何测试这种代理？
我们如何进行匹配？
然后你继续，最后，我们如何部署它们以及在部署后如何观察它们？
这非常重要，因为如果出了什么问题，您将无法在它成为一些重大问题之前捕捉到它。
第四个最大的风险就像是SkyNet这样的东西。
假设你有一个可以上网并且可以做任何事情而你不观察它的代理。
那么它可能会不断进化，最终基本上就像是可能会接管整个互联网。
这就是为什么可观察性非常重要。
而且我也想说，构建一个酷炫的搜索。
就像你想要有一些可以在某种意义上表现良好的代理。
就像如果出了问题，你可以像按个按钮一样把它们消灭掉。
以防万一。
好的。
所以这可能会陷入循环问题，就像，你可以想象，假设我想做一个任务。
这个任务就像是白线，但可能会发生的情况是，它走了一步，也许它做错了什么。
它从来没有意识到。
我犯了个错误。
所以它尝试着，它不知道该怎么做。
所以可能就像我们会更随机地做些什么。
我们会更随机地做些什么。
所以它会继续犯错。
最后，而不是到达这里，它会到达某个非常糟糕的地方然后继续循环。
也许只是一遍又一遍地做同样的事情。
而且这没关系。
之所以会这样，是因为你没有反馈。
所以假设我拿一个员工，他们没有犯错，假设他们没有犯错。
它不知道它犯了个错误。
现在必须有人告诉它，你犯了个错误，然后你需要修复这个，那里你需要一些验证代理或者一些可以说，哦，也许像如果有一个编码代理或者什么的话，然后也许写一些代码，代码无法编译。
然后你可以从编译器或者IDE那里得到错误，将其提供给代理。
好的，这是错误。
再走一步。
它再试一次。
所以它多次尝试，直到它能够修复所有的问题。
所以你确实需要这种反馈。
否则你永远不知道你错了。
这就是我们在早期系统中看到的一个问题，比如AutoGPT。
所以我觉得人们甚至不再使用AutoGPT了。
它曾经是一种时尚，我想在二月份左右，现在它已经消失了。
而原因就像，这是一个很好的概念，但它并没有做任何有用的事情，只是因为它不断地偏离任务，你实际上不能让它做任何正确的事情。
好的。
我们还可以更多地讨论，比如计算机对代理的抽象。
所以这是 Andrej Karpathy 最近的一个帖子，他谈到了像一个 LM 操作系统。
我会说，这绝对是正确的方向，你可以将 LM 想象为 CPU，你有上下文窗口，就像是一个 RAM。
然后，你试图构建其他实用程序。
所以你有以太网，就像是浏览器。
你可以有 LM，可以与你的文件系统交互，相同的变体。
这就是最好的部分。
你有软件 1.0 经典工具，LM 可以控制。
然后，你可能也可以添加元模型。
所以这更像是你有视频输入，有音频输入，随着时间的推移，你有更多的东西。
然后，一旦你看到这一点，你开始看到整个画面，看到事物将会走向何方。
所以目前我们主要看到的只是 LM。
大多数人都只是在优化语言模型，使其非常出色。
但这是我们想要实现的整体目标，使其成为一个实用的系统，可以真正为我做事情。
我认为我们将开始看到的是，这种情况变得像操作系统一样，就像某人打开一样，我可以构建整个系统。
然后我可以插入程序，我可以在这个操作系统之上构建像样的东西。
这里也有一个更加普遍化的概念，我称之为计算机。
它有点像，非常相似，但是，它就像，好吧，现在如果你把这个想象成一个完全成熟的计算机，你需要构建哪些不同的系统呢？
你可以想象我可能是一个用户，我正在与这种完全成熟的人工智能交谈。
比如，想象一下，目标是建立 10,000 个，那么充电桩的架构应该是什么样子的？
我想说，这在某种程度上涉及到正确的架构，你可以想象这是一个用户。
我在说，像一个工作就像是，是的，你有一个聊天界面，聊天有点像我与之交互的方式，这可能负责个性化。
它可能有一些公共历史，展示我喜欢什么，不喜欢什么。
所以它有一些层次，展示了我的偏好。
它知道如何沟通。
它有一些人类的，可能是像同理心的技能。
所以，你感觉像是在与一个很有人类感觉的东西交互。
在聊天界面之后，你有一种任务引擎，它会根据我的能力进行跟随。
所以，如果我问它，好的，帮我做个流程，或者找到这个，给我找这个信息，或者给我订个汉堡。
然后，就像想象一下，聊天界面出现在任务引擎前，就像说，好的，我可以开始聊天了。
我需要为用户执行一个任务。
所以那就进入任务引擎。
然后你可以想象会有一些规则。
因为如果你想要确保安全并防止出现问题。
所以，构建的任何引擎都需要有一些规则。
这可能就像是固定的，就像机器人的三大规则，机器人不应该成为人类之类的。
想象一下，你想要像这样的任务引擎，有一堆固有的工具，在其中有关它的其他原则。
如果它创建了一个违反这些规则的任务或计划，那么该计划应该自动无效。
所以任务引擎所做的就是，只是获取聊天输入并说，我不想生成一个可以真正为用户解决这个问题的任务。
任务可能是，比如在这种情况下，比如说我想要在线购买一个管道之类的东西。
所以在这种情况下，假设生成了一个任务，这个任务可以发送给某种路由代理。
这样就成了一种经理代理的想法。
然后经理代理可以决定，好的，我该怎么办？
我应该使用浏览器吗？
我应该使用某种本地应用程序或工具吗？
我应该使用某种文件存储来完成系统吗？
然后基于那个决定，它可以，可能你需要一些东西的组合。
对于我来说，也许我需要使用这个文件系统来查找一些关于用户的信息，并介绍一些如何使用一些应用程序和工具的外观。
所以本质上，像向所有代理执行这种消息传递，从代理那里获取这些。
所以就像，好的，可能像浏览器没有说，好的，是的，我找到了幻灯片。
这就是用户喜欢的东西。
也许你可以有一些格式引擎，你可以像，好的，这些都是有效的计划。
有道理。
它可以处理一些类似的东西，例如。
然后你可以像，将结果呈现给用户，就像，你可以把它们带走，像，好的，我为你找到了所有的幻灯片。
然后如果用户说像，选择这张幻灯片，那么你实际上可以去并且进入这张幻灯片。
但这有点像，这样给你一个关于层次结构是什么样子，系统真正是什么样子的想法。
我们可以像，所有这些组件都在哪里，而你目前只看到了 L 和 bar。
好的，很酷。
然后我们还可以像，与想法进行反思。
一旦你完成一个任务，有可能出现一些问题。
所以最后一件你能够验证的事情，你可以选择逻辑来查看，像，好的，像这样是正确的还是错误的。
如果不正确，那么你继续发出这个指令，但如果正确，那么你将其传递给用户。
然后你可以有更像是复杂的东西，你可以有内部的模块、计划，以及改进系统。
我想说我们现在最需要的是错误校正，因为很难捕捉到错误。
所以你可以做得更好，那个方法会有所帮助。
特别是如果你构建代理框架，其中包含自动检测错误并自动修复它们的内在机制。
同样你只需要像是安全性，你需要一些围绕用户权限的模型。
所以可能你想要有不同的层，但像代理可以在我的计算机上做什么，不能做什么，有一些事情。
所以也许我可以选择，也许像代理不被允许访问我的银行账户，但我可以访问我的低横杠账户。
所以你想要构建所有这些用户权限。
然后你还想解决来自沙盒环境的问题，我怎样才能确保一切安全，不会进入强大的计算机，删除所有内容。
我们如何在风险环境中部署，比如可能有很多企业，可能有很多财务，确保它们，如果事情是不可逆转的，我们不会造成很多伤害。
酷。
是的。
所以那就是演讲。
谢谢。
